{"cells":[{"cell_type":"markdown","source":["# Addestramento\n","Migliore modello del TransformerConv addestrato su 1000 epoche per la classificazione delle transazioni"],"metadata":{"id":"P4xEz6Qv7asp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iidXjXM7pXO"},"outputs":[],"source":["%%capture\n","from google.colab import drive\n","drive.mount('/content/drive')  # Autenticazione con Google Drive\n","\n","!pip install torch_geometric\n","#!pip install torch-sparse\n","import pandas as pd\n","import os\n","import random\n","import numpy as np\n","import os.path as osp\n","import torch\n","import warnings\n","from torch_geometric.data import Data, HeteroData\n","from torch_geometric.transforms import RandomNodeSplit\n","from torch_geometric.nn import GCNConv, GATConv, SAGEConv, ChebConv\n","import torch_geometric.nn as pyg_nn\n","import torch.nn as nn\n","import torch_geometric.utils as pyg_utils\n","from torch.nn import Module, Linear\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_recall_fscore_support, f1_score, classification_report\n","from torch_geometric.seed import seed_everything\n","import joblib\n","drive.mount('/content/drive')  # Autenticazione con Google Drive\n","\n","warnings.simplefilter(action='ignore')\n","SEED = 51\n","FILEPATH_TX = \"/content/drive/MyDrive/blockchain/00_gnn/risultati_finali/final_res/tx_last.csv\"\n","FILEPATH_WALLET = \"/content/drive/MyDrive/blockchain/00_gnn/risultati_finali/final_res/w_last.csv\"\n","\n","base_path = \"/content/drive/MyDrive/blockchain/E++/\"\n","path_comb = '/content/drive/MyDrive/blockchain/00_gnn/combination_do.csv'\n","\n","type_classification = 'tx'"]},{"cell_type":"markdown","metadata":{"id":"XOk9zPoYDC5I"},"source":["##Crea db vuoto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCrI1kO2CYxi"},"outputs":[],"source":["def create_df():\n","  # Crea DataFrame vuoti\n","  df_tx = pd.DataFrame(columns=['epoch', 'hidden_channels', 'out_channels', 'num_layers', 'num_epoch', 'patience', 'lr', 'weight_decay', 'conv_type', 'eps', 'gamma','step_size', 'aggr', 'end'])\n","  df_wallet = pd.DataFrame(columns=['epoch', 'hidden_channels', 'out_channels', 'num_layers', 'num_epoch', 'patience', 'lr', 'weight_decay', 'conv_type', 'eps', 'gamma','step_size', 'aggr', 'end'])\n","\n","  # Salva i DataFrame come file CSV\n","  df_tx.to_csv(FILEPATH_TX, index=False)\n","  df_wallet.to_csv(FILEPATH_WALLET, index=False)\n","\n","#create_df()"]},{"cell_type":"markdown","metadata":{"id":"W1Syx8hzDPvM"},"source":["##Carica dati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qobTcbrVqpwG"},"outputs":[],"source":["def load_data():\n","    # Loading transactions\n","\n","    #Reading edges, features and classes from transaction files (as done with the original dataset)\n","    df_edges_tx = pd.read_csv(osp.join(base_path, \"txs_edgelist.csv\"))\n","    df_features_tx = pd.read_csv(osp.join(base_path, \"txs_features.csv\"), header=None)\n","    df_classes_tx = pd.read_csv(osp.join(base_path, \"txs_classes.csv\"))\n","\n","    #Columns naming based on index\n","    colNames1_tx = {'0': 'txId', 1: \"Time step\"}\n","    colNames2_tx = {str(ii+2): \"Local_feature_\" + str(ii+1) for ii in range(94)}\n","    colNames3_tx = {str(ii+96): \"Aggregate_feature_\" + str(ii+1) for ii in range(72)}\n","\n","    colNames_tx = dict(colNames1_tx, **colNames2_tx, **colNames3_tx)\n","    colNames_tx = {int(jj): item_kk for jj, item_kk in colNames_tx.items()}\n","\n","    # Rename feature columns\n","    df_features_tx = df_features_tx.rename(columns=colNames_tx)\n","\n","    # Map unknown class to '3'\n","    df_classes_tx.loc[df_classes_tx['class'] == 'unknown', 'class'] = '3'\n","\n","    # Merge classes and features in one Dataframe\n","    df_class_feature_tx = pd.merge(df_classes_tx, df_features_tx)\n","\n","    # Exclude records with unknown class transaction\n","    df_class_feature_tx = df_class_feature_tx[df_class_feature_tx['class'] != 3]\n","\n","    # Build Dataframe with head and tail of transactions (edges)\n","    known_txs = df_class_feature_tx[\"txId\"].values\n","    df_edges_tx = df_edges_tx[(df_edges_tx[\"txId1\"].isin(known_txs)) & (df_edges_tx[\"txId2\"].isin(known_txs))]\n","\n","    # Build indices for features and edge types\n","    features_idx_tx = {name: idx for idx, name in enumerate(sorted(df_class_feature_tx[\"txId\"].unique()))}\n","    class_idx_tx = {name: idx for idx, name in enumerate(sorted(df_class_feature_tx[\"class\"].unique()))}\n","\n","    # Apply index encoding to features\n","    df_class_feature_tx[\"txId\"] = df_class_feature_tx[\"txId\"].apply(lambda name: features_idx_tx[name])\n","    df_class_feature_tx[\"class\"] = df_class_feature_tx[\"class\"].apply(lambda name: class_idx_tx[name])\n","\n","    # Apply index encoding to edges\n","    df_edges_tx[\"txId1\"] = df_edges_tx[\"txId1\"].apply(lambda name: features_idx_tx[name])\n","    df_edges_tx[\"txId2\"] = df_edges_tx[\"txId2\"].apply(lambda name: features_idx_tx[name])\n","\n","    # Loading wallets\n","\n","    # From file\n","    df_edges_wallet = pd.read_csv(osp.join(base_path, \"AddrAddr_edgelist.csv\"))\n","    df_class_feature_wallet = pd.read_csv(osp.join(base_path, \"wallets_features_classes_combined.csv\"))\n","\n","    # Exclude records with unknown class transaction\n","    #print(df_class_feature_wallet.shape)\n","    df_class_feature_wallet = df_class_feature_wallet[df_class_feature_wallet[\"class\"] != 3]\n","    #print(df_class_feature_wallet.shape)\n","\n","    # Build Dataframe with head and tail of AddrToAddr (edges)\n","    known_wallets = df_class_feature_wallet[\"address\"].values\n","    df_edges_wallet = df_edges_wallet[(df_edges_wallet[\"input_address\"].isin(known_wallets)) & (df_edges_wallet[\"output_address\"].isin(known_wallets))]\n","\n","    # Building indices for features and edge types\n","    features_idx_wallet = {name: idx for idx, name in enumerate(sorted(df_class_feature_wallet[\"address\"].unique()))}\n","    class_idx_wallet = {name: idx for idx, name in enumerate(sorted(df_class_feature_wallet[\"class\"].unique()))}\n","\n","    # Apply index encoding to features\n","    df_class_feature_wallet[\"address\"] = df_class_feature_wallet[\"address\"].apply(lambda name: features_idx_wallet[name])\n","    df_class_feature_wallet[\"class\"] = df_class_feature_wallet[\"class\"].apply(lambda name: class_idx_wallet[name])\n","\n","    # Apply index encoding to edges\n","    df_edges_wallet[\"input_address\"] = df_edges_wallet[\"input_address\"].apply(lambda name: features_idx_wallet[name])\n","    df_edges_wallet[\"output_address\"] = df_edges_wallet[\"output_address\"].apply(lambda name: features_idx_wallet[name])\n","\n","    # Loading AddrTx and TxAddr\n","\n","    # From file\n","    df_edges_wallet_tx = pd.read_csv(osp.join(base_path, \"AddrTx_edgelist.csv\"))\n","    df_edges_tx_wallet = pd.read_csv(osp.join(base_path, \"TxAddr_edgelist.csv\"))\n","\n","    # Build Dataframe with head and tail of AddrTx (edges)\n","    df_edges_wallet_tx = df_edges_wallet_tx[(df_edges_wallet_tx[\"input_address\"].isin(known_wallets)) & df_edges_wallet_tx[\"txId\"].isin(known_txs)]\n","    df_edges_tx_wallet = df_edges_tx_wallet[(df_edges_tx_wallet[\"txId\"].isin(known_txs)) & df_edges_tx_wallet[\"output_address\"].isin(known_wallets)]\n","\n","    # Apply index encoding to edges\n","    df_edges_wallet_tx[\"input_address\"] = df_edges_wallet_tx[\"input_address\"].apply(lambda name: features_idx_wallet[name])\n","    df_edges_wallet_tx[\"txId\"] = df_edges_wallet_tx[\"txId\"].apply(lambda name: features_idx_tx[name])\n","    df_edges_tx_wallet[\"txId\"] = df_edges_tx_wallet[\"txId\"].apply(lambda name: features_idx_tx[name])\n","    df_edges_tx_wallet[\"output_address\"] = df_edges_tx_wallet[\"output_address\"].apply(lambda name: features_idx_wallet[name])\n","\n","    return df_class_feature_tx, df_edges_tx, df_class_feature_wallet, df_edges_wallet, df_edges_wallet_tx, df_edges_tx_wallet, features_idx_tx, features_idx_wallet\n","\n","def data_to_pyg(df_class_feature_tx, df_edges_tx, df_class_feature_wallet, df_edges_wallet, df_edges_wallet_tx, df_edges_tx_wallet, features_idx_tx, features_idx_wallet):\n","    data = HeteroData()\n","\n","    # Defining PyG objects for transactions\n","    df_class_feature_tx = df_class_feature_tx.fillna(0)\n","    data['tx'].x = torch.tensor(df_class_feature_tx.iloc[:, 3:].values, dtype=torch.float)\n","    data['tx'].y = torch.tensor(df_class_feature_tx[\"class\"].values, dtype=torch.long)\n","    data['tx','is_related_to','tx'].edge_index = torch.tensor([df_edges_tx[\"txId1\"].values,\n","                            df_edges_tx[\"txId2\"].values], dtype=torch.int64)\n","    #data['tx'] = random_node_split(num_val=0.15, num_test=0.2)(data['tx'])\n","    # Defining PyG objects for wallets\n","    data['wallet'].x = torch.tensor(df_class_feature_wallet.iloc[:, 3:].values, dtype=torch.float)\n","    data['wallet'].y = torch.tensor(df_class_feature_wallet[\"class\"].values, dtype=torch.long)\n","    data['wallet','interacts_with','wallet'].edge_index = torch.tensor([df_edges_wallet[\"input_address\"].values,\n","                            df_edges_wallet[\"output_address\"].values], dtype=torch.int64)\n","    #data['wallet'] = random_node_split(num_val=0.15, num_test=0.2)(data['wallet'])\n","    # Defining PyG objects for cross-edges\n","    data['wallet','performs','tx'].edge_index = torch.tensor([df_edges_wallet_tx[\"input_address\"].values,\n","                                         df_edges_wallet_tx[\"txId\"].values], dtype=torch.int64)\n","\n","    data['tx', 'flows_into', 'wallet'].edge_index = torch.tensor([df_edges_tx_wallet[\"txId\"].values,\n","                                         df_edges_tx_wallet[\"output_address\"].values], dtype=torch.int64)\n","\n","    # Impostare il seed per la divisione del dataset\n","    return RandomNodeSplit(num_val=0.10, num_test=0.15)(data)"]},{"cell_type":"markdown","metadata":{"id":"OhFPkCpExzOL"},"source":["##Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQfEkZ1nx44T"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Do2dQUF-x7hj"},"outputs":[],"source":["#NEW -> SU RANGE\n","# Utility per conversione a tensor\n","def to_tensor(arr):\n","    return torch.tensor(arr, dtype=torch.float).to(device)\n","\n","def scale_features(data, method=\"standard\"):\n","  if method == 'no':\n","    return data\n","\n","  # Scaling per training\n","  data['tx'].x[data['tx'].train_mask] = to_tensor(\n","      scale_train_data(data['tx'].x[data['tx'].train_mask].cpu().numpy(), method, 'tx')\n","  )\n","  data['wallet'].x[data['wallet'].train_mask] = to_tensor(\n","      scale_train_data(data['wallet'].x[data['wallet'].train_mask].cpu().numpy(), method, 'wallet')\n","  )\n","\n","  # Scaling per validation\n","  data['tx'].x[data['tx'].val_mask] = to_tensor(scale_validation_data(data['tx'].x[data['tx'].val_mask].cpu().numpy(), method, 'tx'))\n","  data['wallet'].x[data['wallet'].val_mask] = to_tensor(scale_validation_data(data['wallet'].x[data['wallet'].val_mask].cpu().numpy(), method, 'wallet'))\n","\n","  data['tx'].x[data['tx'].test_mask] = to_tensor(scale_validation_data(data['tx'].x[data['tx'].test_mask].cpu().numpy(), method, 'tx'))\n","  data['wallet'].x[data['wallet'].test_mask] = to_tensor(scale_validation_data(data['wallet'].x[data['wallet'].test_mask].cpu().numpy(), method, 'wallet'))\n","  return data\n","\n","def scale_train_data(train, scaling_method, df):\n","\n","    if 'standard' in scaling_method:\n","        scaler = StandardScaler()\n","        scaled_train = scaler.fit_transform(train)  # Scala tutte le colonne\n","        joblib.dump(scaler, f\"scaler_standard_{df}.pkl\")\n","\n","        if 'l2' in scaling_method:\n","            norm = Normalizer(norm='l2')\n","            scaled_train = norm.fit_transform(scaled_train)\n","            joblib.dump(norm, f\"scaler_l2_{df}.pkl\")\n","    else:\n","        raise ValueError(f\"Metodo di scaling '{scaling_method}' non supportato.\")\n","\n","    return scaled_train\n","\n","def scale_validation_data(val, scaling_method, df):\n","\n","    if 'standard' in scaling_method:\n","        scaler = joblib.load(f\"scaler_standard_{df}.pkl\")\n","        scaled_val = scaler.transform(val)  # Scala tutte le colonne\n","\n","        if 'l2' in scaling_method:\n","            norm = joblib.load(f\"scaler_l2_{df}.pkl\")\n","            scaled_val = norm.transform(scaled_val)\n","    else:\n","        raise ValueError(f\"Metodo di scaling '{scaling_method}' non supportato.\")\n","\n","    return scaled_val"]},{"cell_type":"code","source":["def dimentional_reduction(data, dim_reduction, pca_threshold):\n","    if dim_reduction == 'no':\n","        return data\n","    elif dim_reduction == 'pca':\n","        data1 = copy.deepcopy(data)\n","\n","        transformed_tx_data = apply_pca_train(data['tx'].x[data['tx'].train_mask].cpu().numpy(), 'tx', pca_threshold)\n","        transformed_wallet_data = apply_pca_train(data['wallet'].x[data['wallet'].train_mask].cpu().numpy(), 'wallet', pca_threshold)\n","\n","        data1['tx'].x = torch.zeros((data['tx'].x.shape[0], transformed_tx_data.shape[1]), dtype=torch.float, device=device)\n","        data1['wallet'].x = torch.zeros((data['wallet'].x.shape[0], transformed_wallet_data.shape[1]), dtype=torch.float, device=device)\n","\n","        data1['tx'].x[data['tx'].train_mask] = to_tensor(transformed_tx_data)\n","        data1['wallet'].x[data['wallet'].train_mask] = to_tensor(transformed_wallet_data)\n","\n","        transformed_tx_data = apply_pca_validation(data['tx'].x[data['tx'].val_mask].cpu().numpy(), 'tx')\n","        transformed_wallet_data = apply_pca_validation(data['wallet'].x[data['wallet'].val_mask].cpu().numpy(), 'wallet')\n","        data1['tx'].x[data['tx'].val_mask] = to_tensor(transformed_tx_data)\n","        data1['wallet'].x[data['wallet'].val_mask] = to_tensor(transformed_wallet_data)\n","\n","        transformed_tx_data = apply_pca_validation(data['tx'].x[data['tx'].test_mask].cpu().numpy(), 'tx')\n","        transformed_wallet_data = apply_pca_validation(data['wallet'].x[data['wallet'].test_mask].cpu().numpy(), 'wallet')\n","        data1['tx'].x[data['tx'].test_mask] = to_tensor(transformed_tx_data)\n","        data1['wallet'].x[data['wallet'].test_mask] = to_tensor(transformed_wallet_data)\n","\n","        return data1\n","\n","def apply_pca_train(train, df, pca_threshold=0.99):\n","    pca = PCA(random_state=SEED)\n","    pca.fit(train)\n","\n","    # Selezione componenti principali\n","    cumulative_variance = pca.explained_variance_ratio_.cumsum()\n","    n_components = (cumulative_variance >= pca_threshold).argmax() + 1\n","\n","    pca = PCA(n_components=n_components, random_state=SEED)\n","    transformed_data = pca.fit_transform(train).astype(np.float32)\n","\n","    joblib.dump(pca, f\"pca_model_{df}.pkl\")\n","    print(f\"  Numero di componenti principali per {df}: {pca.n_components_}\")\n","\n","    return transformed_data\n","\n","def apply_pca_validation(val, df):\n","    pca = joblib.load(f\"pca_model_{df}.pkl\")\n","    transformed_data = pca.transform(val).astype(np.float32)\n","    return transformed_data"],"metadata":{"id":"PVRMmabn21eP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CaNNtrNLDSdI"},"source":["##Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbfXKtdynFBL"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear, Dropout\n","from torch_geometric.nn import HeteroConv, GATConv, SAGEConv, TransformerConv\n","import random\n","from itertools import product\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxfbqge_p64q"},"outputs":[],"source":["def set_seed(seed = 51):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # Per più GPU\n","\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    torch.use_deterministic_algorithms(True, warn_only=True)\n","\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    seed_everything(seed)\n","device = \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EiBF-BZYfq7b"},"outputs":[],"source":["class ResidualHeteroGNN(torch.nn.Module):\n","    def __init__(self, conv, hidden_channels=64, num_layers=2, aggr='sum', dropout_prob=0.5, out_channels=2, num_head=1):\n","        super().__init__()\n","        self.convs = torch.nn.ModuleList()\n","        self.skips = torch.nn.ModuleList()\n","        self.dropout = Dropout(p=dropout_prob)\n","        heads = num_head if conv == 'Transformer' else 1 # Define heads\n","\n","        for _ in range(num_layers):\n","            if conv == 'GAT':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads),\n","                    ('wallet', 'interacts_with', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads),\n","                    ('wallet', 'performs', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads),\n","                    ('tx', 'flows_into', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads)\n","                }, aggr=aggr)\n","            elif conv == 'SAGE':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'interacts_with', 'wallet'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'performs', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('tx', 'flows_into', 'wallet'): SAGEConv(-1, hidden_channels)\n","                }, aggr=aggr)\n","            elif conv == 'Transformer':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'interacts_with', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'performs', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('tx', 'flows_into', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads)\n","                }, aggr=aggr)\n","            else:\n","                raise ValueError(\"Invalid convolution type. Choose from ['GAT', 'SAGE', 'Transformer']\")\n","\n","            self.convs.append(conv_layer)\n","            self.skips.append(Linear(hidden_channels * heads, hidden_channels * heads)) # Fix: Linear layer expects the output of conv\n","\n","        # FIX: Modifica della dimensione di input dei layer lineari\n","        self.lin_tx = Linear(hidden_channels * heads, out_channels)\n","        self.lin_wallet = Linear(hidden_channels * heads, out_channels)\n","\n","    def forward(self, x_dict, edge_index_dict):\n","        for conv, skip in zip(self.convs, self.skips):\n","            x_dict_new = conv(x_dict, edge_index_dict)\n","            x_dict = {key: self.dropout(F.relu(x + skip(x_dict_new[key]))) for key, x in x_dict_new.items()}  # Residual + Dropout\n","        return self.lin_tx(x_dict['tx']), self.lin_wallet(x_dict['wallet'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdcebmslq5D0"},"outputs":[],"source":["class HeteroGNN(torch.nn.Module):\n","    def __init__(self, conv, hidden_channels=64, num_layers=2, aggr='sum', dropout_prob=0, out_channels=2, num_head=1):\n","        super().__init__()\n","        self.convs = torch.nn.ModuleList()\n","        self.dropout = Dropout(p=dropout_prob)\n","        heads = num_head if conv == 'Transformer' else 1  # Definiamo i heads solo se necessario\n","\n","        for _ in range(num_layers):\n","            if conv == 'GAT':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n","                    ('wallet', 'interacts_with', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n","                    ('wallet', 'performs', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n","                    ('tx', 'flows_into', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False)\n","                }, aggr=aggr)\n","            elif conv == 'SAGE':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'interacts_with', 'wallet'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'performs', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('tx', 'flows_into', 'wallet'): SAGEConv(-1, hidden_channels)\n","                }, aggr=aggr)\n","            elif conv == 'Transformer':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'interacts_with', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'performs', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('tx', 'flows_into', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads)\n","                }, aggr=aggr)\n","            else:\n","                raise ValueError(\"Invalid convolution type. Choose from ['GAT', 'SAGE', 'Transformer']\")\n","\n","            self.convs.append(conv_layer)\n","\n","        # FIX: Modifica della dimensione di input dei layer lineari\n","        self.lin_tx = Linear(hidden_channels * heads, out_channels)\n","        self.lin_wallet = Linear(hidden_channels * heads, out_channels)\n","\n","    def forward(self, x_dict, edge_index_dict):\n","        for conv in self.convs:\n","            x_dict = conv(x_dict, edge_index_dict)\n","            x_dict = {key: self.dropout(x.relu()) for key, x in x_dict.items()}\n","        return self.lin_tx(x_dict['tx']), self.lin_wallet(x_dict['wallet'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJEJVt5l04Eb"},"outputs":[],"source":["def is_combination_tested(filepath, new_row):\n","    existing_results = pd.read_csv(filepath)\n","\n","    # Identifica le colonne comuni tra il dataset e new_row\n","    dataset_columns = set(existing_results.columns)\n","    comparison_columns = [col for col in new_row.keys() if col not in ['end', 'num_epoch', 'epoch']]\n","\n","    # Filtra le combinazioni\n","    filtered_results = existing_results.copy()\n","    #filtered_results = filtered_results[filtered_results['end'] == True]\n","    filtered_results = filtered_results[filtered_results['num_epoch'] >= new_row['num_epoch']]\n","\n","    for col in comparison_columns:\n","        if col in dataset_columns:\n","            # Mantieni solo le righe in cui i valori corrispondono (o sono entrambi NaN)\n","            filtered_results = filtered_results[\n","                (filtered_results[col] == new_row[col]) | (pd.isna(filtered_results[col]) & pd.isna(new_row[col]))\n","            ]\n","\n","    return not filtered_results.empty\n","\n","def append_and_save_results(FILEPATH_TX, FILEPATH_WALLET, params_tx, params_wallet, end=False):\n","  def append_and_save_result(filepath, new_row, end=False):\n","    new_row['end'] = end\n","    # Leggi i risultati esistenti\n","    results_df = pd.read_csv(filepath)\n","    results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n","    results_df.to_csv(filepath, index=False)\n","\n","  append_and_save_result(FILEPATH_TX, params_tx, end)\n","  append_and_save_result(FILEPATH_WALLET, params_wallet, end)\n","  if end:\n","    df_comb = pd.read_csv(path_comb)\n","    filtered_params = {key: params_tx[key] for key in params_tx if \"train\" not in key and \"val\" not in key}\n","    print(filtered_params)\n","    df_comb = pd.concat([df_comb, pd.DataFrame([filtered_params])], ignore_index=True)\n","    df_comb.to_csv(path_comb, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vo1zTF6zxQR"},"outputs":[],"source":["def compute_class_weights(data):\n","    class_counts = torch.bincount(data['tx'].y)\n","    weights = 1.0 / class_counts.float()\n","    weights /= weights.sum()\n","    return weights\n","\n","def eval(model, data, out_tx, out_wallet, params):\n","\n","  class_weights = compute_class_weights(data)\n","  criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n","\n","  model.eval()  # Imposta il modello in modalità di valutazione\n","\n","  tx_mask = data['tx'].train_mask\n","  wallet_mask = data['wallet'].train_mask\n","  tx_mask_val =  data['tx'].val_mask\n","  wallet_mask_val = data['wallet'].val_mask\n","\n","  params_tx = copy.copy(params)\n","  params_wallet = copy.copy(params)\n","\n","  # Calculate metrics for transactions\n","  params_tx['train_loss'] = criterion(out_tx[tx_mask], data['tx'].y[tx_mask].cpu())  # Convert to scalar\n","  params_tx['train_acc'] = accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_f1'] = f1_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  # Calculate metrics for wallets\n","  params_wallet['train_loss'] = criterion(out_wallet[wallet_mask], data['wallet'].y[wallet_mask].cpu())  # Convert to scalar\n","  params_wallet['train_acc'] = accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_f1'] = f1_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","\n","  loss = params_tx['train_loss'] + params_wallet['train_loss']\n","\n","  with torch.no_grad():\n","    params_tx['val_loss'] = criterion(out_tx[tx_mask_val], data['tx'].y[tx_mask_val].cpu())  # Convert to scalar\n","    params_tx['val_acc'] = accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_precision'] = precision_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_recall'] = recall_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_f1'] = f1_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","\n","    # Calculate metrics for wallets\n","    params_wallet['val_loss'] = criterion(out_wallet[wallet_mask_val], data['wallet'].y[wallet_mask_val].cpu())  # Convert to scalar\n","    params_wallet['val_acc'] = accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_precision'] = precision_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_recall'] = recall_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_f1'] = f1_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","\n","    print(f\"Epoch {str(params['epoch']).zfill(3)}:      TX: Train Loss: {params_tx['train_loss']:.4f}, Acc: {params_tx['train_acc']:.4f}, F1: {params_tx['train_f1']:.4f} Bal: {params_tx['train_balanced_acc']:.4f} - Val Loss: {params_tx['val_loss']:.4f}, Accuracy: {params_tx['val_acc']:.4f}, F1: {params_tx['val_f1']:.4f} Bal: {params_tx['val_balanced_acc']:.4f}\")\n","    print(f\"           WALLETS: Train Loss: {params_wallet['train_loss']:.8f}, Acc: {params_wallet['train_acc']:.8f}, F1: {params_wallet['train_f1']:.8f} Bal: {params_wallet['train_balanced_acc']:.4f} - Val Loss: {params_wallet['val_loss']:.8f}, Accuracy: {params_wallet['val_acc']:.4f}, F1: {params_wallet['val_f1']:.4f} Bal: {params_wallet['val_balanced_acc']:.4f}\")\n","\n","  return loss, params_tx, params_wallet\n","\n","\n","def eval_total(model, data, out_tx, out_wallet, params, best_epoch):\n","\n","  class_weights = compute_class_weights(data)\n","  criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n","\n","  model.eval()  # Imposta il modello in modalitÃ  di valutazione\n","\n","  tx_mask = data['tx'].train_mask\n","  wallet_mask = data['wallet'].train_mask\n","  tx_mask_val =  data['tx'].val_mask\n","  wallet_mask_val = data['wallet'].val_mask\n","  tx_mask_test = data['tx'].test_mask\n","  wallet_mask_test = data['wallet'].test_mask\n","\n","  params_tx = copy.copy(params)\n","  params_wallet = copy.copy(params)\n","\n","  # Calculate metrics for transactions\n","  params_tx['train_loss'] = criterion(out_tx[tx_mask], data['tx'].y[tx_mask].cpu())  # Convert to scalar\n","  params_tx['train_acc'] = accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_f1'] = f1_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  # Calculate metrics for wallets\n","  params_wallet['train_loss'] = criterion(out_wallet[wallet_mask], data['wallet'].y[wallet_mask].cpu())  # Convert to scalar\n","  params_wallet['train_acc'] = accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_f1'] = f1_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","\n","  with torch.no_grad():\n","    # Calculate metrics for validation\n","    params_tx['val_loss'] = criterion(out_tx[tx_mask_val], data['tx'].y[tx_mask_val].cpu())  # Convert to scalar\n","    params_tx['val_acc'] = accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_precision'] = precision_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_recall'] = recall_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_f1'] = f1_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    report_tx_val = classification_report(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","\n","    params_wallet['val_loss'] = criterion(out_wallet[wallet_mask_val], data['wallet'].y[wallet_mask_val].cpu())  # Convert to scalar\n","    params_wallet['val_acc'] = accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_precision'] = precision_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_recall'] = recall_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_f1'] = f1_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    report_wallet_val = classification_report(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","\n","    # Calculate metrics for test\n","    params_tx['test_loss'] = criterion(out_tx[tx_mask_test], data['tx'].y[tx_mask_test].cpu())  # Convert to scalar\n","    params_tx['test_acc'] = accuracy_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_precision'] = precision_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_recall'] = recall_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_f1'] = f1_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    report_tx_test = classification_report(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","\n","    params_wallet['test_loss'] = criterion(out_wallet[wallet_mask_test], data['wallet'].y[wallet_mask_test].cpu())  # Convert to scalar\n","    params_wallet['test_acc'] = accuracy_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_precision'] = precision_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_recall'] = recall_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_f1'] = f1_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    report_wallet_test = classification_report(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","\n","    # Stampa delle metriche con formattazione migliorata\n","    print('Final_result for '+type_classification)\n","    print(params)\n","    print(f\"Epoch {best_epoch}:\")\n","    print(\"  TX:\")\n","    print(f\"   Train: Loss={params_tx['train_loss']:.4f}, Acc={params_tx['train_acc']:.4f}, F1={params_tx['train_f1']:.4f}, Bal. Acc={params_tx['train_balanced_acc']:.4f}\")\n","    print(f\"   Val:   Loss={params_tx['val_loss']:.4f}, Acc={params_tx['val_acc']:.4f}, F1={params_tx['val_f1']:.4f}, Bal. Acc={params_tx['val_balanced_acc']:.4f}\")\n","    print(f\"   Test:  Loss={params_tx['test_loss']:.4f}, Acc={params_tx['test_acc']:.4f}, F1={params_tx['test_f1']:.4f}, Bal. Acc={params_tx['test_balanced_acc']:.4f}\")\n","    print(report_tx_val)\n","    print(report_tx_test)\n","    print(\"  WALLETS:\")\n","    print(f\"   Train: Loss={params_wallet['train_loss']:.8f}, Acc={params_wallet['train_acc']:.8f}, F1={params_wallet['train_f1']:.8f}, Bal. Acc={params_wallet['train_balanced_acc']:.4f}\")\n","    print(f\"   Val:   Loss={params_wallet['val_loss']:.8f}, Acc={params_wallet['val_acc']:.4f}, F1={params_wallet['val_f1']:.4f}, Bal. Acc={params_wallet['val_balanced_acc']:.4f}\")\n","    print(f\"   Test:  Loss={params_wallet['test_loss']:.8f}, Acc={params_wallet['test_acc']:.4f}, F1={params_wallet['test_f1']:.4f}, Bal. Acc={params_wallet['test_balanced_acc']:.4f}\")\n","    print(report_wallet_val)\n","    print(report_wallet_test)\n","    print()\n","\n","def compute_class_weights(data):\n","    class_counts = torch.bincount(data['tx'].y)\n","    weights = 1.0 / class_counts.float()\n","    weights /= weights.sum()\n","    return weights\n","\n","def train(model, data, params):\n","    best_model = None\n","    best_epoch = None\n","\n","    if params['optimizer'] == 'Adam':\n","      optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n","    elif params['optimizer'] == 'AdamW':\n","      optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n","    else:\n","      optimizer = None\n","\n","    if params['lr_scheduler'] == 'ReduceLROnPlateau':\n","      scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=params['factor'], patience=params['p'])\n","    elif params['lr_scheduler'] == 'CosineAnnealingLR':\n","      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=params['T_max'], eta_min=params['eta_min'])\n","    elif params['lr_scheduler'] == 'StepLR':\n","      scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=params['step_size'], gamma=params['gamma'])\n","    else:\n","      scheduler = None\n","\n","    print(f'Combinazione: {params}')\n","    model.train()\n","    tx_mask = data['tx'].train_mask\n","    wallet_mask = data['wallet'].train_mask\n","    tx_mask_val =  data['tx'].val_mask\n","    wallet_mask_val = data['wallet'].val_mask\n","\n","    best_val_tx_acc = 0\n","    best_val_wallet_acc = 0\n","\n","    best_val_tx_loss = float('inf')\n","    best_val_wallet_loss = float('inf')\n","    patience = params['patience']\n","    epochs_since_best = 0\n","\n","    for epoch in range(params['num_epoch']):\n","        params['epoch'] = epoch+1\n","        optimizer.zero_grad()\n","        out_tx, out_wallet = model(data.x_dict, data.edge_index_dict)\n","        loss, params_tx, params_wallet = eval(model, data, out_tx, out_wallet, params)\n","\n","        val_tx_loss = params_tx['val_loss']\n","        val_wallet_loss = params_wallet['val_loss']\n","        val_tx_acc = params_tx['val_balanced_acc']\n","        val_wallet_acc = params_wallet['val_balanced_acc']\n","\n","        # Check if validation loss has improved\n","        if val_tx_loss < best_val_tx_loss or val_wallet_loss < best_val_wallet_loss:\n","            best_val_tx_loss = val_tx_loss\n","            best_val_wallet_loss = val_wallet_loss\n","            epochs_since_best = 0\n","        else:\n","            epochs_since_best += 1\n","\n","        # Check if early stopping criteria is met\n","        if epochs_since_best >= patience:\n","            print(f'Early stopping at epoch {epoch}')\n","            append_and_save_results(FILEPATH_TX, FILEPATH_WALLET, params_tx, params_wallet, True)\n","            out_tx, out_wallet = best_model(data.x_dict, data.edge_index_dict)\n","            eval_total(best_model, data, out_tx, out_wallet, params, best_epoch)\n","            return best_model\n","\n","        if type_classification == 'w':\n","          if best_val_wallet_acc < val_wallet_acc:\n","            best_val_wallet_acc = val_wallet_acc\n","            best_model = copy.deepcopy(model)\n","            best_epoch = epoch+1\n","\n","        elif type_classification == 'tx':\n","          if best_val_tx_acc < val_tx_acc:\n","            best_val_tx_acc = val_tx_acc\n","            best_model = copy.deepcopy(model)\n","            best_epoch = epoch+1\n","\n","        else:\n","          print('Definisci modello da considerare')\n","          raise ValueError\n","\n","        loss.backward()\n","        optimizer.step()\n","        #scheduler.step()\n","        scheduler.step(loss)\n","\n","        append_and_save_results(FILEPATH_TX, FILEPATH_WALLET, params_tx, params_wallet, params['epoch']==params['num_epoch'])\n","\n","    out_tx, out_wallet = best_model(data.x_dict, data.edge_index_dict)\n","    eval_total(best_model, data, out_tx, out_wallet, params, best_epoch)\n","    return model\n","\n","\n","def train_grid(data_full, param_grid, scalers, dim_reductions, pca_thresholds):\n","    best_model = None\n","    best_f1 = 0\n","\n","    keys, values = zip(*param_grid.items())\n","    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n","    combination_counter = 0\n","    total_combinations = len(param_combinations) * len(scalers) * len(dim_reductions) * len(pca_thresholds)\n","\n","    for scaler in scalers:\n","      data = scale_features(data_full.clone(), scaler)\n","      for dim_reduction in dim_reductions:\n","        for pca_threshold in pca_thresholds:\n","          data = dimentional_reduction(data, dim_reduction, pca_threshold)\n","\n","          for params in param_combinations:\n","            combination_counter += 1\n","\n","            set_seed(SEED)\n","            params['scaler'] = scaler\n","            params['dim_reduction'] = dim_reduction # Fixed the typo here: 'dim_reduction' instead of 'dim_reducition'\n","\n","            if params['lr_scheduler'] != 'ReduceLROnPlateau':\n","              params['p'] = None\n","              params['factor'] = None\n","            elif params['lr_scheduler'] != 'CosineAnnealingLR':\n","              params['T_max'] = None\n","              params['eta_min'] = None\n","\n","            if params['conv_type'] != 'Transformer':\n","              params['num_head'] = None\n","\n","            if dim_reduction == 'no':\n","              params['pca_threshold'] = None\n","            else:\n","              params['pca_threshold'] = pca_threshold\n","\n","            if True: #not is_combination_tested(path_comb, params):\n","              print(f\"  Combinazione {combination_counter}/{total_combinations}\")  # Print the counter\n","              model = None\n","              if params[ 'type_model'] == 'HeteroGNN':\n","                model = HeteroGNN(params['conv_type'], hidden_channels = params['hidden_channels'], num_layers = params['num_layers'],\n","                                  aggr=params['aggr'], dropout_prob=params['dropout'], num_head=params['num_head'])\n","              elif params[ 'type_model'] == 'ResidualHeteroGNN':\n","                model = ResidualHeteroGNN(params['conv_type'], hidden_channels = params['hidden_channels'], num_layers = params['num_layers'],\n","                                  aggr=params['aggr'], dropout_prob=params['dropout'], num_head=params['num_head'])\n","              model = train(model, data, params)\n","            else:\n","              print(f\"  Configurazione {combination_counter}/{total_combinations} già testata, salto...\")\n","    return best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOYfyiGS4aMO"},"outputs":[],"source":["set_seed(SEED)\n","data = data_to_pyg(*load_data())"]},{"cell_type":"markdown","source":["# Risultati"],"metadata":{"id":"Zei3g85F7rVm"}},{"cell_type":"code","source":["hyperparams = {\n","    \"hidden_channels\": [32],\n","    'num_head': [3],\n","    \"num_layers\": [2],\n","    \"num_epoch\": [1000],\n","    \"patience\": [50],\n","    \"lr\": [0.001],\n","    \"weight_decay\": [0.0005],\n","    \"dropout\": [0],\n","    \"conv_type\": ['Transformer'],\n","    \"p\": [5],\n","    \"factor\": [0.5],\n","    \"eta_min\": ['/'],\n","    \"T_max\": ['/'],\n","    \"aggr\": ['mean'], #\n","    'lr_scheduler':['ReduceLROnPlateau'],\n","    'optimizer': ['Adam'],\n","    'type_model':['HeteroGNN'],\n","}\n","\n","scaler = ['standard_l2']\n","dim_reduction=['pca']\n","pca_threshold=[0.99]\n","best_model = train_grid(data, hyperparams, scaler, dim_reduction, pca_threshold)"],"metadata":{"id":"H2m9pT1kPQWq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743154282168,"user_tz":-60,"elapsed":10976803,"user":{"displayName":"comunità capi","userId":"08703040014020928057"}},"outputId":"e1498810-683f-4927-87cc-0bc99c2ef120"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Numero di componenti principali per tx: 73\n","  Numero di componenti principali per wallet: 22\n","  Combinazione 1/1\n","Combinazione: {'hidden_channels': 32, 'num_head': 3, 'num_layers': 2, 'num_epoch': 1000, 'patience': 50, 'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0, 'conv_type': 'Transformer', 'p': 5, 'factor': 0.5, 'eta_min': None, 'T_max': None, 'aggr': 'mean', 'lr_scheduler': 'ReduceLROnPlateau', 'optimizer': 'Adam', 'type_model': 'HeteroGNN', 'scaler': 'standard_l2', 'dim_reduction': 'pca', 'pca_threshold': 0.99}\n","Epoch 001:      TX: Train Loss: 0.6942, Acc: 0.6191, F1: 0.7555 Bal: 0.4804 - Val Loss: 0.6941, Accuracy: 0.6125, F1: 0.7506 Bal: 0.4717\n","           WALLETS: Train Loss: 0.68823326, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.68867201, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 002:      TX: Train Loss: 0.6927, Acc: 0.5263, F1: 0.6666 Bal: 0.5267 - Val Loss: 0.6927, Accuracy: 0.5195, F1: 0.6608 Bal: 0.5192\n","           WALLETS: Train Loss: 0.68612683, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.68662846, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 003:      TX: Train Loss: 0.6913, Acc: 0.4445, F1: 0.5718 Bal: 0.5738 - Val Loss: 0.6914, Accuracy: 0.4373, F1: 0.5646 Bal: 0.5668\n","           WALLETS: Train Loss: 0.68410403, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.68465745, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 004:      TX: Train Loss: 0.6900, Acc: 0.4073, F1: 0.5190 Bal: 0.6160 - Val Loss: 0.6901, Accuracy: 0.4022, F1: 0.5152 Bal: 0.6013\n","           WALLETS: Train Loss: 0.68212533, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.68272102, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 005:      TX: Train Loss: 0.6886, Acc: 0.4137, F1: 0.5235 Bal: 0.6371 - Val Loss: 0.6888, Accuracy: 0.4125, F1: 0.5242 Bal: 0.6267\n","           WALLETS: Train Loss: 0.68015629, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.68078679, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 006:      TX: Train Loss: 0.6871, Acc: 0.4499, F1: 0.5658 Bal: 0.6573 - Val Loss: 0.6874, Accuracy: 0.4434, F1: 0.5599 Bal: 0.6458\n","           WALLETS: Train Loss: 0.67815077, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.67881316, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 007:      TX: Train Loss: 0.6855, Acc: 0.4996, F1: 0.6204 Bal: 0.6805 - Val Loss: 0.6858, Accuracy: 0.4991, F1: 0.6213 Bal: 0.6718\n","           WALLETS: Train Loss: 0.67607558, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.67676222, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 008:      TX: Train Loss: 0.6838, Acc: 0.5522, F1: 0.6742 Bal: 0.7018 - Val Loss: 0.6841, Accuracy: 0.5535, F1: 0.6761 Bal: 0.6991\n","           WALLETS: Train Loss: 0.67389959, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.67460585, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 009:      TX: Train Loss: 0.6817, Acc: 0.6027, F1: 0.7218 Bal: 0.7231 - Val Loss: 0.6821, Accuracy: 0.6044, F1: 0.7237 Bal: 0.7225\n","           WALLETS: Train Loss: 0.67159152, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.67230946, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 010:      TX: Train Loss: 0.6795, Acc: 0.6493, F1: 0.7628 Bal: 0.7413 - Val Loss: 0.6799, Accuracy: 0.6531, F1: 0.7662 Bal: 0.7426\n","           WALLETS: Train Loss: 0.66914171, Acc: 0.92251564, F1: 0.95969637 Bal: 0.5000 - Val Loss: 0.66986483, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 011:      TX: Train Loss: 0.6769, Acc: 0.6890, F1: 0.7955 Bal: 0.7566 - Val Loss: 0.6775, Accuracy: 0.6959, F1: 0.8010 Bal: 0.7615\n","           WALLETS: Train Loss: 0.66653132, Acc: 0.92251201, F1: 0.95969441 Bal: 0.5000 - Val Loss: 0.66725373, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5000\n","Epoch 012:      TX: Train Loss: 0.6741, Acc: 0.7210, F1: 0.8207 Bal: 0.7686 - Val Loss: 0.6747, Accuracy: 0.7288, F1: 0.8265 Bal: 0.7758\n","           WALLETS: Train Loss: 0.66372901, Acc: 0.92247573, F1: 0.95967203 Bal: 0.5004 - Val Loss: 0.66444153, Accuracy: 0.9209, F1: 0.9588 Bal: 0.5003\n","Epoch 013:      TX: Train Loss: 0.6709, Acc: 0.7460, F1: 0.8395 Bal: 0.7782 - Val Loss: 0.6715, Accuracy: 0.7567, F1: 0.8472 Bal: 0.7873\n","           WALLETS: Train Loss: 0.66070056, Acc: 0.92218545, F1: 0.95947024 Bal: 0.5065 - Val Loss: 0.66139847, Accuracy: 0.9205, F1: 0.9585 Bal: 0.5070\n","Epoch 014:      TX: Train Loss: 0.6673, Acc: 0.7648, F1: 0.8533 Bal: 0.7860 - Val Loss: 0.6681, Accuracy: 0.7778, F1: 0.8624 Bal: 0.7951\n","           WALLETS: Train Loss: 0.65741515, Acc: 0.92060347, F1: 0.95842548 Bal: 0.5311 - Val Loss: 0.65809530, Accuracy: 0.9199, F1: 0.9580 Bal: 0.5366\n","Epoch 015:      TX: Train Loss: 0.6633, Acc: 0.7798, F1: 0.8640 Bal: 0.7922 - Val Loss: 0.6642, Accuracy: 0.7931, F1: 0.8733 Bal: 0.7997\n","           WALLETS: Train Loss: 0.65385890, Acc: 0.91775156, F1: 0.95656256 Bal: 0.5691 - Val Loss: 0.65451652, Accuracy: 0.9171, F1: 0.9562 Bal: 0.5748\n","Epoch 016:      TX: Train Loss: 0.6589, Acc: 0.7902, F1: 0.8712 Bal: 0.7964 - Val Loss: 0.6599, Accuracy: 0.8023, F1: 0.8796 Bal: 0.8048\n","           WALLETS: Train Loss: 0.65002012, Acc: 0.91336483, F1: 0.95390710 Bal: 0.5949 - Val Loss: 0.65064955, Accuracy: 0.9121, F1: 0.9532 Bal: 0.5973\n","Epoch 017:      TX: Train Loss: 0.6540, Acc: 0.7970, F1: 0.8760 Bal: 0.7997 - Val Loss: 0.6551, Accuracy: 0.8065, F1: 0.8824 Bal: 0.8081\n","           WALLETS: Train Loss: 0.64587492, Acc: 0.90974369, F1: 0.95170287 Bal: 0.6142 - Val Loss: 0.64647382, Accuracy: 0.9082, F1: 0.9508 Bal: 0.6139\n","Epoch 018:      TX: Train Loss: 0.6486, Acc: 0.8015, F1: 0.8791 Bal: 0.8019 - Val Loss: 0.6499, Accuracy: 0.8102, F1: 0.8849 Bal: 0.8112\n","           WALLETS: Train Loss: 0.64141619, Acc: 0.90698611, F1: 0.94986300 Bal: 0.6447 - Val Loss: 0.64198041, Accuracy: 0.9067, F1: 0.9497 Bal: 0.6455\n","Epoch 019:      TX: Train Loss: 0.6427, Acc: 0.8044, F1: 0.8810 Bal: 0.8039 - Val Loss: 0.6441, Accuracy: 0.8111, F1: 0.8855 Bal: 0.8117\n","           WALLETS: Train Loss: 0.63663131, Acc: 0.90463128, F1: 0.94810170 Bal: 0.6884 - Val Loss: 0.63715774, Accuracy: 0.9049, F1: 0.9482 Bal: 0.6868\n","Epoch 020:      TX: Train Loss: 0.6363, Acc: 0.8061, F1: 0.8821 Bal: 0.8057 - Val Loss: 0.6378, Accuracy: 0.8109, F1: 0.8854 Bal: 0.8106\n","           WALLETS: Train Loss: 0.63151401, Acc: 0.89810017, F1: 0.94403303 Bal: 0.7155 - Val Loss: 0.63200313, Accuracy: 0.8978, F1: 0.9438 Bal: 0.7146\n","Epoch 021:      TX: Train Loss: 0.6293, Acc: 0.8084, F1: 0.8837 Bal: 0.8081 - Val Loss: 0.6310, Accuracy: 0.8129, F1: 0.8867 Bal: 0.8107\n","           WALLETS: Train Loss: 0.62607139, Acc: 0.89129693, F1: 0.93986008 Bal: 0.7307 - Val Loss: 0.62652546, Accuracy: 0.8910, F1: 0.9396 Bal: 0.7312\n","Epoch 022:      TX: Train Loss: 0.6217, Acc: 0.8113, F1: 0.8856 Bal: 0.8101 - Val Loss: 0.6236, Accuracy: 0.8153, F1: 0.8884 Bal: 0.8110\n","           WALLETS: Train Loss: 0.62029636, Acc: 0.88541893, F1: 0.93624796 Bal: 0.7403 - Val Loss: 0.62071604, Accuracy: 0.8845, F1: 0.9357 Bal: 0.7396\n","Epoch 023:      TX: Train Loss: 0.6135, Acc: 0.8135, F1: 0.8871 Bal: 0.8119 - Val Loss: 0.6156, Accuracy: 0.8194, F1: 0.8912 Bal: 0.8133\n","           WALLETS: Train Loss: 0.61420041, Acc: 0.88263958, F1: 0.93445224 Bal: 0.7508 - Val Loss: 0.61458457, Accuracy: 0.8820, F1: 0.9340 Bal: 0.7513\n","Epoch 024:      TX: Train Loss: 0.6047, Acc: 0.8167, F1: 0.8893 Bal: 0.8132 - Val Loss: 0.6070, Accuracy: 0.8225, F1: 0.8932 Bal: 0.8160\n","           WALLETS: Train Loss: 0.60779375, Acc: 0.88089796, F1: 0.93334389 Bal: 0.7555 - Val Loss: 0.60814399, Accuracy: 0.8802, F1: 0.9329 Bal: 0.7550\n","Epoch 025:      TX: Train Loss: 0.5953, Acc: 0.8205, F1: 0.8918 Bal: 0.8156 - Val Loss: 0.5977, Accuracy: 0.8267, F1: 0.8960 Bal: 0.8183\n","           WALLETS: Train Loss: 0.60106993, Acc: 0.87951554, F1: 0.93242875 Bal: 0.7617 - Val Loss: 0.60138583, Accuracy: 0.8788, F1: 0.9319 Bal: 0.7607\n","Epoch 026:      TX: Train Loss: 0.5852, Acc: 0.8246, F1: 0.8945 Bal: 0.8177 - Val Loss: 0.5879, Accuracy: 0.8297, F1: 0.8981 Bal: 0.8181\n","           WALLETS: Train Loss: 0.59405106, Acc: 0.87734939, F1: 0.93107604 Bal: 0.7647 - Val Loss: 0.59433138, Accuracy: 0.8766, F1: 0.9306 Bal: 0.7641\n","Epoch 027:      TX: Train Loss: 0.5746, Acc: 0.8277, F1: 0.8966 Bal: 0.8189 - Val Loss: 0.5775, Accuracy: 0.8333, F1: 0.9004 Bal: 0.8200\n","           WALLETS: Train Loss: 0.58676851, Acc: 0.87638786, F1: 0.93044082 Bal: 0.7685 - Val Loss: 0.58701462, Accuracy: 0.8759, F1: 0.9301 Bal: 0.7677\n","Epoch 028:      TX: Train Loss: 0.5635, Acc: 0.8301, F1: 0.8982 Bal: 0.8191 - Val Loss: 0.5666, Accuracy: 0.8359, F1: 0.9021 Bal: 0.8225\n","           WALLETS: Train Loss: 0.57924873, Acc: 0.87553882, F1: 0.92985534 Bal: 0.7736 - Val Loss: 0.57946151, Accuracy: 0.8754, F1: 0.9297 Bal: 0.7726\n","Epoch 029:      TX: Train Loss: 0.5519, Acc: 0.8326, F1: 0.8999 Bal: 0.8201 - Val Loss: 0.5552, Accuracy: 0.8379, F1: 0.9034 Bal: 0.8226\n","           WALLETS: Train Loss: 0.57152557, Acc: 0.87445756, F1: 0.92917383 Bal: 0.7752 - Val Loss: 0.57170248, Accuracy: 0.8742, F1: 0.9290 Bal: 0.7727\n","Epoch 030:      TX: Train Loss: 0.5398, Acc: 0.8343, F1: 0.9010 Bal: 0.8210 - Val Loss: 0.5434, Accuracy: 0.8407, F1: 0.9052 Bal: 0.8242\n","           WALLETS: Train Loss: 0.56363255, Acc: 0.87361940, F1: 0.92863363 Bal: 0.7772 - Val Loss: 0.56377423, Accuracy: 0.8735, F1: 0.9285 Bal: 0.7746\n","Epoch 031:      TX: Train Loss: 0.5274, Acc: 0.8363, F1: 0.9023 Bal: 0.8221 - Val Loss: 0.5312, Accuracy: 0.8423, F1: 0.9062 Bal: 0.8250\n","           WALLETS: Train Loss: 0.55560470, Acc: 0.87288646, F1: 0.92814495 Bal: 0.7801 - Val Loss: 0.55570978, Accuracy: 0.8729, F1: 0.9280 Bal: 0.7798\n","Epoch 032:      TX: Train Loss: 0.5147, Acc: 0.8376, F1: 0.9031 Bal: 0.8234 - Val Loss: 0.5187, Accuracy: 0.8442, F1: 0.9075 Bal: 0.8271\n","           WALLETS: Train Loss: 0.54749817, Acc: 0.87170360, F1: 0.92740960 Bal: 0.7807 - Val Loss: 0.54756218, Accuracy: 0.8716, F1: 0.9273 Bal: 0.7798\n","Epoch 033:      TX: Train Loss: 0.5018, Acc: 0.8392, F1: 0.9041 Bal: 0.8253 - Val Loss: 0.5059, Accuracy: 0.8440, F1: 0.9074 Bal: 0.8270\n","           WALLETS: Train Loss: 0.53937531, Acc: 0.87107952, F1: 0.92700135 Bal: 0.7825 - Val Loss: 0.53939694, Accuracy: 0.8709, F1: 0.9268 Bal: 0.7820\n","Epoch 034:      TX: Train Loss: 0.4887, Acc: 0.8406, F1: 0.9050 Bal: 0.8270 - Val Loss: 0.4930, Accuracy: 0.8458, F1: 0.9085 Bal: 0.8280\n","           WALLETS: Train Loss: 0.53130901, Acc: 0.87017242, F1: 0.92642484 Bal: 0.7838 - Val Loss: 0.53128201, Accuracy: 0.8702, F1: 0.9264 Bal: 0.7821\n","Epoch 035:      TX: Train Loss: 0.4756, Acc: 0.8419, F1: 0.9059 Bal: 0.8290 - Val Loss: 0.4800, Accuracy: 0.8471, F1: 0.9093 Bal: 0.8307\n","           WALLETS: Train Loss: 0.52337289, Acc: 0.86937780, F1: 0.92589421 Bal: 0.7866 - Val Loss: 0.52329373, Accuracy: 0.8695, F1: 0.9259 Bal: 0.7862\n","Epoch 036:      TX: Train Loss: 0.4625, Acc: 0.8428, F1: 0.9064 Bal: 0.8302 - Val Loss: 0.4671, Accuracy: 0.8480, F1: 0.9098 Bal: 0.8321\n","           WALLETS: Train Loss: 0.51563972, Acc: 0.86810786, F1: 0.92509325 Bal: 0.7878 - Val Loss: 0.51550841, Accuracy: 0.8686, F1: 0.9253 Bal: 0.7885\n","Epoch 037:      TX: Train Loss: 0.4496, Acc: 0.8441, F1: 0.9073 Bal: 0.8324 - Val Loss: 0.4543, Accuracy: 0.8484, F1: 0.9101 Bal: 0.8334\n","           WALLETS: Train Loss: 0.50817883, Acc: 0.86725882, F1: 0.92455072 Bal: 0.7890 - Val Loss: 0.50799650, Accuracy: 0.8679, F1: 0.9248 Bal: 0.7900\n","Epoch 038:      TX: Train Loss: 0.4370, Acc: 0.8456, F1: 0.9082 Bal: 0.8340 - Val Loss: 0.4417, Accuracy: 0.8488, F1: 0.9104 Bal: 0.8336\n","           WALLETS: Train Loss: 0.50106585, Acc: 0.86553170, F1: 0.92347244 Bal: 0.7895 - Val Loss: 0.50083792, Accuracy: 0.8660, F1: 0.9237 Bal: 0.7896\n","Epoch 039:      TX: Train Loss: 0.4246, Acc: 0.8467, F1: 0.9089 Bal: 0.8353 - Val Loss: 0.4294, Accuracy: 0.8493, F1: 0.9107 Bal: 0.8338\n","           WALLETS: Train Loss: 0.49436140, Acc: 0.86504550, F1: 0.92315385 Bal: 0.7906 - Val Loss: 0.49409714, Accuracy: 0.8656, F1: 0.9234 Bal: 0.7919\n","Epoch 040:      TX: Train Loss: 0.4127, Acc: 0.8477, F1: 0.9095 Bal: 0.8370 - Val Loss: 0.4175, Accuracy: 0.8502, F1: 0.9112 Bal: 0.8373\n","           WALLETS: Train Loss: 0.48811966, Acc: 0.86479151, F1: 0.92296083 Bal: 0.7930 - Val Loss: 0.48782733, Accuracy: 0.8650, F1: 0.9230 Bal: 0.7927\n","Epoch 041:      TX: Train Loss: 0.4013, Acc: 0.8488, F1: 0.9102 Bal: 0.8394 - Val Loss: 0.4059, Accuracy: 0.8517, F1: 0.9121 Bal: 0.8391\n","           WALLETS: Train Loss: 0.48237976, Acc: 0.86400415, F1: 0.92244792 Bal: 0.7946 - Val Loss: 0.48206463, Accuracy: 0.8641, F1: 0.9224 Bal: 0.7928\n","Epoch 042:      TX: Train Loss: 0.3903, Acc: 0.8499, F1: 0.9108 Bal: 0.8418 - Val Loss: 0.3949, Accuracy: 0.8517, F1: 0.9120 Bal: 0.8440\n","           WALLETS: Train Loss: 0.47717208, Acc: 0.86302448, F1: 0.92183815 Bal: 0.7945 - Val Loss: 0.47683814, Accuracy: 0.8634, F1: 0.9220 Bal: 0.7934\n","Epoch 043:      TX: Train Loss: 0.3800, Acc: 0.8513, F1: 0.9117 Bal: 0.8447 - Val Loss: 0.3844, Accuracy: 0.8532, F1: 0.9130 Bal: 0.8449\n","           WALLETS: Train Loss: 0.47252402, Acc: 0.86232783, F1: 0.92139375 Bal: 0.7952 - Val Loss: 0.47217178, Accuracy: 0.8621, F1: 0.9212 Bal: 0.7929\n","Epoch 044:      TX: Train Loss: 0.3703, Acc: 0.8530, F1: 0.9127 Bal: 0.8467 - Val Loss: 0.3745, Accuracy: 0.8543, F1: 0.9137 Bal: 0.8474\n","           WALLETS: Train Loss: 0.46843386, Acc: 0.86093453, F1: 0.92053336 Bal: 0.7945 - Val Loss: 0.46806920, Accuracy: 0.8610, F1: 0.9205 Bal: 0.7927\n","Epoch 045:      TX: Train Loss: 0.3611, Acc: 0.8543, F1: 0.9136 Bal: 0.8499 - Val Loss: 0.3651, Accuracy: 0.8545, F1: 0.9138 Bal: 0.8495\n","           WALLETS: Train Loss: 0.46487975, Acc: 0.86116675, F1: 0.92057119 Bal: 0.8015 - Val Loss: 0.46450800, Accuracy: 0.8612, F1: 0.9205 Bal: 0.7988\n","Epoch 046:      TX: Train Loss: 0.3526, Acc: 0.8565, F1: 0.9150 Bal: 0.8526 - Val Loss: 0.3562, Accuracy: 0.8561, F1: 0.9147 Bal: 0.8514\n","           WALLETS: Train Loss: 0.46183223, Acc: 0.85988592, F1: 0.91976130 Bal: 0.8020 - Val Loss: 0.46145716, Accuracy: 0.8599, F1: 0.9197 Bal: 0.7991\n","Epoch 047:      TX: Train Loss: 0.3447, Acc: 0.8581, F1: 0.9160 Bal: 0.8552 - Val Loss: 0.3480, Accuracy: 0.8583, F1: 0.9161 Bal: 0.8526\n","           WALLETS: Train Loss: 0.45924282, Acc: 0.85882280, F1: 0.91910222 Bal: 0.8015 - Val Loss: 0.45887092, Accuracy: 0.8584, F1: 0.9188 Bal: 0.7982\n","Epoch 048:      TX: Train Loss: 0.3374, Acc: 0.8594, F1: 0.9167 Bal: 0.8567 - Val Loss: 0.3403, Accuracy: 0.8602, F1: 0.9174 Bal: 0.8547\n","           WALLETS: Train Loss: 0.45705295, Acc: 0.85752384, F1: 0.91829877 Bal: 0.8007 - Val Loss: 0.45669055, Accuracy: 0.8570, F1: 0.9179 Bal: 0.7973\n","Epoch 049:      TX: Train Loss: 0.3307, Acc: 0.8617, F1: 0.9182 Bal: 0.8598 - Val Loss: 0.3331, Accuracy: 0.8618, F1: 0.9183 Bal: 0.8575\n","           WALLETS: Train Loss: 0.45519051, Acc: 0.85665665, F1: 0.91775512 Bal: 0.8006 - Val Loss: 0.45484054, Accuracy: 0.8560, F1: 0.9173 Bal: 0.7971\n","Epoch 050:      TX: Train Loss: 0.3245, Acc: 0.8638, F1: 0.9195 Bal: 0.8619 - Val Loss: 0.3264, Accuracy: 0.8633, F1: 0.9193 Bal: 0.8593\n","           WALLETS: Train Loss: 0.45359597, Acc: 0.85560442, F1: 0.91709581 Bal: 0.8003 - Val Loss: 0.45325965, Accuracy: 0.8548, F1: 0.9166 Bal: 0.7969\n","Epoch 051:      TX: Train Loss: 0.3188, Acc: 0.8659, F1: 0.9208 Bal: 0.8644 - Val Loss: 0.3202, Accuracy: 0.8670, F1: 0.9216 Bal: 0.8633\n","           WALLETS: Train Loss: 0.45219815, Acc: 0.85337658, F1: 0.91570327 Bal: 0.7995 - Val Loss: 0.45187238, Accuracy: 0.8528, F1: 0.9153 Bal: 0.7963\n","Epoch 052:      TX: Train Loss: 0.3136, Acc: 0.8681, F1: 0.9222 Bal: 0.8670 - Val Loss: 0.3145, Accuracy: 0.8686, F1: 0.9225 Bal: 0.8671\n","           WALLETS: Train Loss: 0.45093155, Acc: 0.85148619, F1: 0.91450855 Bal: 0.7993 - Val Loss: 0.45060855, Accuracy: 0.8509, F1: 0.9141 Bal: 0.7954\n","Epoch 053:      TX: Train Loss: 0.3088, Acc: 0.8695, F1: 0.9231 Bal: 0.8684 - Val Loss: 0.3092, Accuracy: 0.8710, F1: 0.9240 Bal: 0.8734\n","           WALLETS: Train Loss: 0.44973403, Acc: 0.85048838, F1: 0.91387642 Bal: 0.7993 - Val Loss: 0.44940111, Accuracy: 0.8498, F1: 0.9134 Bal: 0.7954\n","Epoch 054:      TX: Train Loss: 0.3044, Acc: 0.8706, F1: 0.9238 Bal: 0.8693 - Val Loss: 0.3043, Accuracy: 0.8730, F1: 0.9252 Bal: 0.8745\n","           WALLETS: Train Loss: 0.44855374, Acc: 0.84938535, F1: 0.91316772 Bal: 0.7998 - Val Loss: 0.44820109, Accuracy: 0.8487, F1: 0.9127 Bal: 0.7961\n","Epoch 055:      TX: Train Loss: 0.3003, Acc: 0.8727, F1: 0.9251 Bal: 0.8719 - Val Loss: 0.2998, Accuracy: 0.8752, F1: 0.9266 Bal: 0.8747\n","           WALLETS: Train Loss: 0.44735685, Acc: 0.84870321, F1: 0.91273100 Bal: 0.7999 - Val Loss: 0.44697508, Accuracy: 0.8477, F1: 0.9120 Bal: 0.7960\n","Epoch 056:      TX: Train Loss: 0.2966, Acc: 0.8745, F1: 0.9262 Bal: 0.8740 - Val Loss: 0.2956, Accuracy: 0.8765, F1: 0.9275 Bal: 0.8755\n","           WALLETS: Train Loss: 0.44613054, Acc: 0.84815532, F1: 0.91237628 Bal: 0.8003 - Val Loss: 0.44571221, Accuracy: 0.8475, F1: 0.9119 Bal: 0.7972\n","Epoch 057:      TX: Train Loss: 0.2932, Acc: 0.8761, F1: 0.9272 Bal: 0.8758 - Val Loss: 0.2918, Accuracy: 0.8769, F1: 0.9277 Bal: 0.8757\n","           WALLETS: Train Loss: 0.44487116, Acc: 0.84800293, F1: 0.91228100 Bal: 0.8002 - Val Loss: 0.44441232, Accuracy: 0.8475, F1: 0.9119 Bal: 0.7973\n","Epoch 058:      TX: Train Loss: 0.2900, Acc: 0.8777, F1: 0.9281 Bal: 0.8771 - Val Loss: 0.2883, Accuracy: 0.8787, F1: 0.9288 Bal: 0.8767\n","           WALLETS: Train Loss: 0.44357744, Acc: 0.84823515, F1: 0.91242491 Bal: 0.8004 - Val Loss: 0.44307250, Accuracy: 0.8479, F1: 0.9121 Bal: 0.7979\n","Epoch 059:      TX: Train Loss: 0.2870, Acc: 0.8787, F1: 0.9288 Bal: 0.8781 - Val Loss: 0.2850, Accuracy: 0.8789, F1: 0.9290 Bal: 0.8778\n","           WALLETS: Train Loss: 0.44226289, Acc: 0.84856170, F1: 0.91262981 Bal: 0.8006 - Val Loss: 0.44170395, Accuracy: 0.8479, F1: 0.9121 Bal: 0.7976\n","Epoch 060:      TX: Train Loss: 0.2842, Acc: 0.8800, F1: 0.9296 Bal: 0.8793 - Val Loss: 0.2820, Accuracy: 0.8802, F1: 0.9297 Bal: 0.8805\n","           WALLETS: Train Loss: 0.44094515, Acc: 0.84905154, F1: 0.91293884 Bal: 0.8007 - Val Loss: 0.44033059, Accuracy: 0.8484, F1: 0.9124 Bal: 0.7978\n","Epoch 061:      TX: Train Loss: 0.2816, Acc: 0.8814, F1: 0.9305 Bal: 0.8800 - Val Loss: 0.2793, Accuracy: 0.8813, F1: 0.9305 Bal: 0.8801\n","           WALLETS: Train Loss: 0.43963945, Acc: 0.84975907, F1: 0.91338372 Bal: 0.8010 - Val Loss: 0.43896949, Accuracy: 0.8493, F1: 0.9130 Bal: 0.7983\n","Epoch 062:      TX: Train Loss: 0.2791, Acc: 0.8821, F1: 0.9309 Bal: 0.8809 - Val Loss: 0.2768, Accuracy: 0.8822, F1: 0.9310 Bal: 0.8806\n","           WALLETS: Train Loss: 0.43836614, Acc: 0.85061538, F1: 0.91392132 Bal: 0.8014 - Val Loss: 0.43764347, Accuracy: 0.8499, F1: 0.9134 Bal: 0.7987\n","Epoch 063:      TX: Train Loss: 0.2767, Acc: 0.8831, F1: 0.9315 Bal: 0.8820 - Val Loss: 0.2744, Accuracy: 0.8833, F1: 0.9317 Bal: 0.8832\n","           WALLETS: Train Loss: 0.43713677, Acc: 0.85194337, F1: 0.91475213 Bal: 0.8021 - Val Loss: 0.43636352, Accuracy: 0.8511, F1: 0.9142 Bal: 0.7992\n","Epoch 064:      TX: Train Loss: 0.2744, Acc: 0.8845, F1: 0.9324 Bal: 0.8837 - Val Loss: 0.2723, Accuracy: 0.8857, F1: 0.9332 Bal: 0.8845\n","           WALLETS: Train Loss: 0.43595693, Acc: 0.85328950, F1: 0.91559439 Bal: 0.8027 - Val Loss: 0.43513301, Accuracy: 0.8528, F1: 0.9152 Bal: 0.7999\n","Epoch 065:      TX: Train Loss: 0.2722, Acc: 0.8856, F1: 0.9331 Bal: 0.8845 - Val Loss: 0.2703, Accuracy: 0.8866, F1: 0.9337 Bal: 0.8840\n","           WALLETS: Train Loss: 0.43482706, Acc: 0.85449413, F1: 0.91634786 Bal: 0.8032 - Val Loss: 0.43395001, Accuracy: 0.8540, F1: 0.9160 Bal: 0.8006\n","Epoch 066:      TX: Train Loss: 0.2701, Acc: 0.8865, F1: 0.9336 Bal: 0.8849 - Val Loss: 0.2685, Accuracy: 0.8870, F1: 0.9340 Bal: 0.8833\n","           WALLETS: Train Loss: 0.43375427, Acc: 0.85572053, F1: 0.91711309 Bal: 0.8038 - Val Loss: 0.43281978, Accuracy: 0.8554, F1: 0.9168 Bal: 0.8012\n","Epoch 067:      TX: Train Loss: 0.2680, Acc: 0.8871, F1: 0.9340 Bal: 0.8852 - Val Loss: 0.2668, Accuracy: 0.8885, F1: 0.9350 Bal: 0.8841\n","           WALLETS: Train Loss: 0.43273580, Acc: 0.85706303, F1: 0.91795139 Bal: 0.8043 - Val Loss: 0.43173853, Accuracy: 0.8567, F1: 0.9177 Bal: 0.8017\n","Epoch 068:      TX: Train Loss: 0.2660, Acc: 0.8874, F1: 0.9342 Bal: 0.8853 - Val Loss: 0.2652, Accuracy: 0.8888, F1: 0.9351 Bal: 0.8842\n","           WALLETS: Train Loss: 0.43176329, Acc: 0.85805358, F1: 0.91856866 Bal: 0.8047 - Val Loss: 0.43070170, Accuracy: 0.8581, F1: 0.9185 Bal: 0.8023\n","Epoch 069:      TX: Train Loss: 0.2640, Acc: 0.8883, F1: 0.9347 Bal: 0.8863 - Val Loss: 0.2637, Accuracy: 0.8907, F1: 0.9363 Bal: 0.8863\n","           WALLETS: Train Loss: 0.43082702, Acc: 0.85886997, F1: 0.91907490 Bal: 0.8051 - Val Loss: 0.42969856, Accuracy: 0.8588, F1: 0.9190 Bal: 0.8027\n","Epoch 070:      TX: Train Loss: 0.2621, Acc: 0.8895, F1: 0.9355 Bal: 0.8879 - Val Loss: 0.2623, Accuracy: 0.8916, F1: 0.9368 Bal: 0.8878\n","           WALLETS: Train Loss: 0.42991665, Acc: 0.85988592, F1: 0.91970724 Bal: 0.8055 - Val Loss: 0.42871961, Accuracy: 0.8600, F1: 0.9197 Bal: 0.8032\n","Epoch 071:      TX: Train Loss: 0.2603, Acc: 0.8907, F1: 0.9362 Bal: 0.8889 - Val Loss: 0.2609, Accuracy: 0.8936, F1: 0.9381 Bal: 0.8889\n","           WALLETS: Train Loss: 0.42902330, Acc: 0.86054992, F1: 0.92011880 Bal: 0.8058 - Val Loss: 0.42776033, Accuracy: 0.8607, F1: 0.9202 Bal: 0.8034\n","Epoch 072:      TX: Train Loss: 0.2585, Acc: 0.8916, F1: 0.9368 Bal: 0.8893 - Val Loss: 0.2596, Accuracy: 0.8949, F1: 0.9389 Bal: 0.8896\n","           WALLETS: Train Loss: 0.42814037, Acc: 0.86116675, F1: 0.92050155 Bal: 0.8060 - Val Loss: 0.42681038, Accuracy: 0.8612, F1: 0.9205 Bal: 0.8039\n","Epoch 073:      TX: Train Loss: 0.2567, Acc: 0.8923, F1: 0.9372 Bal: 0.8892 - Val Loss: 0.2584, Accuracy: 0.8960, F1: 0.9396 Bal: 0.8902\n","           WALLETS: Train Loss: 0.42725864, Acc: 0.86188517, F1: 0.92094578 Bal: 0.8064 - Val Loss: 0.42586014, Accuracy: 0.8619, F1: 0.9209 Bal: 0.8042\n","Epoch 074:      TX: Train Loss: 0.2550, Acc: 0.8934, F1: 0.9379 Bal: 0.8902 - Val Loss: 0.2572, Accuracy: 0.8973, F1: 0.9404 Bal: 0.8910\n","           WALLETS: Train Loss: 0.42636871, Acc: 0.86261448, F1: 0.92139473 Bal: 0.8069 - Val Loss: 0.42489898, Accuracy: 0.8627, F1: 0.9214 Bal: 0.8050\n","Epoch 075:      TX: Train Loss: 0.2533, Acc: 0.8941, F1: 0.9383 Bal: 0.8904 - Val Loss: 0.2560, Accuracy: 0.8969, F1: 0.9401 Bal: 0.8907\n","           WALLETS: Train Loss: 0.42547187, Acc: 0.86309705, F1: 0.92169051 Bal: 0.8073 - Val Loss: 0.42392802, Accuracy: 0.8628, F1: 0.9214 Bal: 0.8050\n","Epoch 076:      TX: Train Loss: 0.2516, Acc: 0.8953, F1: 0.9391 Bal: 0.8910 - Val Loss: 0.2548, Accuracy: 0.8986, F1: 0.9412 Bal: 0.8927\n","           WALLETS: Train Loss: 0.42456630, Acc: 0.86348892, F1: 0.92193184 Bal: 0.8075 - Val Loss: 0.42294672, Accuracy: 0.8632, F1: 0.9217 Bal: 0.8052\n","Epoch 077:      TX: Train Loss: 0.2499, Acc: 0.8967, F1: 0.9400 Bal: 0.8920 - Val Loss: 0.2536, Accuracy: 0.8993, F1: 0.9416 Bal: 0.8930\n","           WALLETS: Train Loss: 0.42365539, Acc: 0.86379008, F1: 0.92211651 Bal: 0.8077 - Val Loss: 0.42195871, Accuracy: 0.8639, F1: 0.9221 Bal: 0.8058\n","Epoch 078:      TX: Train Loss: 0.2483, Acc: 0.8975, F1: 0.9404 Bal: 0.8926 - Val Loss: 0.2524, Accuracy: 0.9000, F1: 0.9420 Bal: 0.8934\n","           WALLETS: Train Loss: 0.42274123, Acc: 0.86402229, F1: 0.92225799 Bal: 0.8080 - Val Loss: 0.42096740, Accuracy: 0.8644, F1: 0.9224 Bal: 0.8061\n","Epoch 079:      TX: Train Loss: 0.2466, Acc: 0.8987, F1: 0.9411 Bal: 0.8935 - Val Loss: 0.2511, Accuracy: 0.9006, F1: 0.9424 Bal: 0.8928\n","           WALLETS: Train Loss: 0.42182606, Acc: 0.86433796, F1: 0.92245440 Bal: 0.8080 - Val Loss: 0.41997203, Accuracy: 0.8646, F1: 0.9225 Bal: 0.8063\n","Epoch 080:      TX: Train Loss: 0.2450, Acc: 0.8995, F1: 0.9416 Bal: 0.8942 - Val Loss: 0.2499, Accuracy: 0.9011, F1: 0.9427 Bal: 0.8930\n","           WALLETS: Train Loss: 0.42091718, Acc: 0.86442504, F1: 0.92250450 Bal: 0.8083 - Val Loss: 0.41897854, Accuracy: 0.8646, F1: 0.9225 Bal: 0.8068\n","Epoch 081:      TX: Train Loss: 0.2434, Acc: 0.9003, F1: 0.9422 Bal: 0.8947 - Val Loss: 0.2486, Accuracy: 0.9024, F1: 0.9435 Bal: 0.8938\n","           WALLETS: Train Loss: 0.42001894, Acc: 0.86446496, F1: 0.92252522 Bal: 0.8086 - Val Loss: 0.41799009, Accuracy: 0.8646, F1: 0.9226 Bal: 0.8068\n","Epoch 082:      TX: Train Loss: 0.2418, Acc: 0.9010, F1: 0.9425 Bal: 0.8951 - Val Loss: 0.2473, Accuracy: 0.9035, F1: 0.9441 Bal: 0.8944\n","           WALLETS: Train Loss: 0.41913429, Acc: 0.86458107, F1: 0.92259641 Bal: 0.8087 - Val Loss: 0.41700718, Accuracy: 0.8646, F1: 0.9225 Bal: 0.8069\n","Epoch 083:      TX: Train Loss: 0.2403, Acc: 0.9021, F1: 0.9432 Bal: 0.8959 - Val Loss: 0.2460, Accuracy: 0.9039, F1: 0.9444 Bal: 0.8946\n","           WALLETS: Train Loss: 0.41827053, Acc: 0.86462823, F1: 0.92262449 Bal: 0.8088 - Val Loss: 0.41604438, Accuracy: 0.8648, F1: 0.9227 Bal: 0.8069\n","Epoch 084:      TX: Train Loss: 0.2387, Acc: 0.9029, F1: 0.9437 Bal: 0.8967 - Val Loss: 0.2446, Accuracy: 0.9052, F1: 0.9452 Bal: 0.8953\n","           WALLETS: Train Loss: 0.41742569, Acc: 0.86465001, F1: 0.92263597 Bal: 0.8089 - Val Loss: 0.41510016, Accuracy: 0.8648, F1: 0.9226 Bal: 0.8073\n","Epoch 085:      TX: Train Loss: 0.2371, Acc: 0.9035, F1: 0.9441 Bal: 0.8974 - Val Loss: 0.2432, Accuracy: 0.9063, F1: 0.9459 Bal: 0.8959\n","           WALLETS: Train Loss: 0.41659793, Acc: 0.86475523, F1: 0.92270045 Bal: 0.8090 - Val Loss: 0.41417548, Accuracy: 0.8648, F1: 0.9226 Bal: 0.8077\n","Epoch 086:      TX: Train Loss: 0.2356, Acc: 0.9043, F1: 0.9446 Bal: 0.8978 - Val Loss: 0.2419, Accuracy: 0.9068, F1: 0.9461 Bal: 0.8962\n","           WALLETS: Train Loss: 0.41578472, Acc: 0.86484594, F1: 0.92275277 Bal: 0.8093 - Val Loss: 0.41326591, Accuracy: 0.8650, F1: 0.9227 Bal: 0.8078\n","Epoch 087:      TX: Train Loss: 0.2341, Acc: 0.9053, F1: 0.9452 Bal: 0.8987 - Val Loss: 0.2405, Accuracy: 0.9076, F1: 0.9467 Bal: 0.8967\n","           WALLETS: Train Loss: 0.41498357, Acc: 0.86494028, F1: 0.92280893 Bal: 0.8094 - Val Loss: 0.41237006, Accuracy: 0.8650, F1: 0.9228 Bal: 0.8078\n","Epoch 088:      TX: Train Loss: 0.2325, Acc: 0.9064, F1: 0.9459 Bal: 0.8997 - Val Loss: 0.2392, Accuracy: 0.9085, F1: 0.9472 Bal: 0.8981\n","           WALLETS: Train Loss: 0.41419497, Acc: 0.86514710, F1: 0.92293720 Bal: 0.8095 - Val Loss: 0.41149017, Accuracy: 0.8654, F1: 0.9230 Bal: 0.8082\n","Epoch 089:      TX: Train Loss: 0.2310, Acc: 0.9073, F1: 0.9464 Bal: 0.9006 - Val Loss: 0.2378, Accuracy: 0.9096, F1: 0.9479 Bal: 0.8988\n","           WALLETS: Train Loss: 0.41341972, Acc: 0.86528135, F1: 0.92301791 Bal: 0.8097 - Val Loss: 0.41062886, Accuracy: 0.8658, F1: 0.9232 Bal: 0.8085\n","Epoch 090:      TX: Train Loss: 0.2295, Acc: 0.9084, F1: 0.9470 Bal: 0.9014 - Val Loss: 0.2364, Accuracy: 0.9098, F1: 0.9480 Bal: 0.8989\n","           WALLETS: Train Loss: 0.41265172, Acc: 0.86556799, F1: 0.92319620 Bal: 0.8097 - Val Loss: 0.40978172, Accuracy: 0.8660, F1: 0.9234 Bal: 0.8086\n","Epoch 091:      TX: Train Loss: 0.2281, Acc: 0.9093, F1: 0.9476 Bal: 0.9024 - Val Loss: 0.2351, Accuracy: 0.9107, F1: 0.9485 Bal: 0.8984\n","           WALLETS: Train Loss: 0.41189221, Acc: 0.86598888, F1: 0.92345602 Bal: 0.8099 - Val Loss: 0.40894935, Accuracy: 0.8665, F1: 0.9237 Bal: 0.8089\n","Epoch 092:      TX: Train Loss: 0.2266, Acc: 0.9101, F1: 0.9481 Bal: 0.9030 - Val Loss: 0.2338, Accuracy: 0.9118, F1: 0.9492 Bal: 0.8990\n","           WALLETS: Train Loss: 0.41113761, Acc: 0.86633358, F1: 0.92366952 Bal: 0.8100 - Val Loss: 0.40812880, Accuracy: 0.8670, F1: 0.9240 Bal: 0.8093\n","Epoch 093:      TX: Train Loss: 0.2251, Acc: 0.9110, F1: 0.9486 Bal: 0.9039 - Val Loss: 0.2325, Accuracy: 0.9136, F1: 0.9503 Bal: 0.9000\n","           WALLETS: Train Loss: 0.41038886, Acc: 0.86679801, F1: 0.92395364 Bal: 0.8103 - Val Loss: 0.40732238, Accuracy: 0.8673, F1: 0.9242 Bal: 0.8092\n","Epoch 094:      TX: Train Loss: 0.2236, Acc: 0.9118, F1: 0.9491 Bal: 0.9046 - Val Loss: 0.2312, Accuracy: 0.9136, F1: 0.9503 Bal: 0.9000\n","           WALLETS: Train Loss: 0.40964043, Acc: 0.86705926, F1: 0.92411190 Bal: 0.8106 - Val Loss: 0.40652290, Accuracy: 0.8676, F1: 0.9244 Bal: 0.8095\n","Epoch 095:      TX: Train Loss: 0.2221, Acc: 0.9131, F1: 0.9499 Bal: 0.9057 - Val Loss: 0.2299, Accuracy: 0.9153, F1: 0.9513 Bal: 0.9009\n","           WALLETS: Train Loss: 0.40889364, Acc: 0.86734590, F1: 0.92428353 Bal: 0.8110 - Val Loss: 0.40572953, Accuracy: 0.8680, F1: 0.9246 Bal: 0.8099\n","Epoch 096:      TX: Train Loss: 0.2207, Acc: 0.9142, F1: 0.9506 Bal: 0.9072 - Val Loss: 0.2286, Accuracy: 0.9155, F1: 0.9515 Bal: 0.9011\n","           WALLETS: Train Loss: 0.40814814, Acc: 0.86756723, F1: 0.92442192 Bal: 0.8110 - Val Loss: 0.40494359, Accuracy: 0.8681, F1: 0.9246 Bal: 0.8104\n","Epoch 097:      TX: Train Loss: 0.2192, Acc: 0.9147, F1: 0.9508 Bal: 0.9073 - Val Loss: 0.2273, Accuracy: 0.9164, F1: 0.9520 Bal: 0.9015\n","           WALLETS: Train Loss: 0.40740538, Acc: 0.86791919, F1: 0.92463666 Bal: 0.8113 - Val Loss: 0.40416515, Accuracy: 0.8686, F1: 0.9250 Bal: 0.8109\n","Epoch 098:      TX: Train Loss: 0.2177, Acc: 0.9157, F1: 0.9515 Bal: 0.9082 - Val Loss: 0.2261, Accuracy: 0.9164, F1: 0.9520 Bal: 0.9015\n","           WALLETS: Train Loss: 0.40666395, Acc: 0.86791919, F1: 0.92463541 Bal: 0.8114 - Val Loss: 0.40338606, Accuracy: 0.8686, F1: 0.9250 Bal: 0.8113\n","Epoch 099:      TX: Train Loss: 0.2162, Acc: 0.9169, F1: 0.9521 Bal: 0.9092 - Val Loss: 0.2248, Accuracy: 0.9166, F1: 0.9521 Bal: 0.9017\n","           WALLETS: Train Loss: 0.40593058, Acc: 0.86800627, F1: 0.92469009 Bal: 0.8113 - Val Loss: 0.40261313, Accuracy: 0.8690, F1: 0.9252 Bal: 0.8119\n","Epoch 100:      TX: Train Loss: 0.2147, Acc: 0.9180, F1: 0.9528 Bal: 0.9102 - Val Loss: 0.2236, Accuracy: 0.9166, F1: 0.9521 Bal: 0.9017\n","           WALLETS: Train Loss: 0.40520427, Acc: 0.86809698, F1: 0.92474636 Bal: 0.8113 - Val Loss: 0.40184906, Accuracy: 0.8691, F1: 0.9252 Bal: 0.8117\n","Epoch 101:      TX: Train Loss: 0.2133, Acc: 0.9190, F1: 0.9534 Bal: 0.9112 - Val Loss: 0.2224, Accuracy: 0.9177, F1: 0.9528 Bal: 0.9033\n","           WALLETS: Train Loss: 0.40447977, Acc: 0.86820946, F1: 0.92481412 Bal: 0.8115 - Val Loss: 0.40108868, Accuracy: 0.8693, F1: 0.9254 Bal: 0.8117\n","Epoch 102:      TX: Train Loss: 0.2118, Acc: 0.9201, F1: 0.9540 Bal: 0.9121 - Val Loss: 0.2212, Accuracy: 0.9186, F1: 0.9533 Bal: 0.9037\n","           WALLETS: Train Loss: 0.40375236, Acc: 0.86841265, F1: 0.92493811 Bal: 0.8116 - Val Loss: 0.40032616, Accuracy: 0.8695, F1: 0.9255 Bal: 0.8120\n","Epoch 103:      TX: Train Loss: 0.2103, Acc: 0.9214, F1: 0.9548 Bal: 0.9133 - Val Loss: 0.2200, Accuracy: 0.9197, F1: 0.9539 Bal: 0.9073\n","           WALLETS: Train Loss: 0.40302342, Acc: 0.86826026, F1: 0.92484341 Bal: 0.8116 - Val Loss: 0.39956486, Accuracy: 0.8695, F1: 0.9255 Bal: 0.8123\n","Epoch 104:      TX: Train Loss: 0.2088, Acc: 0.9221, F1: 0.9553 Bal: 0.9138 - Val Loss: 0.2188, Accuracy: 0.9217, F1: 0.9551 Bal: 0.9084\n","           WALLETS: Train Loss: 0.40229669, Acc: 0.86809698, F1: 0.92473857 Bal: 0.8119 - Val Loss: 0.39880711, Accuracy: 0.8691, F1: 0.9253 Bal: 0.8121\n","Epoch 105:      TX: Train Loss: 0.2073, Acc: 0.9233, F1: 0.9560 Bal: 0.9146 - Val Loss: 0.2176, Accuracy: 0.9223, F1: 0.9555 Bal: 0.9088\n","           WALLETS: Train Loss: 0.40156990, Acc: 0.86792282, F1: 0.92463015 Bal: 0.8119 - Val Loss: 0.39805591, Accuracy: 0.8691, F1: 0.9253 Bal: 0.8119\n","Epoch 106:      TX: Train Loss: 0.2058, Acc: 0.9241, F1: 0.9565 Bal: 0.9150 - Val Loss: 0.2165, Accuracy: 0.9234, F1: 0.9561 Bal: 0.9113\n","           WALLETS: Train Loss: 0.40083846, Acc: 0.86787928, F1: 0.92459750 Bal: 0.8123 - Val Loss: 0.39730385, Accuracy: 0.8690, F1: 0.9252 Bal: 0.8129\n","Epoch 107:      TX: Train Loss: 0.2043, Acc: 0.9250, F1: 0.9570 Bal: 0.9156 - Val Loss: 0.2154, Accuracy: 0.9243, F1: 0.9567 Bal: 0.9118\n","           WALLETS: Train Loss: 0.40010440, Acc: 0.86783211, F1: 0.92456667 Bal: 0.8124 - Val Loss: 0.39654645, Accuracy: 0.8689, F1: 0.9251 Bal: 0.8127\n","Epoch 108:      TX: Train Loss: 0.2028, Acc: 0.9260, F1: 0.9576 Bal: 0.9166 - Val Loss: 0.2143, Accuracy: 0.9245, F1: 0.9568 Bal: 0.9119\n","           WALLETS: Train Loss: 0.39936507, Acc: 0.86769423, F1: 0.92448141 Bal: 0.8123 - Val Loss: 0.39578557, Accuracy: 0.8689, F1: 0.9251 Bal: 0.8131\n","Epoch 109:      TX: Train Loss: 0.2013, Acc: 0.9268, F1: 0.9581 Bal: 0.9173 - Val Loss: 0.2132, Accuracy: 0.9256, F1: 0.9574 Bal: 0.9126\n","           WALLETS: Train Loss: 0.39862025, Acc: 0.86745838, F1: 0.92433379 Bal: 0.8124 - Val Loss: 0.39502135, Accuracy: 0.8685, F1: 0.9248 Bal: 0.8128\n","Epoch 110:      TX: Train Loss: 0.1999, Acc: 0.9278, F1: 0.9587 Bal: 0.9181 - Val Loss: 0.2121, Accuracy: 0.9263, F1: 0.9578 Bal: 0.9129\n","           WALLETS: Train Loss: 0.39786789, Acc: 0.86751281, F1: 0.92436439 Bal: 0.8126 - Val Loss: 0.39425331, Accuracy: 0.8684, F1: 0.9248 Bal: 0.8128\n","Epoch 111:      TX: Train Loss: 0.1984, Acc: 0.9282, F1: 0.9589 Bal: 0.9186 - Val Loss: 0.2111, Accuracy: 0.9258, F1: 0.9576 Bal: 0.9117\n","           WALLETS: Train Loss: 0.39710742, Acc: 0.86775591, F1: 0.92451146 Bal: 0.8129 - Val Loss: 0.39347792, Accuracy: 0.8686, F1: 0.9249 Bal: 0.8127\n","Epoch 112:      TX: Train Loss: 0.1969, Acc: 0.9292, F1: 0.9595 Bal: 0.9200 - Val Loss: 0.2100, Accuracy: 0.9261, F1: 0.9577 Bal: 0.9108\n","           WALLETS: Train Loss: 0.39633521, Acc: 0.86782485, F1: 0.92455472 Bal: 0.8129 - Val Loss: 0.39269125, Accuracy: 0.8689, F1: 0.9251 Bal: 0.8131\n","Epoch 113:      TX: Train Loss: 0.1954, Acc: 0.9300, F1: 0.9600 Bal: 0.9204 - Val Loss: 0.2090, Accuracy: 0.9269, F1: 0.9582 Bal: 0.9113\n","           WALLETS: Train Loss: 0.39556387, Acc: 0.86795547, F1: 0.92463240 Bal: 0.8131 - Val Loss: 0.39190206, Accuracy: 0.8689, F1: 0.9251 Bal: 0.8132\n","Epoch 114:      TX: Train Loss: 0.1939, Acc: 0.9309, F1: 0.9605 Bal: 0.9215 - Val Loss: 0.2079, Accuracy: 0.9283, F1: 0.9590 Bal: 0.9121\n","           WALLETS: Train Loss: 0.39478877, Acc: 0.86814415, F1: 0.92474819 Bal: 0.8132 - Val Loss: 0.39111131, Accuracy: 0.8690, F1: 0.9252 Bal: 0.8130\n","Epoch 115:      TX: Train Loss: 0.1924, Acc: 0.9319, F1: 0.9611 Bal: 0.9226 - Val Loss: 0.2069, Accuracy: 0.9289, F1: 0.9594 Bal: 0.9124\n","           WALLETS: Train Loss: 0.39400506, Acc: 0.86845619, F1: 0.92493592 Bal: 0.8136 - Val Loss: 0.39031518, Accuracy: 0.8693, F1: 0.9254 Bal: 0.8131\n","Epoch 116:      TX: Train Loss: 0.1910, Acc: 0.9326, F1: 0.9615 Bal: 0.9233 - Val Loss: 0.2059, Accuracy: 0.9294, F1: 0.9597 Bal: 0.9127\n","           WALLETS: Train Loss: 0.39321956, Acc: 0.86870655, F1: 0.92508886 Bal: 0.8138 - Val Loss: 0.38951576, Accuracy: 0.8695, F1: 0.9255 Bal: 0.8132\n","Epoch 117:      TX: Train Loss: 0.1895, Acc: 0.9332, F1: 0.9618 Bal: 0.9236 - Val Loss: 0.2049, Accuracy: 0.9302, F1: 0.9602 Bal: 0.9132\n","           WALLETS: Train Loss: 0.39242965, Acc: 0.86953382, F1: 0.92559322 Bal: 0.8145 - Val Loss: 0.38871273, Accuracy: 0.8702, F1: 0.9259 Bal: 0.8139\n","Epoch 118:      TX: Train Loss: 0.1880, Acc: 0.9337, F1: 0.9622 Bal: 0.9243 - Val Loss: 0.2038, Accuracy: 0.9307, F1: 0.9605 Bal: 0.9134\n","           WALLETS: Train Loss: 0.39163586, Acc: 0.86964630, F1: 0.92566183 Bal: 0.8145 - Val Loss: 0.38790742, Accuracy: 0.8704, F1: 0.9261 Bal: 0.8142\n","Epoch 119:      TX: Train Loss: 0.1866, Acc: 0.9343, F1: 0.9625 Bal: 0.9250 - Val Loss: 0.2028, Accuracy: 0.9311, F1: 0.9607 Bal: 0.9146\n","           WALLETS: Train Loss: 0.39083824, Acc: 0.86987489, F1: 0.92579910 Bal: 0.8149 - Val Loss: 0.38709939, Accuracy: 0.8707, F1: 0.9262 Bal: 0.8147\n","Epoch 120:      TX: Train Loss: 0.1851, Acc: 0.9351, F1: 0.9630 Bal: 0.9256 - Val Loss: 0.2018, Accuracy: 0.9322, F1: 0.9614 Bal: 0.9162\n","           WALLETS: Train Loss: 0.39003840, Acc: 0.87032481, F1: 0.92607096 Bal: 0.8154 - Val Loss: 0.38629395, Accuracy: 0.8710, F1: 0.9264 Bal: 0.8145\n","Epoch 121:      TX: Train Loss: 0.1836, Acc: 0.9359, F1: 0.9634 Bal: 0.9264 - Val Loss: 0.2008, Accuracy: 0.9320, F1: 0.9612 Bal: 0.9151\n","           WALLETS: Train Loss: 0.38923898, Acc: 0.87048446, F1: 0.92616533 Bal: 0.8157 - Val Loss: 0.38549051, Accuracy: 0.8714, F1: 0.9267 Bal: 0.8151\n","Epoch 122:      TX: Train Loss: 0.1822, Acc: 0.9364, F1: 0.9637 Bal: 0.9269 - Val Loss: 0.1998, Accuracy: 0.9324, F1: 0.9615 Bal: 0.9154\n","           WALLETS: Train Loss: 0.38843706, Acc: 0.87066225, F1: 0.92626837 Bal: 0.8162 - Val Loss: 0.38468194, Accuracy: 0.8714, F1: 0.9267 Bal: 0.8154\n","Epoch 123:      TX: Train Loss: 0.1807, Acc: 0.9369, F1: 0.9640 Bal: 0.9280 - Val Loss: 0.1988, Accuracy: 0.9333, F1: 0.9620 Bal: 0.9178\n","           WALLETS: Train Loss: 0.38763195, Acc: 0.87069491, F1: 0.92628470 Bal: 0.8165 - Val Loss: 0.38387051, Accuracy: 0.8716, F1: 0.9267 Bal: 0.8154\n","Epoch 124:      TX: Train Loss: 0.1793, Acc: 0.9376, F1: 0.9644 Bal: 0.9288 - Val Loss: 0.1979, Accuracy: 0.9346, F1: 0.9628 Bal: 0.9176\n","           WALLETS: Train Loss: 0.38682869, Acc: 0.87079288, F1: 0.92634009 Bal: 0.8168 - Val Loss: 0.38306269, Accuracy: 0.8716, F1: 0.9267 Bal: 0.8158\n","Epoch 125:      TX: Train Loss: 0.1779, Acc: 0.9386, F1: 0.9650 Bal: 0.9296 - Val Loss: 0.1970, Accuracy: 0.9353, F1: 0.9632 Bal: 0.9179\n","           WALLETS: Train Loss: 0.38602743, Acc: 0.87098155, F1: 0.92645130 Bal: 0.8172 - Val Loss: 0.38225541, Accuracy: 0.8718, F1: 0.9269 Bal: 0.8164\n","Epoch 126:      TX: Train Loss: 0.1764, Acc: 0.9392, F1: 0.9654 Bal: 0.9305 - Val Loss: 0.1961, Accuracy: 0.9364, F1: 0.9638 Bal: 0.9185\n","           WALLETS: Train Loss: 0.38522369, Acc: 0.87086182, F1: 0.92637284 Bal: 0.8175 - Val Loss: 0.38143879, Accuracy: 0.8714, F1: 0.9267 Bal: 0.8165\n","Epoch 127:      TX: Train Loss: 0.1750, Acc: 0.9397, F1: 0.9657 Bal: 0.9314 - Val Loss: 0.1952, Accuracy: 0.9370, F1: 0.9642 Bal: 0.9209\n","           WALLETS: Train Loss: 0.38441697, Acc: 0.87098155, F1: 0.92643883 Bal: 0.8181 - Val Loss: 0.38062024, Accuracy: 0.8711, F1: 0.9265 Bal: 0.8160\n","Epoch 128:      TX: Train Loss: 0.1736, Acc: 0.9405, F1: 0.9661 Bal: 0.9321 - Val Loss: 0.1943, Accuracy: 0.9373, F1: 0.9643 Bal: 0.9210\n","           WALLETS: Train Loss: 0.38360649, Acc: 0.87080376, F1: 0.92632938 Bal: 0.8181 - Val Loss: 0.37980419, Accuracy: 0.8708, F1: 0.9263 Bal: 0.8161\n","Epoch 129:      TX: Train Loss: 0.1722, Acc: 0.9408, F1: 0.9663 Bal: 0.9320 - Val Loss: 0.1934, Accuracy: 0.9370, F1: 0.9642 Bal: 0.9199\n","           WALLETS: Train Loss: 0.38278994, Acc: 0.87075296, F1: 0.92629462 Bal: 0.8183 - Val Loss: 0.37897563, Accuracy: 0.8705, F1: 0.9261 Bal: 0.8165\n","Epoch 130:      TX: Train Loss: 0.1708, Acc: 0.9414, F1: 0.9666 Bal: 0.9330 - Val Loss: 0.1926, Accuracy: 0.9368, F1: 0.9641 Bal: 0.9198\n","           WALLETS: Train Loss: 0.38197127, Acc: 0.87066588, F1: 0.92623336 Bal: 0.8188 - Val Loss: 0.37814018, Accuracy: 0.8705, F1: 0.9261 Bal: 0.8166\n","Epoch 131:      TX: Train Loss: 0.1694, Acc: 0.9419, F1: 0.9670 Bal: 0.9337 - Val Loss: 0.1918, Accuracy: 0.9373, F1: 0.9643 Bal: 0.9200\n","           WALLETS: Train Loss: 0.38114801, Acc: 0.87068402, F1: 0.92623745 Bal: 0.8193 - Val Loss: 0.37730673, Accuracy: 0.8706, F1: 0.9261 Bal: 0.8170\n","Epoch 132:      TX: Train Loss: 0.1681, Acc: 0.9425, F1: 0.9673 Bal: 0.9346 - Val Loss: 0.1910, Accuracy: 0.9381, F1: 0.9648 Bal: 0.9205\n","           WALLETS: Train Loss: 0.38032061, Acc: 0.87066225, F1: 0.92621923 Bal: 0.8196 - Val Loss: 0.37647110, Accuracy: 0.8706, F1: 0.9261 Bal: 0.8173\n","Epoch 133:      TX: Train Loss: 0.1667, Acc: 0.9431, F1: 0.9677 Bal: 0.9351 - Val Loss: 0.1903, Accuracy: 0.9379, F1: 0.9647 Bal: 0.9204\n","           WALLETS: Train Loss: 0.37949315, Acc: 0.87070217, F1: 0.92623909 Bal: 0.8200 - Val Loss: 0.37563229, Accuracy: 0.8704, F1: 0.9260 Bal: 0.8181\n","Epoch 134:      TX: Train Loss: 0.1654, Acc: 0.9438, F1: 0.9681 Bal: 0.9355 - Val Loss: 0.1896, Accuracy: 0.9384, F1: 0.9650 Bal: 0.9216\n","           WALLETS: Train Loss: 0.37866300, Acc: 0.87057880, F1: 0.92615618 Bal: 0.8204 - Val Loss: 0.37479436, Accuracy: 0.8704, F1: 0.9259 Bal: 0.8184\n","Epoch 135:      TX: Train Loss: 0.1640, Acc: 0.9443, F1: 0.9683 Bal: 0.9357 - Val Loss: 0.1890, Accuracy: 0.9386, F1: 0.9651 Bal: 0.9217\n","           WALLETS: Train Loss: 0.37782809, Acc: 0.87092350, F1: 0.92636582 Bal: 0.8207 - Val Loss: 0.37396201, Accuracy: 0.8705, F1: 0.9260 Bal: 0.8185\n","Epoch 136:      TX: Train Loss: 0.1627, Acc: 0.9446, F1: 0.9685 Bal: 0.9367 - Val Loss: 0.1883, Accuracy: 0.9384, F1: 0.9650 Bal: 0.9216\n","           WALLETS: Train Loss: 0.37698874, Acc: 0.87113032, F1: 0.92648365 Bal: 0.8215 - Val Loss: 0.37312356, Accuracy: 0.8708, F1: 0.9262 Bal: 0.8193\n","Epoch 137:      TX: Train Loss: 0.1614, Acc: 0.9453, F1: 0.9689 Bal: 0.9378 - Val Loss: 0.1877, Accuracy: 0.9386, F1: 0.9651 Bal: 0.9217\n","           WALLETS: Train Loss: 0.37614691, Acc: 0.87121377, F1: 0.92652441 Bal: 0.8222 - Val Loss: 0.37227735, Accuracy: 0.8711, F1: 0.9264 Bal: 0.8205\n","Epoch 138:      TX: Train Loss: 0.1600, Acc: 0.9459, F1: 0.9693 Bal: 0.9389 - Val Loss: 0.1871, Accuracy: 0.9392, F1: 0.9655 Bal: 0.9221\n","           WALLETS: Train Loss: 0.37530783, Acc: 0.87138793, F1: 0.92662590 Bal: 0.8227 - Val Loss: 0.37143874, Accuracy: 0.8711, F1: 0.9264 Bal: 0.8214\n","Epoch 139:      TX: Train Loss: 0.1587, Acc: 0.9464, F1: 0.9696 Bal: 0.9393 - Val Loss: 0.1865, Accuracy: 0.9397, F1: 0.9657 Bal: 0.9223\n","           WALLETS: Train Loss: 0.37446922, Acc: 0.87152944, F1: 0.92671103 Bal: 0.8229 - Val Loss: 0.37060058, Accuracy: 0.8714, F1: 0.9265 Bal: 0.8216\n","Epoch 140:      TX: Train Loss: 0.1575, Acc: 0.9471, F1: 0.9700 Bal: 0.9402 - Val Loss: 0.1859, Accuracy: 0.9403, F1: 0.9661 Bal: 0.9217\n","           WALLETS: Train Loss: 0.37363070, Acc: 0.87154758, F1: 0.92671455 Bal: 0.8234 - Val Loss: 0.36976406, Accuracy: 0.8713, F1: 0.9265 Bal: 0.8227\n","Epoch 141:      TX: Train Loss: 0.1562, Acc: 0.9475, F1: 0.9702 Bal: 0.9408 - Val Loss: 0.1853, Accuracy: 0.9410, F1: 0.9665 Bal: 0.9211\n","           WALLETS: Train Loss: 0.37279797, Acc: 0.87235671, F1: 0.92720708 Bal: 0.8241 - Val Loss: 0.36894119, Accuracy: 0.8721, F1: 0.9270 Bal: 0.8233\n","Epoch 142:      TX: Train Loss: 0.1549, Acc: 0.9480, F1: 0.9705 Bal: 0.9417 - Val Loss: 0.1847, Accuracy: 0.9414, F1: 0.9668 Bal: 0.9213\n","           WALLETS: Train Loss: 0.37196761, Acc: 0.87251999, F1: 0.92729944 Bal: 0.8247 - Val Loss: 0.36812347, Accuracy: 0.8722, F1: 0.9270 Bal: 0.8240\n","Epoch 143:      TX: Train Loss: 0.1537, Acc: 0.9484, F1: 0.9707 Bal: 0.9420 - Val Loss: 0.1842, Accuracy: 0.9419, F1: 0.9670 Bal: 0.9216\n","           WALLETS: Train Loss: 0.37113583, Acc: 0.87247645, F1: 0.92726467 Bal: 0.8252 - Val Loss: 0.36729735, Accuracy: 0.8719, F1: 0.9268 Bal: 0.8241\n","Epoch 144:      TX: Train Loss: 0.1524, Acc: 0.9491, F1: 0.9711 Bal: 0.9428 - Val Loss: 0.1837, Accuracy: 0.9419, F1: 0.9670 Bal: 0.9216\n","           WALLETS: Train Loss: 0.37030613, Acc: 0.87263973, F1: 0.92735705 Bal: 0.8259 - Val Loss: 0.36647958, Accuracy: 0.8718, F1: 0.9268 Bal: 0.8242\n","Epoch 145:      TX: Train Loss: 0.1512, Acc: 0.9492, F1: 0.9712 Bal: 0.9433 - Val Loss: 0.1832, Accuracy: 0.9419, F1: 0.9670 Bal: 0.9206\n","           WALLETS: Train Loss: 0.36947548, Acc: 0.87286469, F1: 0.92749197 Bal: 0.8262 - Val Loss: 0.36566544, Accuracy: 0.8720, F1: 0.9269 Bal: 0.8250\n","Epoch 146:      TX: Train Loss: 0.1500, Acc: 0.9494, F1: 0.9713 Bal: 0.9438 - Val Loss: 0.1827, Accuracy: 0.9425, F1: 0.9674 Bal: 0.9210\n","           WALLETS: Train Loss: 0.36864260, Acc: 0.87260707, F1: 0.92732203 Bal: 0.8269 - Val Loss: 0.36484376, Accuracy: 0.8715, F1: 0.9266 Bal: 0.8252\n","Epoch 147:      TX: Train Loss: 0.1488, Acc: 0.9498, F1: 0.9715 Bal: 0.9445 - Val Loss: 0.1823, Accuracy: 0.9430, F1: 0.9677 Bal: 0.9212\n","           WALLETS: Train Loss: 0.36780757, Acc: 0.87282478, F1: 0.92745224 Bal: 0.8272 - Val Loss: 0.36403340, Accuracy: 0.8720, F1: 0.9268 Bal: 0.8257\n","Epoch 148:      TX: Train Loss: 0.1476, Acc: 0.9502, F1: 0.9718 Bal: 0.9449 - Val Loss: 0.1819, Accuracy: 0.9441, F1: 0.9683 Bal: 0.9218\n","           WALLETS: Train Loss: 0.36696941, Acc: 0.87293000, F1: 0.92751241 Bal: 0.8276 - Val Loss: 0.36321792, Accuracy: 0.8719, F1: 0.9268 Bal: 0.8260\n","Epoch 149:      TX: Train Loss: 0.1464, Acc: 0.9507, F1: 0.9720 Bal: 0.9457 - Val Loss: 0.1815, Accuracy: 0.9445, F1: 0.9686 Bal: 0.9221\n","           WALLETS: Train Loss: 0.36612755, Acc: 0.87285743, F1: 0.92745570 Bal: 0.8284 - Val Loss: 0.36239660, Accuracy: 0.8718, F1: 0.9267 Bal: 0.8263\n","Epoch 150:      TX: Train Loss: 0.1452, Acc: 0.9513, F1: 0.9724 Bal: 0.9463 - Val Loss: 0.1811, Accuracy: 0.9452, F1: 0.9690 Bal: 0.9224\n","           WALLETS: Train Loss: 0.36528292, Acc: 0.87328558, F1: 0.92771376 Bal: 0.8290 - Val Loss: 0.36158398, Accuracy: 0.8724, F1: 0.9271 Bal: 0.8266\n","Epoch 151:      TX: Train Loss: 0.1441, Acc: 0.9516, F1: 0.9725 Bal: 0.9465 - Val Loss: 0.1807, Accuracy: 0.9456, F1: 0.9692 Bal: 0.9227\n","           WALLETS: Train Loss: 0.36443281, Acc: 0.87320939, F1: 0.92766026 Bal: 0.8294 - Val Loss: 0.36076131, Accuracy: 0.8725, F1: 0.9272 Bal: 0.8271\n","Epoch 152:      TX: Train Loss: 0.1430, Acc: 0.9518, F1: 0.9727 Bal: 0.9468 - Val Loss: 0.1804, Accuracy: 0.9458, F1: 0.9694 Bal: 0.9228\n","           WALLETS: Train Loss: 0.36358094, Acc: 0.87342709, F1: 0.92778836 Bal: 0.8299 - Val Loss: 0.35994318, Accuracy: 0.8729, F1: 0.9274 Bal: 0.8278\n","Epoch 153:      TX: Train Loss: 0.1418, Acc: 0.9522, F1: 0.9729 Bal: 0.9473 - Val Loss: 0.1801, Accuracy: 0.9462, F1: 0.9696 Bal: 0.9230\n","           WALLETS: Train Loss: 0.36272576, Acc: 0.87357948, F1: 0.92787261 Bal: 0.8306 - Val Loss: 0.35912383, Accuracy: 0.8731, F1: 0.9275 Bal: 0.8287\n","Epoch 154:      TX: Train Loss: 0.1407, Acc: 0.9525, F1: 0.9731 Bal: 0.9478 - Val Loss: 0.1799, Accuracy: 0.9465, F1: 0.9697 Bal: 0.9231\n","           WALLETS: Train Loss: 0.36186457, Acc: 0.87359037, F1: 0.92786882 Bal: 0.8314 - Val Loss: 0.35829332, Accuracy: 0.8732, F1: 0.9276 Bal: 0.8297\n","Epoch 155:      TX: Train Loss: 0.1396, Acc: 0.9529, F1: 0.9733 Bal: 0.9484 - Val Loss: 0.1796, Accuracy: 0.9469, F1: 0.9700 Bal: 0.9234\n","           WALLETS: Train Loss: 0.36099952, Acc: 0.87395321, F1: 0.92808807 Bal: 0.8318 - Val Loss: 0.35746226, Accuracy: 0.8735, F1: 0.9278 Bal: 0.8302\n","Epoch 156:      TX: Train Loss: 0.1385, Acc: 0.9533, F1: 0.9736 Bal: 0.9488 - Val Loss: 0.1794, Accuracy: 0.9476, F1: 0.9704 Bal: 0.9238\n","           WALLETS: Train Loss: 0.36013272, Acc: 0.87384073, F1: 0.92801093 Bal: 0.8323 - Val Loss: 0.35661459, Accuracy: 0.8734, F1: 0.9277 Bal: 0.8306\n","Epoch 157:      TX: Train Loss: 0.1375, Acc: 0.9539, F1: 0.9739 Bal: 0.9503 - Val Loss: 0.1792, Accuracy: 0.9480, F1: 0.9706 Bal: 0.9240\n","           WALLETS: Train Loss: 0.35926595, Acc: 0.87395684, F1: 0.92807629 Bal: 0.8328 - Val Loss: 0.35577747, Accuracy: 0.8736, F1: 0.9278 Bal: 0.8307\n","Epoch 158:      TX: Train Loss: 0.1364, Acc: 0.9543, F1: 0.9741 Bal: 0.9512 - Val Loss: 0.1790, Accuracy: 0.9482, F1: 0.9707 Bal: 0.9251\n","           WALLETS: Train Loss: 0.35839987, Acc: 0.87394958, F1: 0.92806202 Bal: 0.8335 - Val Loss: 0.35494125, Accuracy: 0.8736, F1: 0.9277 Bal: 0.8318\n","Epoch 159:      TX: Train Loss: 0.1354, Acc: 0.9548, F1: 0.9744 Bal: 0.9516 - Val Loss: 0.1788, Accuracy: 0.9482, F1: 0.9707 Bal: 0.9251\n","           WALLETS: Train Loss: 0.35753605, Acc: 0.87412374, F1: 0.92816380 Bal: 0.8339 - Val Loss: 0.35412157, Accuracy: 0.8739, F1: 0.9280 Bal: 0.8326\n","Epoch 160:      TX: Train Loss: 0.1343, Acc: 0.9550, F1: 0.9745 Bal: 0.9517 - Val Loss: 0.1785, Accuracy: 0.9484, F1: 0.9709 Bal: 0.9252\n","           WALLETS: Train Loss: 0.35667849, Acc: 0.87406206, F1: 0.92811475 Bal: 0.8347 - Val Loss: 0.35330057, Accuracy: 0.8742, F1: 0.9281 Bal: 0.8339\n","Epoch 161:      TX: Train Loss: 0.1333, Acc: 0.9555, F1: 0.9748 Bal: 0.9521 - Val Loss: 0.1784, Accuracy: 0.9493, F1: 0.9714 Bal: 0.9257\n","           WALLETS: Train Loss: 0.35582376, Acc: 0.87445756, F1: 0.92835490 Bal: 0.8350 - Val Loss: 0.35250062, Accuracy: 0.8747, F1: 0.9284 Bal: 0.8340\n","Epoch 162:      TX: Train Loss: 0.1323, Acc: 0.9559, F1: 0.9750 Bal: 0.9529 - Val Loss: 0.1781, Accuracy: 0.9498, F1: 0.9716 Bal: 0.9260\n","           WALLETS: Train Loss: 0.35497618, Acc: 0.87417091, F1: 0.92816558 Bal: 0.8359 - Val Loss: 0.35167921, Accuracy: 0.8743, F1: 0.9282 Bal: 0.8344\n","Epoch 163:      TX: Train Loss: 0.1313, Acc: 0.9562, F1: 0.9752 Bal: 0.9534 - Val Loss: 0.1779, Accuracy: 0.9500, F1: 0.9718 Bal: 0.9261\n","           WALLETS: Train Loss: 0.35414150, Acc: 0.87511067, F1: 0.92874739 Bal: 0.8359 - Val Loss: 0.35091445, Accuracy: 0.8750, F1: 0.9286 Bal: 0.8340\n","Epoch 164:      TX: Train Loss: 0.1304, Acc: 0.9566, F1: 0.9754 Bal: 0.9538 - Val Loss: 0.1778, Accuracy: 0.9500, F1: 0.9718 Bal: 0.9261\n","           WALLETS: Train Loss: 0.35331866, Acc: 0.87354320, F1: 0.92775919 Bal: 0.8371 - Val Loss: 0.35007507, Accuracy: 0.8736, F1: 0.9277 Bal: 0.8364\n","Epoch 165:      TX: Train Loss: 0.1294, Acc: 0.9570, F1: 0.9757 Bal: 0.9546 - Val Loss: 0.1776, Accuracy: 0.9500, F1: 0.9718 Bal: 0.9261\n","           WALLETS: Train Loss: 0.35250613, Acc: 0.87603591, F1: 0.92931199 Bal: 0.8364 - Val Loss: 0.34938422, Accuracy: 0.8756, F1: 0.9289 Bal: 0.8351\n","Epoch 166:      TX: Train Loss: 0.1285, Acc: 0.9573, F1: 0.9758 Bal: 0.9552 - Val Loss: 0.1774, Accuracy: 0.9502, F1: 0.9719 Bal: 0.9262\n","           WALLETS: Train Loss: 0.35170692, Acc: 0.87253088, F1: 0.92710972 Bal: 0.8386 - Val Loss: 0.34849921, Accuracy: 0.8728, F1: 0.9272 Bal: 0.8382\n","Epoch 167:      TX: Train Loss: 0.1275, Acc: 0.9579, F1: 0.9762 Bal: 0.9559 - Val Loss: 0.1773, Accuracy: 0.9504, F1: 0.9720 Bal: 0.9263\n","           WALLETS: Train Loss: 0.35088667, Acc: 0.87649308, F1: 0.92958318 Bal: 0.8373 - Val Loss: 0.34784847, Accuracy: 0.8760, F1: 0.9292 Bal: 0.8363\n","Epoch 168:      TX: Train Loss: 0.1266, Acc: 0.9580, F1: 0.9762 Bal: 0.9564 - Val Loss: 0.1771, Accuracy: 0.9506, F1: 0.9722 Bal: 0.9264\n","           WALLETS: Train Loss: 0.35006320, Acc: 0.87350329, F1: 0.92770297 Bal: 0.8394 - Val Loss: 0.34695908, Accuracy: 0.8739, F1: 0.9278 Bal: 0.8391\n","Epoch 169:      TX: Train Loss: 0.1257, Acc: 0.9583, F1: 0.9764 Bal: 0.9567 - Val Loss: 0.1770, Accuracy: 0.9509, F1: 0.9723 Bal: 0.9266\n","           WALLETS: Train Loss: 0.34925720, Acc: 0.87467163, F1: 0.92842504 Bal: 0.8395 - Val Loss: 0.34622234, Accuracy: 0.8746, F1: 0.9283 Bal: 0.8386\n","Epoch 170:      TX: Train Loss: 0.1248, Acc: 0.9587, F1: 0.9767 Bal: 0.9570 - Val Loss: 0.1769, Accuracy: 0.9511, F1: 0.9724 Bal: 0.9267\n","           WALLETS: Train Loss: 0.34848398, Acc: 0.87619193, F1: 0.92936398 Bal: 0.8397 - Val Loss: 0.34553203, Accuracy: 0.8758, F1: 0.9291 Bal: 0.8387\n","Epoch 171:      TX: Train Loss: 0.1239, Acc: 0.9588, F1: 0.9767 Bal: 0.9574 - Val Loss: 0.1768, Accuracy: 0.9509, F1: 0.9723 Bal: 0.9266\n","           WALLETS: Train Loss: 0.34772468, Acc: 0.87327833, F1: 0.92753503 Bal: 0.8414 - Val Loss: 0.34469870, Accuracy: 0.8732, F1: 0.9274 Bal: 0.8402\n","Epoch 172:      TX: Train Loss: 0.1230, Acc: 0.9593, F1: 0.9770 Bal: 0.9580 - Val Loss: 0.1767, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9269\n","           WALLETS: Train Loss: 0.34693998, Acc: 0.87659468, F1: 0.92960090 Bal: 0.8406 - Val Loss: 0.34405500, Accuracy: 0.8764, F1: 0.9294 Bal: 0.8402\n","Epoch 173:      TX: Train Loss: 0.1222, Acc: 0.9598, F1: 0.9773 Bal: 0.9584 - Val Loss: 0.1766, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9269\n","           WALLETS: Train Loss: 0.34616306, Acc: 0.87452287, F1: 0.92830131 Bal: 0.8418 - Val Loss: 0.34323105, Accuracy: 0.8741, F1: 0.9279 Bal: 0.8404\n","Epoch 174:      TX: Train Loss: 0.1213, Acc: 0.9603, F1: 0.9775 Bal: 0.9592 - Val Loss: 0.1765, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9269\n","           WALLETS: Train Loss: 0.34541094, Acc: 0.87452649, F1: 0.92829729 Bal: 0.8423 - Val Loss: 0.34249586, Accuracy: 0.8741, F1: 0.9280 Bal: 0.8409\n","Epoch 175:      TX: Train Loss: 0.1205, Acc: 0.9606, F1: 0.9777 Bal: 0.9596 - Val Loss: 0.1764, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9283\n","           WALLETS: Train Loss: 0.34468225, Acc: 0.87636609, F1: 0.92944056 Bal: 0.8420 - Val Loss: 0.34184897, Accuracy: 0.8761, F1: 0.9292 Bal: 0.8416\n","Epoch 176:      TX: Train Loss: 0.1196, Acc: 0.9607, F1: 0.9778 Bal: 0.9602 - Val Loss: 0.1762, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9283\n","           WALLETS: Train Loss: 0.34395838, Acc: 0.87358311, F1: 0.92769191 Bal: 0.8437 - Val Loss: 0.34103504, Accuracy: 0.8732, F1: 0.9274 Bal: 0.8428\n","Epoch 177:      TX: Train Loss: 0.1188, Acc: 0.9610, F1: 0.9780 Bal: 0.9609 - Val Loss: 0.1761, Accuracy: 0.9520, F1: 0.9729 Bal: 0.9282\n","           WALLETS: Train Loss: 0.34322080, Acc: 0.87614839, F1: 0.92928879 Bal: 0.8432 - Val Loss: 0.34040388, Accuracy: 0.8756, F1: 0.9289 Bal: 0.8427\n","Epoch 178:      TX: Train Loss: 0.1180, Acc: 0.9614, F1: 0.9782 Bal: 0.9616 - Val Loss: 0.1759, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9283\n","           WALLETS: Train Loss: 0.34249827, Acc: 0.87474420, F1: 0.92840329 Bal: 0.8444 - Val Loss: 0.33965331, Accuracy: 0.8744, F1: 0.9281 Bal: 0.8432\n","Epoch 179:      TX: Train Loss: 0.1172, Acc: 0.9615, F1: 0.9782 Bal: 0.9621 - Val Loss: 0.1757, Accuracy: 0.9520, F1: 0.9729 Bal: 0.9282\n","           WALLETS: Train Loss: 0.34179810, Acc: 0.87425074, F1: 0.92809229 Bal: 0.8447 - Val Loss: 0.33896178, Accuracy: 0.8742, F1: 0.9279 Bal: 0.8444\n","Epoch 180:      TX: Train Loss: 0.1164, Acc: 0.9618, F1: 0.9784 Bal: 0.9622 - Val Loss: 0.1757, Accuracy: 0.9524, F1: 0.9732 Bal: 0.9284\n","           WALLETS: Train Loss: 0.34111077, Acc: 0.87604679, F1: 0.92920292 Bal: 0.8449 - Val Loss: 0.33836037, Accuracy: 0.8760, F1: 0.9290 Bal: 0.8457\n","Epoch 181:      TX: Train Loss: 0.1157, Acc: 0.9618, F1: 0.9784 Bal: 0.9625 - Val Loss: 0.1756, Accuracy: 0.9520, F1: 0.9729 Bal: 0.9282\n","           WALLETS: Train Loss: 0.34043288, Acc: 0.87349603, F1: 0.92760575 Bal: 0.8460 - Val Loss: 0.33761314, Accuracy: 0.8736, F1: 0.9275 Bal: 0.8474\n","Epoch 182:      TX: Train Loss: 0.1149, Acc: 0.9622, F1: 0.9787 Bal: 0.9629 - Val Loss: 0.1756, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9283\n","           WALLETS: Train Loss: 0.33974898, Acc: 0.87602139, F1: 0.92917270 Bal: 0.8460 - Val Loss: 0.33704272, Accuracy: 0.8759, F1: 0.9290 Bal: 0.8471\n","Epoch 183:      TX: Train Loss: 0.1142, Acc: 0.9625, F1: 0.9788 Bal: 0.9630 - Val Loss: 0.1755, Accuracy: 0.9517, F1: 0.9728 Bal: 0.9280\n","           WALLETS: Train Loss: 0.33907500, Acc: 0.87427614, F1: 0.92807831 Bal: 0.8469 - Val Loss: 0.33633974, Accuracy: 0.8742, F1: 0.9279 Bal: 0.8490\n","Epoch 184:      TX: Train Loss: 0.1134, Acc: 0.9626, F1: 0.9789 Bal: 0.9634 - Val Loss: 0.1754, Accuracy: 0.9513, F1: 0.9725 Bal: 0.9278\n","           WALLETS: Train Loss: 0.33841288, Acc: 0.87483128, F1: 0.92841535 Bal: 0.8474 - Val Loss: 0.33573303, Accuracy: 0.8747, F1: 0.9282 Bal: 0.8492\n","Epoch 185:      TX: Train Loss: 0.1127, Acc: 0.9629, F1: 0.9790 Bal: 0.9635 - Val Loss: 0.1755, Accuracy: 0.9517, F1: 0.9728 Bal: 0.9280\n","           WALLETS: Train Loss: 0.33776632, Acc: 0.87576015, F1: 0.92898371 Bal: 0.8479 - Val Loss: 0.33515540, Accuracy: 0.8756, F1: 0.9287 Bal: 0.8491\n","Epoch 186:      TX: Train Loss: 0.1120, Acc: 0.9632, F1: 0.9792 Bal: 0.9640 - Val Loss: 0.1754, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9279\n","           WALLETS: Train Loss: 0.33713445, Acc: 0.87388064, F1: 0.92781026 Bal: 0.8485 - Val Loss: 0.33451355, Accuracy: 0.8738, F1: 0.9276 Bal: 0.8500\n","Epoch 187:      TX: Train Loss: 0.1113, Acc: 0.9634, F1: 0.9793 Bal: 0.9643 - Val Loss: 0.1753, Accuracy: 0.9511, F1: 0.9724 Bal: 0.9277\n","           WALLETS: Train Loss: 0.33650741, Acc: 0.87638060, F1: 0.92935844 Bal: 0.8486 - Val Loss: 0.33402830, Accuracy: 0.8761, F1: 0.9290 Bal: 0.8495\n","Epoch 188:      TX: Train Loss: 0.1106, Acc: 0.9636, F1: 0.9795 Bal: 0.9644 - Val Loss: 0.1754, Accuracy: 0.9513, F1: 0.9725 Bal: 0.9268\n","           WALLETS: Train Loss: 0.33589375, Acc: 0.87344160, F1: 0.92752690 Bal: 0.8492 - Val Loss: 0.33336896, Accuracy: 0.8734, F1: 0.9273 Bal: 0.8507\n","Epoch 189:      TX: Train Loss: 0.1099, Acc: 0.9636, F1: 0.9794 Bal: 0.9648 - Val Loss: 0.1750, Accuracy: 0.9511, F1: 0.9724 Bal: 0.9277\n","           WALLETS: Train Loss: 0.33527470, Acc: 0.87673619, F1: 0.92956806 Bal: 0.8494 - Val Loss: 0.33291307, Accuracy: 0.8765, F1: 0.9293 Bal: 0.8511\n","Epoch 190:      TX: Train Loss: 0.1092, Acc: 0.9643, F1: 0.9798 Bal: 0.9650 - Val Loss: 0.1754, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9269\n","           WALLETS: Train Loss: 0.33466744, Acc: 0.87405843, F1: 0.92789690 Bal: 0.8502 - Val Loss: 0.33226788, Accuracy: 0.8741, F1: 0.9278 Bal: 0.8522\n","Epoch 191:      TX: Train Loss: 0.1086, Acc: 0.9639, F1: 0.9796 Bal: 0.9654 - Val Loss: 0.1750, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9279\n","           WALLETS: Train Loss: 0.33406067, Acc: 0.87617016, F1: 0.92920883 Bal: 0.8501 - Val Loss: 0.33179775, Accuracy: 0.8763, F1: 0.9291 Bal: 0.8518\n","Epoch 192:      TX: Train Loss: 0.1079, Acc: 0.9648, F1: 0.9801 Bal: 0.9658 - Val Loss: 0.1754, Accuracy: 0.9517, F1: 0.9728 Bal: 0.9271\n","           WALLETS: Train Loss: 0.33346662, Acc: 0.87485305, F1: 0.92837965 Bal: 0.8510 - Val Loss: 0.33121526, Accuracy: 0.8749, F1: 0.9283 Bal: 0.8530\n","Epoch 193:      TX: Train Loss: 0.1072, Acc: 0.9643, F1: 0.9799 Bal: 0.9657 - Val Loss: 0.1750, Accuracy: 0.9515, F1: 0.9727 Bal: 0.9269\n","           WALLETS: Train Loss: 0.33288088, Acc: 0.87576378, F1: 0.92894143 Bal: 0.8512 - Val Loss: 0.33071530, Accuracy: 0.8759, F1: 0.9289 Bal: 0.8533\n","Epoch 194:      TX: Train Loss: 0.1066, Acc: 0.9648, F1: 0.9801 Bal: 0.9663 - Val Loss: 0.1752, Accuracy: 0.9517, F1: 0.9728 Bal: 0.9271\n","           WALLETS: Train Loss: 0.33230659, Acc: 0.87581095, F1: 0.92896501 Bal: 0.8516 - Val Loss: 0.33020094, Accuracy: 0.8760, F1: 0.9290 Bal: 0.8534\n","Epoch 195:      TX: Train Loss: 0.1060, Acc: 0.9651, F1: 0.9803 Bal: 0.9666 - Val Loss: 0.1752, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9273\n","           WALLETS: Train Loss: 0.33174005, Acc: 0.87524492, F1: 0.92860777 Bal: 0.8520 - Val Loss: 0.32967055, Accuracy: 0.8757, F1: 0.9287 Bal: 0.8543\n","Epoch 196:      TX: Train Loss: 0.1053, Acc: 0.9650, F1: 0.9803 Bal: 0.9665 - Val Loss: 0.1749, Accuracy: 0.9526, F1: 0.9733 Bal: 0.9295\n","           WALLETS: Train Loss: 0.33118004, Acc: 0.87638423, F1: 0.92931229 Bal: 0.8522 - Val Loss: 0.32921544, Accuracy: 0.8767, F1: 0.9294 Bal: 0.8536\n","Epoch 197:      TX: Train Loss: 0.1047, Acc: 0.9657, F1: 0.9806 Bal: 0.9669 - Val Loss: 0.1752, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9263\n","           WALLETS: Train Loss: 0.33063507, Acc: 0.87448658, F1: 0.92812470 Bal: 0.8529 - Val Loss: 0.32865673, Accuracy: 0.8749, F1: 0.9283 Bal: 0.8550\n","Epoch 198:      TX: Train Loss: 0.1041, Acc: 0.9654, F1: 0.9805 Bal: 0.9670 - Val Loss: 0.1748, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9283\n","           WALLETS: Train Loss: 0.33009952, Acc: 0.87709177, F1: 0.92974735 Bal: 0.8524 - Val Loss: 0.32828507, Accuracy: 0.8774, F1: 0.9298 Bal: 0.8542\n","Epoch 199:      TX: Train Loss: 0.1035, Acc: 0.9659, F1: 0.9807 Bal: 0.9672 - Val Loss: 0.1752, Accuracy: 0.9522, F1: 0.9730 Bal: 0.9273\n","           WALLETS: Train Loss: 0.32959452, Acc: 0.87363391, F1: 0.92757517 Bal: 0.8543 - Val Loss: 0.32768252, Accuracy: 0.8740, F1: 0.9277 Bal: 0.8563\n","Epoch 200:      TX: Train Loss: 0.1030, Acc: 0.9656, F1: 0.9806 Bal: 0.9677 - Val Loss: 0.1747, Accuracy: 0.9526, F1: 0.9733 Bal: 0.9295\n","           WALLETS: Train Loss: 0.32910481, Acc: 0.87902208, F1: 0.93093920 Bal: 0.8525 - Val Loss: 0.32746345, Accuracy: 0.8797, F1: 0.9312 Bal: 0.8554\n","Epoch 201:      TX: Train Loss: 0.1024, Acc: 0.9664, F1: 0.9811 Bal: 0.9682 - Val Loss: 0.1751, Accuracy: 0.9528, F1: 0.9734 Bal: 0.9286\n","           WALLETS: Train Loss: 0.32863885, Acc: 0.87215715, F1: 0.92664718 Bal: 0.8549 - Val Loss: 0.32676911, Accuracy: 0.8726, F1: 0.9268 Bal: 0.8571\n","Epoch 202:      TX: Train Loss: 0.1018, Acc: 0.9663, F1: 0.9810 Bal: 0.9684 - Val Loss: 0.1749, Accuracy: 0.9528, F1: 0.9734 Bal: 0.9286\n","           WALLETS: Train Loss: 0.32809684, Acc: 0.87962802, F1: 0.93130119 Bal: 0.8535 - Val Loss: 0.32657301, Accuracy: 0.8798, F1: 0.9313 Bal: 0.8553\n","Epoch 203:      TX: Train Loss: 0.1013, Acc: 0.9667, F1: 0.9812 Bal: 0.9686 - Val Loss: 0.1750, Accuracy: 0.9528, F1: 0.9734 Bal: 0.9286\n","           WALLETS: Train Loss: 0.32751852, Acc: 0.87436685, F1: 0.92801620 Bal: 0.8554 - Val Loss: 0.32582292, Accuracy: 0.8745, F1: 0.9280 Bal: 0.8578\n","Epoch 204:      TX: Train Loss: 0.1007, Acc: 0.9670, F1: 0.9814 Bal: 0.9688 - Val Loss: 0.1750, Accuracy: 0.9530, F1: 0.9735 Bal: 0.9288\n","           WALLETS: Train Loss: 0.32697585, Acc: 0.87619918, F1: 0.92915665 Bal: 0.8552 - Val Loss: 0.32541087, Accuracy: 0.8765, F1: 0.9292 Bal: 0.8576\n","Epoch 205:      TX: Train Loss: 0.1002, Acc: 0.9672, F1: 0.9815 Bal: 0.9691 - Val Loss: 0.1748, Accuracy: 0.9530, F1: 0.9735 Bal: 0.9288\n","           WALLETS: Train Loss: 0.32652739, Acc: 0.87851773, F1: 0.93059768 Bal: 0.8548 - Val Loss: 0.32510155, Accuracy: 0.8785, F1: 0.9305 Bal: 0.8562\n","Epoch 206:      TX: Train Loss: 0.0996, Acc: 0.9676, F1: 0.9817 Bal: 0.9695 - Val Loss: 0.1750, Accuracy: 0.9530, F1: 0.9735 Bal: 0.9278\n","           WALLETS: Train Loss: 0.32610407, Acc: 0.87354683, F1: 0.92748998 Bal: 0.8565 - Val Loss: 0.32452589, Accuracy: 0.8737, F1: 0.9275 Bal: 0.8580\n","Epoch 207:      TX: Train Loss: 0.0991, Acc: 0.9674, F1: 0.9816 Bal: 0.9694 - Val Loss: 0.1747, Accuracy: 0.9530, F1: 0.9735 Bal: 0.9288\n","           WALLETS: Train Loss: 0.32559630, Acc: 0.87913456, F1: 0.93097325 Bal: 0.8552 - Val Loss: 0.32429647, Accuracy: 0.8789, F1: 0.9307 Bal: 0.8567\n","Epoch 208:      TX: Train Loss: 0.0986, Acc: 0.9680, F1: 0.9820 Bal: 0.9699 - Val Loss: 0.1749, Accuracy: 0.9530, F1: 0.9735 Bal: 0.9278\n","           WALLETS: Train Loss: 0.32507643, Acc: 0.87567307, F1: 0.92880932 Bal: 0.8567 - Val Loss: 0.32368833, Accuracy: 0.8759, F1: 0.9288 Bal: 0.8582\n","Epoch 209:      TX: Train Loss: 0.0980, Acc: 0.9679, F1: 0.9819 Bal: 0.9701 - Val Loss: 0.1745, Accuracy: 0.9528, F1: 0.9734 Bal: 0.9277\n","           WALLETS: Train Loss: 0.32461661, Acc: 0.87567670, F1: 0.92880652 Bal: 0.8571 - Val Loss: 0.32327902, Accuracy: 0.8760, F1: 0.9289 Bal: 0.8586\n","Epoch 210:      TX: Train Loss: 0.0975, Acc: 0.9683, F1: 0.9822 Bal: 0.9702 - Val Loss: 0.1747, Accuracy: 0.9533, F1: 0.9737 Bal: 0.9279\n","           WALLETS: Train Loss: 0.32419953, Acc: 0.87928695, F1: 0.93104799 Bal: 0.8567 - Val Loss: 0.32304823, Accuracy: 0.8790, F1: 0.9308 Bal: 0.8574\n","Epoch 211:      TX: Train Loss: 0.0970, Acc: 0.9682, F1: 0.9821 Bal: 0.9707 - Val Loss: 0.1742, Accuracy: 0.9526, F1: 0.9733 Bal: 0.9275\n","           WALLETS: Train Loss: 0.32376486, Acc: 0.87460995, F1: 0.92812725 Bal: 0.8582 - Val Loss: 0.32247293, Accuracy: 0.8748, F1: 0.9281 Bal: 0.8587\n","Epoch 212:      TX: Train Loss: 0.0965, Acc: 0.9687, F1: 0.9823 Bal: 0.9706 - Val Loss: 0.1748, Accuracy: 0.9541, F1: 0.9742 Bal: 0.9284\n","           WALLETS: Train Loss: 0.32327721, Acc: 0.87869189, F1: 0.93066958 Bal: 0.8574 - Val Loss: 0.32219926, Accuracy: 0.8782, F1: 0.9302 Bal: 0.8580\n","Epoch 213:      TX: Train Loss: 0.0960, Acc: 0.9682, F1: 0.9821 Bal: 0.9708 - Val Loss: 0.1740, Accuracy: 0.9535, F1: 0.9738 Bal: 0.9290\n","           WALLETS: Train Loss: 0.32281849, Acc: 0.87732761, F1: 0.92981593 Bal: 0.8581 - Val Loss: 0.32173946, Accuracy: 0.8770, F1: 0.9295 Bal: 0.8588\n","Epoch 214:      TX: Train Loss: 0.0956, Acc: 0.9691, F1: 0.9826 Bal: 0.9709 - Val Loss: 0.1749, Accuracy: 0.9541, F1: 0.9742 Bal: 0.9284\n","           WALLETS: Train Loss: 0.32240787, Acc: 0.87590528, F1: 0.92892132 Bal: 0.8590 - Val Loss: 0.32131284, Accuracy: 0.8756, F1: 0.9286 Bal: 0.8587\n","Epoch 215:      TX: Train Loss: 0.0951, Acc: 0.9685, F1: 0.9823 Bal: 0.9712 - Val Loss: 0.1740, Accuracy: 0.9535, F1: 0.9738 Bal: 0.9280\n","           WALLETS: Train Loss: 0.32199457, Acc: 0.87935226, F1: 0.93107415 Bal: 0.8577 - Val Loss: 0.32109350, Accuracy: 0.8790, F1: 0.9308 Bal: 0.8585\n","Epoch 216:      TX: Train Loss: 0.0946, Acc: 0.9693, F1: 0.9827 Bal: 0.9715 - Val Loss: 0.1747, Accuracy: 0.9544, F1: 0.9743 Bal: 0.9285\n","           WALLETS: Train Loss: 0.32156107, Acc: 0.87578192, F1: 0.92883853 Bal: 0.8595 - Val Loss: 0.32054228, Accuracy: 0.8756, F1: 0.9286 Bal: 0.8595\n","Epoch 217:      TX: Train Loss: 0.0941, Acc: 0.9691, F1: 0.9826 Bal: 0.9718 - Val Loss: 0.1740, Accuracy: 0.9544, F1: 0.9743 Bal: 0.9285\n","           WALLETS: Train Loss: 0.32110569, Acc: 0.87862658, F1: 0.93061009 Bal: 0.8589 - Val Loss: 0.32024604, Accuracy: 0.8779, F1: 0.9301 Bal: 0.8585\n","Epoch 218:      TX: Train Loss: 0.0937, Acc: 0.9695, F1: 0.9828 Bal: 0.9717 - Val Loss: 0.1743, Accuracy: 0.9546, F1: 0.9744 Bal: 0.9286\n","           WALLETS: Train Loss: 0.32067916, Acc: 0.87819117, F1: 0.93033429 Bal: 0.8593 - Val Loss: 0.31984824, Accuracy: 0.8775, F1: 0.9298 Bal: 0.8588\n","Epoch 219:      TX: Train Loss: 0.0932, Acc: 0.9697, F1: 0.9829 Bal: 0.9722 - Val Loss: 0.1742, Accuracy: 0.9546, F1: 0.9744 Bal: 0.9286\n","           WALLETS: Train Loss: 0.32028118, Acc: 0.87663459, F1: 0.92936004 Bal: 0.8600 - Val Loss: 0.31943119, Accuracy: 0.8765, F1: 0.9292 Bal: 0.8604\n","Epoch 220:      TX: Train Loss: 0.0928, Acc: 0.9698, F1: 0.9830 Bal: 0.9728 - Val Loss: 0.1740, Accuracy: 0.9541, F1: 0.9742 Bal: 0.9284\n","           WALLETS: Train Loss: 0.31988320, Acc: 0.87967519, F1: 0.93125308 Bal: 0.8593 - Val Loss: 0.31921276, Accuracy: 0.8792, F1: 0.9309 Bal: 0.8586\n","Epoch 221:      TX: Train Loss: 0.0923, Acc: 0.9701, F1: 0.9832 Bal: 0.9726 - Val Loss: 0.1743, Accuracy: 0.9546, F1: 0.9744 Bal: 0.9286\n","           WALLETS: Train Loss: 0.31948102, Acc: 0.87642414, F1: 0.92922131 Bal: 0.8606 - Val Loss: 0.31871772, Accuracy: 0.8762, F1: 0.9289 Bal: 0.8612\n","Epoch 222:      TX: Train Loss: 0.0919, Acc: 0.9700, F1: 0.9831 Bal: 0.9733 - Val Loss: 0.1738, Accuracy: 0.9537, F1: 0.9739 Bal: 0.9281\n","           WALLETS: Train Loss: 0.31906179, Acc: 0.87921438, F1: 0.93095731 Bal: 0.8601 - Val Loss: 0.31846842, Accuracy: 0.8787, F1: 0.9305 Bal: 0.8594\n","Epoch 223:      TX: Train Loss: 0.0914, Acc: 0.9707, F1: 0.9835 Bal: 0.9732 - Val Loss: 0.1745, Accuracy: 0.9550, F1: 0.9747 Bal: 0.9289\n","           WALLETS: Train Loss: 0.31865615, Acc: 0.87783196, F1: 0.93009040 Bal: 0.8609 - Val Loss: 0.31804347, Accuracy: 0.8773, F1: 0.9297 Bal: 0.8604\n","Epoch 224:      TX: Train Loss: 0.0910, Acc: 0.9701, F1: 0.9831 Bal: 0.9735 - Val Loss: 0.1736, Accuracy: 0.9533, F1: 0.9737 Bal: 0.9289\n","           WALLETS: Train Loss: 0.31826156, Acc: 0.87803878, F1: 0.93021353 Bal: 0.8613 - Val Loss: 0.31769818, Accuracy: 0.8776, F1: 0.9298 Bal: 0.8610\n","Epoch 225:      TX: Train Loss: 0.0906, Acc: 0.9711, F1: 0.9837 Bal: 0.9736 - Val Loss: 0.1747, Accuracy: 0.9557, F1: 0.9751 Bal: 0.9292\n","           WALLETS: Train Loss: 0.31787750, Acc: 0.87933775, F1: 0.93102011 Bal: 0.8611 - Val Loss: 0.31741831, Accuracy: 0.8789, F1: 0.9306 Bal: 0.8606\n","Epoch 226:      TX: Train Loss: 0.0902, Acc: 0.9702, F1: 0.9832 Bal: 0.9737 - Val Loss: 0.1734, Accuracy: 0.9533, F1: 0.9737 Bal: 0.9289\n","           WALLETS: Train Loss: 0.31750283, Acc: 0.87720062, F1: 0.92968153 Bal: 0.8622 - Val Loss: 0.31698880, Accuracy: 0.8771, F1: 0.9295 Bal: 0.8625\n","Epoch 227:      TX: Train Loss: 0.0898, Acc: 0.9714, F1: 0.9839 Bal: 0.9742 - Val Loss: 0.1746, Accuracy: 0.9550, F1: 0.9747 Bal: 0.9289\n","           WALLETS: Train Loss: 0.31711864, Acc: 0.88024847, F1: 0.93157439 Bal: 0.8617 - Val Loss: 0.31678441, Accuracy: 0.8797, F1: 0.9311 Bal: 0.8612\n","Epoch 228:      TX: Train Loss: 0.0893, Acc: 0.9708, F1: 0.9836 Bal: 0.9742 - Val Loss: 0.1736, Accuracy: 0.9530, F1: 0.9735 Bal: 0.9278\n","           WALLETS: Train Loss: 0.31673998, Acc: 0.87714620, F1: 0.92963998 Bal: 0.8628 - Val Loss: 0.31631321, Accuracy: 0.8772, F1: 0.9296 Bal: 0.8632\n","Epoch 229:      TX: Train Loss: 0.0889, Acc: 0.9714, F1: 0.9839 Bal: 0.9745 - Val Loss: 0.1741, Accuracy: 0.9550, F1: 0.9747 Bal: 0.9289\n","           WALLETS: Train Loss: 0.31635240, Acc: 0.88032467, F1: 0.93161523 Bal: 0.8622 - Val Loss: 0.31611249, Accuracy: 0.8799, F1: 0.9313 Bal: 0.8620\n","Epoch 230:      TX: Train Loss: 0.0885, Acc: 0.9715, F1: 0.9839 Bal: 0.9745 - Val Loss: 0.1742, Accuracy: 0.9552, F1: 0.9748 Bal: 0.9290\n","           WALLETS: Train Loss: 0.31597319, Acc: 0.87775577, F1: 0.93001323 Bal: 0.8631 - Val Loss: 0.31565955, Accuracy: 0.8777, F1: 0.9299 Bal: 0.8631\n","Epoch 231:      TX: Train Loss: 0.0881, Acc: 0.9713, F1: 0.9838 Bal: 0.9752 - Val Loss: 0.1737, Accuracy: 0.9539, F1: 0.9741 Bal: 0.9283\n","           WALLETS: Train Loss: 0.31559178, Acc: 0.88003077, F1: 0.93142838 Bal: 0.8626 - Val Loss: 0.31542596, Accuracy: 0.8796, F1: 0.9311 Bal: 0.8623\n","Epoch 232:      TX: Train Loss: 0.0877, Acc: 0.9722, F1: 0.9843 Bal: 0.9753 - Val Loss: 0.1746, Accuracy: 0.9561, F1: 0.9753 Bal: 0.9295\n","           WALLETS: Train Loss: 0.31521896, Acc: 0.87849233, F1: 0.93046569 Bal: 0.8634 - Val Loss: 0.31501997, Accuracy: 0.8784, F1: 0.9303 Bal: 0.8637\n","Epoch 233:      TX: Train Loss: 0.0874, Acc: 0.9713, F1: 0.9838 Bal: 0.9753 - Val Loss: 0.1734, Accuracy: 0.9537, F1: 0.9739 Bal: 0.9291\n","           WALLETS: Train Loss: 0.31484649, Acc: 0.87984209, F1: 0.93130287 Bal: 0.8633 - Val Loss: 0.31475127, Accuracy: 0.8795, F1: 0.9310 Bal: 0.8636\n","Epoch 234:      TX: Train Loss: 0.0870, Acc: 0.9726, F1: 0.9846 Bal: 0.9760 - Val Loss: 0.1745, Accuracy: 0.9561, F1: 0.9753 Bal: 0.9295\n","           WALLETS: Train Loss: 0.31447926, Acc: 0.87898216, F1: 0.93076283 Bal: 0.8639 - Val Loss: 0.31438556, Accuracy: 0.8786, F1: 0.9304 Bal: 0.8636\n","Epoch 235:      TX: Train Loss: 0.0866, Acc: 0.9717, F1: 0.9841 Bal: 0.9756 - Val Loss: 0.1735, Accuracy: 0.9546, F1: 0.9744 Bal: 0.9296\n","           WALLETS: Train Loss: 0.31411055, Acc: 0.87971873, F1: 0.93121550 Bal: 0.8641 - Val Loss: 0.31408927, Accuracy: 0.8794, F1: 0.9309 Bal: 0.8637\n","Epoch 236:      TX: Train Loss: 0.0862, Acc: 0.9726, F1: 0.9846 Bal: 0.9759 - Val Loss: 0.1742, Accuracy: 0.9552, F1: 0.9748 Bal: 0.9280\n","           WALLETS: Train Loss: 0.31374511, Acc: 0.87935952, F1: 0.93098674 Bal: 0.8646 - Val Loss: 0.31374341, Accuracy: 0.8790, F1: 0.9306 Bal: 0.8637\n","Epoch 237:      TX: Train Loss: 0.0858, Acc: 0.9726, F1: 0.9846 Bal: 0.9764 - Val Loss: 0.1740, Accuracy: 0.9552, F1: 0.9748 Bal: 0.9280\n","           WALLETS: Train Loss: 0.31338224, Acc: 0.87998360, F1: 0.93137082 Bal: 0.8648 - Val Loss: 0.31344131, Accuracy: 0.8794, F1: 0.9309 Bal: 0.8636\n","Epoch 238:      TX: Train Loss: 0.0855, Acc: 0.9724, F1: 0.9845 Bal: 0.9767 - Val Loss: 0.1738, Accuracy: 0.9548, F1: 0.9746 Bal: 0.9278\n","           WALLETS: Train Loss: 0.31302136, Acc: 0.87966430, F1: 0.93117081 Bal: 0.8649 - Val Loss: 0.31309414, Accuracy: 0.8791, F1: 0.9308 Bal: 0.8639\n","Epoch 239:      TX: Train Loss: 0.0851, Acc: 0.9732, F1: 0.9849 Bal: 0.9769 - Val Loss: 0.1744, Accuracy: 0.9561, F1: 0.9753 Bal: 0.9285\n","           WALLETS: Train Loss: 0.31266209, Acc: 0.88048432, F1: 0.93167614 Bal: 0.8651 - Val Loss: 0.31280643, Accuracy: 0.8798, F1: 0.9312 Bal: 0.8640\n","Epoch 240:      TX: Train Loss: 0.0847, Acc: 0.9724, F1: 0.9845 Bal: 0.9768 - Val Loss: 0.1735, Accuracy: 0.9548, F1: 0.9746 Bal: 0.9278\n","           WALLETS: Train Loss: 0.31230927, Acc: 0.87946474, F1: 0.93104279 Bal: 0.8653 - Val Loss: 0.31244168, Accuracy: 0.8790, F1: 0.9307 Bal: 0.8643\n","Epoch 241:      TX: Train Loss: 0.0844, Acc: 0.9735, F1: 0.9851 Bal: 0.9771 - Val Loss: 0.1745, Accuracy: 0.9566, F1: 0.9756 Bal: 0.9287\n","           WALLETS: Train Loss: 0.31196055, Acc: 0.88132611, F1: 0.93219366 Bal: 0.8652 - Val Loss: 0.31222180, Accuracy: 0.8803, F1: 0.9315 Bal: 0.8639\n","Epoch 242:      TX: Train Loss: 0.0840, Acc: 0.9729, F1: 0.9847 Bal: 0.9774 - Val Loss: 0.1736, Accuracy: 0.9550, F1: 0.9747 Bal: 0.9279\n","           WALLETS: Train Loss: 0.31163940, Acc: 0.87816215, F1: 0.93023111 Bal: 0.8657 - Val Loss: 0.31179249, Accuracy: 0.8780, F1: 0.9301 Bal: 0.8647\n","Epoch 243:      TX: Train Loss: 0.0837, Acc: 0.9736, F1: 0.9852 Bal: 0.9774 - Val Loss: 0.1744, Accuracy: 0.9566, F1: 0.9756 Bal: 0.9287\n","           WALLETS: Train Loss: 0.31136489, Acc: 0.88340155, F1: 0.93347493 Bal: 0.8651 - Val Loss: 0.31180781, Accuracy: 0.8828, F1: 0.9330 Bal: 0.8648\n","Epoch 244:      TX: Train Loss: 0.0833, Acc: 0.9732, F1: 0.9849 Bal: 0.9777 - Val Loss: 0.1738, Accuracy: 0.9555, F1: 0.9749 Bal: 0.9281\n","           WALLETS: Train Loss: 0.31124625, Acc: 0.87442490, F1: 0.92789777 Bal: 0.8664 - Val Loss: 0.31128949, Accuracy: 0.8742, F1: 0.9276 Bal: 0.8660\n","Epoch 245:      TX: Train Loss: 0.0830, Acc: 0.9739, F1: 0.9853 Bal: 0.9781 - Val Loss: 0.1743, Accuracy: 0.9563, F1: 0.9755 Bal: 0.9286\n","           WALLETS: Train Loss: 0.31123149, Acc: 0.88774836, F1: 0.93615801 Bal: 0.8638 - Val Loss: 0.31196022, Accuracy: 0.8871, F1: 0.9357 Bal: 0.8620\n","Epoch 246:      TX: Train Loss: 0.0826, Acc: 0.9735, F1: 0.9851 Bal: 0.9779 - Val Loss: 0.1741, Accuracy: 0.9563, F1: 0.9755 Bal: 0.9286\n","           WALLETS: Train Loss: 0.31098029, Acc: 0.87178706, F1: 0.92624751 Bal: 0.8667 - Val Loss: 0.31095785, Accuracy: 0.8714, F1: 0.9259 Bal: 0.8668\n","Epoch 247:      TX: Train Loss: 0.0823, Acc: 0.9736, F1: 0.9852 Bal: 0.9782 - Val Loss: 0.1742, Accuracy: 0.9563, F1: 0.9755 Bal: 0.9286\n","           WALLETS: Train Loss: 0.31008688, Acc: 0.88414537, F1: 0.93392599 Bal: 0.8656 - Val Loss: 0.31068256, Accuracy: 0.8835, F1: 0.9334 Bal: 0.8652\n","Epoch 248:      TX: Train Loss: 0.0820, Acc: 0.9743, F1: 0.9855 Bal: 0.9786 - Val Loss: 0.1746, Accuracy: 0.9568, F1: 0.9757 Bal: 0.9289\n","           WALLETS: Train Loss: 0.30968845, Acc: 0.88311128, F1: 0.93328252 Bal: 0.8661 - Val Loss: 0.31025097, Accuracy: 0.8826, F1: 0.9329 Bal: 0.8653\n","Epoch 249:      TX: Train Loss: 0.0817, Acc: 0.9736, F1: 0.9852 Bal: 0.9785 - Val Loss: 0.1739, Accuracy: 0.9559, F1: 0.9752 Bal: 0.9284\n","           WALLETS: Train Loss: 0.30978417, Acc: 0.87370285, F1: 0.92743798 Bal: 0.8671 - Val Loss: 0.30991158, Accuracy: 0.8731, F1: 0.9269 Bal: 0.8664\n","Epoch 250:      TX: Train Loss: 0.0813, Acc: 0.9746, F1: 0.9857 Bal: 0.9787 - Val Loss: 0.1751, Accuracy: 0.9570, F1: 0.9758 Bal: 0.9280\n","           WALLETS: Train Loss: 0.30924317, Acc: 0.88542256, F1: 0.93470790 Bal: 0.8658 - Val Loss: 0.30995882, Accuracy: 0.8849, F1: 0.9343 Bal: 0.8655\n","Epoch 251:      TX: Train Loss: 0.0810, Acc: 0.9737, F1: 0.9852 Bal: 0.9786 - Val Loss: 0.1738, Accuracy: 0.9555, F1: 0.9749 Bal: 0.9281\n","           WALLETS: Train Loss: 0.30869368, Acc: 0.88153655, F1: 0.93230099 Bal: 0.8670 - Val Loss: 0.30923799, Accuracy: 0.8811, F1: 0.9319 Bal: 0.8661\n","Epoch 252:      TX: Train Loss: 0.0807, Acc: 0.9749, F1: 0.9859 Bal: 0.9791 - Val Loss: 0.1754, Accuracy: 0.9574, F1: 0.9761 Bal: 0.9283\n","           WALLETS: Train Loss: 0.30867913, Acc: 0.87539005, F1: 0.92848054 Bal: 0.8677 - Val Loss: 0.30895242, Accuracy: 0.8750, F1: 0.9281 Bal: 0.8672\n","Epoch 253:      TX: Train Loss: 0.0804, Acc: 0.9736, F1: 0.9852 Bal: 0.9787 - Val Loss: 0.1737, Accuracy: 0.9557, F1: 0.9751 Bal: 0.9292\n","           WALLETS: Train Loss: 0.30828804, Acc: 0.88503070, F1: 0.93446102 Bal: 0.8663 - Val Loss: 0.30906108, Accuracy: 0.8845, F1: 0.9340 Bal: 0.8662\n","Epoch 254:      TX: Train Loss: 0.0801, Acc: 0.9753, F1: 0.9861 Bal: 0.9794 - Val Loss: 0.1756, Accuracy: 0.9577, F1: 0.9762 Bal: 0.9284\n","           WALLETS: Train Loss: 0.30778357, Acc: 0.88119548, F1: 0.93208495 Bal: 0.8674 - Val Loss: 0.30838197, Accuracy: 0.8809, F1: 0.9318 Bal: 0.8669\n","Epoch 255:      TX: Train Loss: 0.0798, Acc: 0.9739, F1: 0.9853 Bal: 0.9790 - Val Loss: 0.1739, Accuracy: 0.9555, F1: 0.9749 Bal: 0.9281\n","           WALLETS: Train Loss: 0.30768305, Acc: 0.87666362, F1: 0.92926674 Bal: 0.8682 - Val Loss: 0.30808985, Accuracy: 0.8764, F1: 0.9290 Bal: 0.8678\n","Epoch 256:      TX: Train Loss: 0.0795, Acc: 0.9754, F1: 0.9862 Bal: 0.9796 - Val Loss: 0.1755, Accuracy: 0.9572, F1: 0.9760 Bal: 0.9272\n","           WALLETS: Train Loss: 0.30733973, Acc: 0.88470777, F1: 0.93425368 Bal: 0.8670 - Val Loss: 0.30818233, Accuracy: 0.8844, F1: 0.9340 Bal: 0.8664\n","Epoch 257:      TX: Train Loss: 0.0792, Acc: 0.9746, F1: 0.9857 Bal: 0.9794 - Val Loss: 0.1745, Accuracy: 0.9568, F1: 0.9757 Bal: 0.9289\n","           WALLETS: Train Loss: 0.30689281, Acc: 0.88135150, F1: 0.93217259 Bal: 0.8680 - Val Loss: 0.30758917, Accuracy: 0.8809, F1: 0.9318 Bal: 0.8672\n","Epoch 258:      TX: Train Loss: 0.0789, Acc: 0.9753, F1: 0.9861 Bal: 0.9798 - Val Loss: 0.1750, Accuracy: 0.9570, F1: 0.9758 Bal: 0.9280\n","           WALLETS: Train Loss: 0.30674142, Acc: 0.87779205, F1: 0.92995456 Bal: 0.8691 - Val Loss: 0.30728588, Accuracy: 0.8774, F1: 0.9296 Bal: 0.8681\n","Epoch 259:      TX: Train Loss: 0.0786, Acc: 0.9756, F1: 0.9863 Bal: 0.9799 - Val Loss: 0.1751, Accuracy: 0.9570, F1: 0.9758 Bal: 0.9280\n","           WALLETS: Train Loss: 0.30642337, Acc: 0.88485653, F1: 0.93433593 Bal: 0.8677 - Val Loss: 0.30733871, Accuracy: 0.8847, F1: 0.9341 Bal: 0.8668\n","Epoch 260:      TX: Train Loss: 0.0783, Acc: 0.9752, F1: 0.9861 Bal: 0.9798 - Val Loss: 0.1746, Accuracy: 0.9566, F1: 0.9756 Bal: 0.9278\n","           WALLETS: Train Loss: 0.30601987, Acc: 0.88202276, F1: 0.93257353 Bal: 0.8691 - Val Loss: 0.30679899, Accuracy: 0.8818, F1: 0.9324 Bal: 0.8684\n","Epoch 261:      TX: Train Loss: 0.0780, Acc: 0.9759, F1: 0.9865 Bal: 0.9800 - Val Loss: 0.1755, Accuracy: 0.9577, F1: 0.9762 Bal: 0.9284\n","           WALLETS: Train Loss: 0.30583212, Acc: 0.87867738, F1: 0.93049842 Bal: 0.8695 - Val Loss: 0.30649072, Accuracy: 0.8781, F1: 0.9301 Bal: 0.8684\n","Epoch 262:      TX: Train Loss: 0.0777, Acc: 0.9754, F1: 0.9861 Bal: 0.9801 - Val Loss: 0.1746, Accuracy: 0.9566, F1: 0.9756 Bal: 0.9278\n","           WALLETS: Train Loss: 0.30553660, Acc: 0.88468600, F1: 0.93422003 Bal: 0.8686 - Val Loss: 0.30652672, Accuracy: 0.8848, F1: 0.9342 Bal: 0.8676\n","Epoch 263:      TX: Train Loss: 0.0775, Acc: 0.9761, F1: 0.9866 Bal: 0.9802 - Val Loss: 0.1758, Accuracy: 0.9579, F1: 0.9763 Bal: 0.9285\n","           WALLETS: Train Loss: 0.30516323, Acc: 0.88191391, F1: 0.93250068 Bal: 0.8695 - Val Loss: 0.30603078, Accuracy: 0.8815, F1: 0.9322 Bal: 0.8687\n","Epoch 264:      TX: Train Loss: 0.0772, Acc: 0.9756, F1: 0.9863 Bal: 0.9804 - Val Loss: 0.1748, Accuracy: 0.9568, F1: 0.9757 Bal: 0.9289\n","           WALLETS: Train Loss: 0.30494395, Acc: 0.88006342, F1: 0.93134610 Bal: 0.8703 - Val Loss: 0.30573702, Accuracy: 0.8794, F1: 0.9309 Bal: 0.8688\n","Epoch 265:      TX: Train Loss: 0.0769, Acc: 0.9765, F1: 0.9868 Bal: 0.9805 - Val Loss: 0.1759, Accuracy: 0.9579, F1: 0.9763 Bal: 0.9285\n","           WALLETS: Train Loss: 0.30467042, Acc: 0.88475494, F1: 0.93425133 Bal: 0.8695 - Val Loss: 0.30575344, Accuracy: 0.8848, F1: 0.9342 Bal: 0.8680\n","Epoch 266:      TX: Train Loss: 0.0766, Acc: 0.9759, F1: 0.9864 Bal: 0.9806 - Val Loss: 0.1751, Accuracy: 0.9570, F1: 0.9758 Bal: 0.9280\n","           WALLETS: Train Loss: 0.30432171, Acc: 0.88187399, F1: 0.93246736 Bal: 0.8702 - Val Loss: 0.30527750, Accuracy: 0.8815, F1: 0.9321 Bal: 0.8690\n","Epoch 267:      TX: Train Loss: 0.0764, Acc: 0.9766, F1: 0.9869 Bal: 0.9809 - Val Loss: 0.1759, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9286\n","           WALLETS: Train Loss: 0.30407435, Acc: 0.88084716, F1: 0.93182729 Bal: 0.8706 - Val Loss: 0.30500937, Accuracy: 0.8803, F1: 0.9314 Bal: 0.8693\n","Epoch 268:      TX: Train Loss: 0.0761, Acc: 0.9762, F1: 0.9866 Bal: 0.9809 - Val Loss: 0.1753, Accuracy: 0.9577, F1: 0.9762 Bal: 0.9294\n","           WALLETS: Train Loss: 0.30381969, Acc: 0.88482025, F1: 0.93428396 Bal: 0.8701 - Val Loss: 0.30500957, Accuracy: 0.8849, F1: 0.9342 Bal: 0.8692\n","Epoch 269:      TX: Train Loss: 0.0758, Acc: 0.9768, F1: 0.9869 Bal: 0.9811 - Val Loss: 0.1759, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9286\n","           WALLETS: Train Loss: 0.30349565, Acc: 0.88169257, F1: 0.93235073 Bal: 0.8705 - Val Loss: 0.30455840, Accuracy: 0.8811, F1: 0.9319 Bal: 0.8692\n","Epoch 270:      TX: Train Loss: 0.0756, Acc: 0.9765, F1: 0.9868 Bal: 0.9812 - Val Loss: 0.1755, Accuracy: 0.9579, F1: 0.9763 Bal: 0.9295\n","           WALLETS: Train Loss: 0.30322477, Acc: 0.88159824, F1: 0.93228892 Bal: 0.8708 - Val Loss: 0.30432290, Accuracy: 0.8810, F1: 0.9318 Bal: 0.8693\n","Epoch 271:      TX: Train Loss: 0.0753, Acc: 0.9769, F1: 0.9870 Bal: 0.9813 - Val Loss: 0.1761, Accuracy: 0.9579, F1: 0.9763 Bal: 0.9295\n","           WALLETS: Train Loss: 0.30298349, Acc: 0.88471140, F1: 0.93421151 Bal: 0.8705 - Val Loss: 0.30429059, Accuracy: 0.8846, F1: 0.9341 Bal: 0.8696\n","Epoch 272:      TX: Train Loss: 0.0751, Acc: 0.9767, F1: 0.9869 Bal: 0.9815 - Val Loss: 0.1757, Accuracy: 0.9583, F1: 0.9766 Bal: 0.9307\n","           WALLETS: Train Loss: 0.30268902, Acc: 0.88151841, F1: 0.93223455 Bal: 0.8712 - Val Loss: 0.30386457, Accuracy: 0.8810, F1: 0.9318 Bal: 0.8695\n","Epoch 273:      TX: Train Loss: 0.0748, Acc: 0.9770, F1: 0.9871 Bal: 0.9815 - Val Loss: 0.1762, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9296\n","           WALLETS: Train Loss: 0.30240113, Acc: 0.88243639, F1: 0.93280380 Bal: 0.8710 - Val Loss: 0.30367497, Accuracy: 0.8821, F1: 0.9325 Bal: 0.8694\n","Epoch 274:      TX: Train Loss: 0.0745, Acc: 0.9769, F1: 0.9870 Bal: 0.9816 - Val Loss: 0.1758, Accuracy: 0.9583, F1: 0.9766 Bal: 0.9307\n","           WALLETS: Train Loss: 0.30215883, Acc: 0.88442113, F1: 0.93403084 Bal: 0.8707 - Val Loss: 0.30358696, Accuracy: 0.8843, F1: 0.9338 Bal: 0.8695\n","Epoch 275:      TX: Train Loss: 0.0743, Acc: 0.9772, F1: 0.9872 Bal: 0.9816 - Val Loss: 0.1763, Accuracy: 0.9585, F1: 0.9767 Bal: 0.9308\n","           WALLETS: Train Loss: 0.30189636, Acc: 0.88145310, F1: 0.93218960 Bal: 0.8715 - Val Loss: 0.30320376, Accuracy: 0.8810, F1: 0.9318 Bal: 0.8698\n","Epoch 276:      TX: Train Loss: 0.0740, Acc: 0.9769, F1: 0.9870 Bal: 0.9817 - Val Loss: 0.1759, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9306\n","           WALLETS: Train Loss: 0.30160299, Acc: 0.88349226, F1: 0.93345023 Bal: 0.8714 - Val Loss: 0.30306277, Accuracy: 0.8831, F1: 0.9331 Bal: 0.8695\n","Epoch 277:      TX: Train Loss: 0.0738, Acc: 0.9774, F1: 0.9873 Bal: 0.9820 - Val Loss: 0.1768, Accuracy: 0.9592, F1: 0.9771 Bal: 0.9312\n","           WALLETS: Train Loss: 0.30134463, Acc: 0.88410183, F1: 0.93382201 Bal: 0.8716 - Val Loss: 0.30286902, Accuracy: 0.8837, F1: 0.9335 Bal: 0.8692\n","Epoch 278:      TX: Train Loss: 0.0736, Acc: 0.9767, F1: 0.9869 Bal: 0.9819 - Val Loss: 0.1756, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9306\n","           WALLETS: Train Loss: 0.30110005, Acc: 0.88189576, F1: 0.93245234 Bal: 0.8724 - Val Loss: 0.30253112, Accuracy: 0.8814, F1: 0.9321 Bal: 0.8703\n","Epoch 279:      TX: Train Loss: 0.0733, Acc: 0.9778, F1: 0.9875 Bal: 0.9822 - Val Loss: 0.1775, Accuracy: 0.9594, F1: 0.9772 Bal: 0.9303\n","           WALLETS: Train Loss: 0.30082238, Acc: 0.88445015, F1: 0.93403293 Bal: 0.8719 - Val Loss: 0.30242655, Accuracy: 0.8840, F1: 0.9337 Bal: 0.8695\n","Epoch 280:      TX: Train Loss: 0.0731, Acc: 0.9765, F1: 0.9868 Bal: 0.9818 - Val Loss: 0.1749, Accuracy: 0.9577, F1: 0.9762 Bal: 0.9313\n","           WALLETS: Train Loss: 0.30054957, Acc: 0.88351040, F1: 0.93344997 Bal: 0.8722 - Val Loss: 0.30213138, Accuracy: 0.8830, F1: 0.9330 Bal: 0.8696\n","Epoch 281:      TX: Train Loss: 0.0729, Acc: 0.9783, F1: 0.9878 Bal: 0.9825 - Val Loss: 0.1786, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9289\n","           WALLETS: Train Loss: 0.30030158, Acc: 0.88260693, F1: 0.93288972 Bal: 0.8725 - Val Loss: 0.30186254, Accuracy: 0.8823, F1: 0.9326 Bal: 0.8703\n","Epoch 282:      TX: Train Loss: 0.0727, Acc: 0.9762, F1: 0.9866 Bal: 0.9817 - Val Loss: 0.1745, Accuracy: 0.9572, F1: 0.9759 Bal: 0.9311\n","           WALLETS: Train Loss: 0.30004725, Acc: 0.88494724, F1: 0.93433508 Bal: 0.8722 - Val Loss: 0.30176809, Accuracy: 0.8848, F1: 0.9341 Bal: 0.8700\n","Epoch 283:      TX: Train Loss: 0.0724, Acc: 0.9785, F1: 0.9879 Bal: 0.9827 - Val Loss: 0.1789, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9298\n","           WALLETS: Train Loss: 0.29978058, Acc: 0.88299517, F1: 0.93312457 Bal: 0.8728 - Val Loss: 0.30142391, Accuracy: 0.8826, F1: 0.9328 Bal: 0.8704\n","Epoch 284:      TX: Train Loss: 0.0721, Acc: 0.9769, F1: 0.9870 Bal: 0.9820 - Val Loss: 0.1758, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9316\n","           WALLETS: Train Loss: 0.29951364, Acc: 0.88370633, F1: 0.93356576 Bal: 0.8726 - Val Loss: 0.30124143, Accuracy: 0.8835, F1: 0.9333 Bal: 0.8707\n","Epoch 285:      TX: Train Loss: 0.0719, Acc: 0.9774, F1: 0.9873 Bal: 0.9823 - Val Loss: 0.1768, Accuracy: 0.9590, F1: 0.9770 Bal: 0.9311\n","           WALLETS: Train Loss: 0.29926303, Acc: 0.88460255, F1: 0.93411720 Bal: 0.8727 - Val Loss: 0.30107191, Accuracy: 0.8842, F1: 0.9338 Bal: 0.8704\n","Epoch 286:      TX: Train Loss: 0.0717, Acc: 0.9782, F1: 0.9878 Bal: 0.9826 - Val Loss: 0.1782, Accuracy: 0.9596, F1: 0.9773 Bal: 0.9305\n","           WALLETS: Train Loss: 0.29901674, Acc: 0.88291171, F1: 0.93306868 Bal: 0.8732 - Val Loss: 0.30075958, Accuracy: 0.8827, F1: 0.9328 Bal: 0.8712\n","Epoch 287:      TX: Train Loss: 0.0715, Acc: 0.9768, F1: 0.9869 Bal: 0.9824 - Val Loss: 0.1755, Accuracy: 0.9577, F1: 0.9762 Bal: 0.9313\n","           WALLETS: Train Loss: 0.29875433, Acc: 0.88482751, F1: 0.93425326 Bal: 0.8728 - Val Loss: 0.30064464, Accuracy: 0.8845, F1: 0.9340 Bal: 0.8709\n","Epoch 288:      TX: Train Loss: 0.0713, Acc: 0.9785, F1: 0.9879 Bal: 0.9827 - Val Loss: 0.1788, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9306\n","           WALLETS: Train Loss: 0.29849213, Acc: 0.88384784, F1: 0.93364288 Bal: 0.8734 - Val Loss: 0.30036074, Accuracy: 0.8836, F1: 0.9334 Bal: 0.8710\n","Epoch 289:      TX: Train Loss: 0.0710, Acc: 0.9774, F1: 0.9873 Bal: 0.9826 - Val Loss: 0.1766, Accuracy: 0.9588, F1: 0.9768 Bal: 0.9319\n","           WALLETS: Train Loss: 0.29823861, Acc: 0.88379704, F1: 0.93360946 Bal: 0.8736 - Val Loss: 0.30014291, Accuracy: 0.8834, F1: 0.9333 Bal: 0.8711\n","Epoch 290:      TX: Train Loss: 0.0708, Acc: 0.9776, F1: 0.9874 Bal: 0.9827 - Val Loss: 0.1772, Accuracy: 0.9594, F1: 0.9772 Bal: 0.9323\n","           WALLETS: Train Loss: 0.29798889, Acc: 0.88512866, F1: 0.93443075 Bal: 0.8735 - Val Loss: 0.30001059, Accuracy: 0.8848, F1: 0.9342 Bal: 0.8713\n","Epoch 291:      TX: Train Loss: 0.0706, Acc: 0.9785, F1: 0.9879 Bal: 0.9829 - Val Loss: 0.1787, Accuracy: 0.9594, F1: 0.9772 Bal: 0.9303\n","           WALLETS: Train Loss: 0.29773641, Acc: 0.88365191, F1: 0.93350255 Bal: 0.8749 - Val Loss: 0.29970208, Accuracy: 0.8834, F1: 0.9333 Bal: 0.8736\n","Epoch 292:      TX: Train Loss: 0.0704, Acc: 0.9773, F1: 0.9873 Bal: 0.9829 - Val Loss: 0.1764, Accuracy: 0.9579, F1: 0.9763 Bal: 0.9314\n","           WALLETS: Train Loss: 0.29747555, Acc: 0.88517220, F1: 0.93445478 Bal: 0.8737 - Val Loss: 0.29957581, Accuracy: 0.8849, F1: 0.9342 Bal: 0.8715\n","Epoch 293:      TX: Train Loss: 0.0702, Acc: 0.9785, F1: 0.9879 Bal: 0.9830 - Val Loss: 0.1789, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9316\n","           WALLETS: Train Loss: 0.29721883, Acc: 0.88454449, F1: 0.93404990 Bal: 0.8751 - Val Loss: 0.29931438, Accuracy: 0.8843, F1: 0.9338 Bal: 0.8735\n","Epoch 294:      TX: Train Loss: 0.0700, Acc: 0.9777, F1: 0.9875 Bal: 0.9828 - Val Loss: 0.1775, Accuracy: 0.9594, F1: 0.9772 Bal: 0.9323\n","           WALLETS: Train Loss: 0.29696545, Acc: 0.88459892, F1: 0.93408195 Bal: 0.8753 - Val Loss: 0.29910529, Accuracy: 0.8845, F1: 0.9339 Bal: 0.8740\n","Epoch 295:      TX: Train Loss: 0.0697, Acc: 0.9777, F1: 0.9875 Bal: 0.9828 - Val Loss: 0.1774, Accuracy: 0.9592, F1: 0.9771 Bal: 0.9322\n","           WALLETS: Train Loss: 0.29671645, Acc: 0.88544796, F1: 0.93460488 Bal: 0.8752 - Val Loss: 0.29895079, Accuracy: 0.8854, F1: 0.9345 Bal: 0.8741\n","Epoch 296:      TX: Train Loss: 0.0696, Acc: 0.9787, F1: 0.9881 Bal: 0.9832 - Val Loss: 0.1790, Accuracy: 0.9601, F1: 0.9776 Bal: 0.9317\n","           WALLETS: Train Loss: 0.29647252, Acc: 0.88439573, F1: 0.93395000 Bal: 0.8758 - Val Loss: 0.29867530, Accuracy: 0.8842, F1: 0.9337 Bal: 0.8743\n","Epoch 297:      TX: Train Loss: 0.0693, Acc: 0.9777, F1: 0.9875 Bal: 0.9832 - Val Loss: 0.1769, Accuracy: 0.9585, F1: 0.9767 Bal: 0.9318\n","           WALLETS: Train Loss: 0.29622474, Acc: 0.88573098, F1: 0.93477401 Bal: 0.8756 - Val Loss: 0.29854804, Accuracy: 0.8855, F1: 0.9345 Bal: 0.8738\n","Epoch 298:      TX: Train Loss: 0.0691, Acc: 0.9786, F1: 0.9880 Bal: 0.9834 - Val Loss: 0.1788, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.29598027, Acc: 0.88477671, F1: 0.93418200 Bal: 0.8760 - Val Loss: 0.29827067, Accuracy: 0.8844, F1: 0.9339 Bal: 0.8743\n","Epoch 299:      TX: Train Loss: 0.0689, Acc: 0.9784, F1: 0.9879 Bal: 0.9834 - Val Loss: 0.1780, Accuracy: 0.9596, F1: 0.9773 Bal: 0.9324\n","           WALLETS: Train Loss: 0.29573524, Acc: 0.88544070, F1: 0.93459206 Bal: 0.8759 - Val Loss: 0.29810718, Accuracy: 0.8854, F1: 0.9345 Bal: 0.8746\n","Epoch 300:      TX: Train Loss: 0.0687, Acc: 0.9782, F1: 0.9878 Bal: 0.9835 - Val Loss: 0.1776, Accuracy: 0.9592, F1: 0.9771 Bal: 0.9322\n","           WALLETS: Train Loss: 0.29549438, Acc: 0.88532822, F1: 0.93452065 Bal: 0.8761 - Val Loss: 0.29789126, Accuracy: 0.8851, F1: 0.9343 Bal: 0.8742\n","Epoch 301:      TX: Train Loss: 0.0685, Acc: 0.9788, F1: 0.9881 Bal: 0.9835 - Val Loss: 0.1791, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.29525623, Acc: 0.88523751, F1: 0.93446084 Bal: 0.8764 - Val Loss: 0.29767010, Accuracy: 0.8849, F1: 0.9342 Bal: 0.8744\n","Epoch 302:      TX: Train Loss: 0.0683, Acc: 0.9781, F1: 0.9877 Bal: 0.9834 - Val Loss: 0.1774, Accuracy: 0.9590, F1: 0.9770 Bal: 0.9321\n","           WALLETS: Train Loss: 0.29501754, Acc: 0.88593779, F1: 0.93489247 Bal: 0.8763 - Val Loss: 0.29751718, Accuracy: 0.8855, F1: 0.9345 Bal: 0.8740\n","Epoch 303:      TX: Train Loss: 0.0681, Acc: 0.9788, F1: 0.9881 Bal: 0.9835 - Val Loss: 0.1789, Accuracy: 0.9601, F1: 0.9776 Bal: 0.9327\n","           WALLETS: Train Loss: 0.29478145, Acc: 0.88509238, F1: 0.93436708 Bal: 0.8767 - Val Loss: 0.29725254, Accuracy: 0.8848, F1: 0.9341 Bal: 0.8750\n","Epoch 304:      TX: Train Loss: 0.0679, Acc: 0.9786, F1: 0.9880 Bal: 0.9837 - Val Loss: 0.1781, Accuracy: 0.9596, F1: 0.9773 Bal: 0.9324\n","           WALLETS: Train Loss: 0.29454234, Acc: 0.88640223, F1: 0.93517502 Bal: 0.8765 - Val Loss: 0.29713202, Accuracy: 0.8858, F1: 0.9347 Bal: 0.8743\n","Epoch 305:      TX: Train Loss: 0.0677, Acc: 0.9785, F1: 0.9879 Bal: 0.9836 - Val Loss: 0.1779, Accuracy: 0.9596, F1: 0.9773 Bal: 0.9324\n","           WALLETS: Train Loss: 0.29430646, Acc: 0.88511415, F1: 0.93437788 Bal: 0.8769 - Val Loss: 0.29684749, Accuracy: 0.8846, F1: 0.9340 Bal: 0.8744\n","Epoch 306:      TX: Train Loss: 0.0675, Acc: 0.9791, F1: 0.9882 Bal: 0.9838 - Val Loss: 0.1790, Accuracy: 0.9601, F1: 0.9776 Bal: 0.9327\n","           WALLETS: Train Loss: 0.29406837, Acc: 0.88661630, F1: 0.93530563 Bal: 0.8766 - Val Loss: 0.29674491, Accuracy: 0.8862, F1: 0.9350 Bal: 0.8748\n","Epoch 307:      TX: Train Loss: 0.0674, Acc: 0.9785, F1: 0.9879 Bal: 0.9837 - Val Loss: 0.1778, Accuracy: 0.9590, F1: 0.9770 Bal: 0.9321\n","           WALLETS: Train Loss: 0.29383451, Acc: 0.88518309, F1: 0.93441794 Bal: 0.8771 - Val Loss: 0.29645696, Accuracy: 0.8846, F1: 0.9340 Bal: 0.8746\n","Epoch 308:      TX: Train Loss: 0.0672, Acc: 0.9793, F1: 0.9884 Bal: 0.9841 - Val Loss: 0.1791, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.29359719, Acc: 0.88675056, F1: 0.93538744 Bal: 0.8767 - Val Loss: 0.29635447, Accuracy: 0.8862, F1: 0.9350 Bal: 0.8749\n","Epoch 309:      TX: Train Loss: 0.0670, Acc: 0.9788, F1: 0.9881 Bal: 0.9839 - Val Loss: 0.1782, Accuracy: 0.9592, F1: 0.9771 Bal: 0.9322\n","           WALLETS: Train Loss: 0.29336470, Acc: 0.88530645, F1: 0.93449085 Bal: 0.8774 - Val Loss: 0.29606506, Accuracy: 0.8849, F1: 0.9342 Bal: 0.8749\n","Epoch 310:      TX: Train Loss: 0.0668, Acc: 0.9791, F1: 0.9883 Bal: 0.9841 - Val Loss: 0.1786, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9325\n","           WALLETS: Train Loss: 0.29312980, Acc: 0.88706985, F1: 0.93557948 Bal: 0.8770 - Val Loss: 0.29597029, Accuracy: 0.8866, F1: 0.9352 Bal: 0.8752\n","Epoch 311:      TX: Train Loss: 0.0666, Acc: 0.9792, F1: 0.9883 Bal: 0.9842 - Val Loss: 0.1787, Accuracy: 0.9596, F1: 0.9773 Bal: 0.9324\n","           WALLETS: Train Loss: 0.29290080, Acc: 0.88524840, F1: 0.93445389 Bal: 0.8775 - Val Loss: 0.29566628, Accuracy: 0.8849, F1: 0.9342 Bal: 0.8754\n","Epoch 312:      TX: Train Loss: 0.0664, Acc: 0.9790, F1: 0.9882 Bal: 0.9840 - Val Loss: 0.1784, Accuracy: 0.9592, F1: 0.9771 Bal: 0.9322\n","           WALLETS: Train Loss: 0.29267049, Acc: 0.88767580, F1: 0.93594860 Bal: 0.8772 - Val Loss: 0.29560229, Accuracy: 0.8870, F1: 0.9354 Bal: 0.8754\n","Epoch 313:      TX: Train Loss: 0.0662, Acc: 0.9796, F1: 0.9886 Bal: 0.9844 - Val Loss: 0.1793, Accuracy: 0.9605, F1: 0.9778 Bal: 0.9329\n","           WALLETS: Train Loss: 0.29245043, Acc: 0.88501981, F1: 0.93430793 Bal: 0.8779 - Val Loss: 0.29525611, Accuracy: 0.8846, F1: 0.9340 Bal: 0.8755\n","Epoch 314:      TX: Train Loss: 0.0661, Acc: 0.9791, F1: 0.9883 Bal: 0.9842 - Val Loss: 0.1783, Accuracy: 0.9590, F1: 0.9770 Bal: 0.9321\n","           WALLETS: Train Loss: 0.29223269, Acc: 0.88860829, F1: 0.93651988 Bal: 0.8772 - Val Loss: 0.29528043, Accuracy: 0.8877, F1: 0.9359 Bal: 0.8755\n","Epoch 315:      TX: Train Loss: 0.0659, Acc: 0.9797, F1: 0.9886 Bal: 0.9844 - Val Loss: 0.1793, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9333\n","           WALLETS: Train Loss: 0.29204288, Acc: 0.88409820, F1: 0.93373495 Bal: 0.8783 - Val Loss: 0.29484943, Accuracy: 0.8837, F1: 0.9334 Bal: 0.8760\n","Epoch 316:      TX: Train Loss: 0.0657, Acc: 0.9793, F1: 0.9884 Bal: 0.9845 - Val Loss: 0.1784, Accuracy: 0.9594, F1: 0.9772 Bal: 0.9323\n","           WALLETS: Train Loss: 0.29187158, Acc: 0.89026284, F1: 0.93753176 Bal: 0.8773 - Val Loss: 0.29509291, Accuracy: 0.8894, F1: 0.9369 Bal: 0.8747\n","Epoch 317:      TX: Train Loss: 0.0655, Acc: 0.9797, F1: 0.9886 Bal: 0.9847 - Val Loss: 0.1790, Accuracy: 0.9605, F1: 0.9778 Bal: 0.9329\n","           WALLETS: Train Loss: 0.29176801, Acc: 0.88208807, F1: 0.93248822 Bal: 0.8787 - Val Loss: 0.29451019, Accuracy: 0.8813, F1: 0.9319 Bal: 0.8758\n","Epoch 318:      TX: Train Loss: 0.0654, Acc: 0.9796, F1: 0.9885 Bal: 0.9847 - Val Loss: 0.1788, Accuracy: 0.9605, F1: 0.9778 Bal: 0.9329\n","           WALLETS: Train Loss: 0.29167587, Acc: 0.89281723, F1: 0.93909379 Bal: 0.8770 - Val Loss: 0.29511979, Accuracy: 0.8918, F1: 0.9384 Bal: 0.8744\n","Epoch 319:      TX: Train Loss: 0.0652, Acc: 0.9798, F1: 0.9887 Bal: 0.9849 - Val Loss: 0.1790, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9331\n","           WALLETS: Train Loss: 0.29158631, Acc: 0.88017228, F1: 0.93130454 Bal: 0.8785 - Val Loss: 0.29427490, Accuracy: 0.8792, F1: 0.9306 Bal: 0.8761\n","Epoch 320:      TX: Train Loss: 0.0650, Acc: 0.9799, F1: 0.9887 Bal: 0.9849 - Val Loss: 0.1790, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9333\n","           WALLETS: Train Loss: 0.29125383, Acc: 0.89319821, F1: 0.93932266 Bal: 0.8773 - Val Loss: 0.29478973, Accuracy: 0.8920, F1: 0.9386 Bal: 0.8749\n","Epoch 321:      TX: Train Loss: 0.0648, Acc: 0.9799, F1: 0.9887 Bal: 0.9851 - Val Loss: 0.1788, Accuracy: 0.9605, F1: 0.9778 Bal: 0.9329\n","           WALLETS: Train Loss: 0.29079381, Acc: 0.88322013, F1: 0.93318442 Bal: 0.8789 - Val Loss: 0.29374060, Accuracy: 0.8825, F1: 0.9327 Bal: 0.8763\n","Epoch 322:      TX: Train Loss: 0.0647, Acc: 0.9800, F1: 0.9888 Bal: 0.9851 - Val Loss: 0.1790, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9331\n","           WALLETS: Train Loss: 0.29040202, Acc: 0.88787536, F1: 0.93605539 Bal: 0.8785 - Val Loss: 0.29366124, Accuracy: 0.8872, F1: 0.9356 Bal: 0.8760\n","Epoch 323:      TX: Train Loss: 0.0645, Acc: 0.9800, F1: 0.9888 Bal: 0.9852 - Val Loss: 0.1789, Accuracy: 0.9605, F1: 0.9778 Bal: 0.9329\n","           WALLETS: Train Loss: 0.29026276, Acc: 0.89015036, F1: 0.93745313 Bal: 0.8781 - Val Loss: 0.29368696, Accuracy: 0.8891, F1: 0.9368 Bal: 0.8759\n","Epoch 324:      TX: Train Loss: 0.0643, Acc: 0.9802, F1: 0.9889 Bal: 0.9854 - Val Loss: 0.1792, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9331\n","           WALLETS: Train Loss: 0.29022837, Acc: 0.88257427, F1: 0.93278280 Bal: 0.8792 - Val Loss: 0.29321778, Accuracy: 0.8818, F1: 0.9322 Bal: 0.8764\n","Epoch 325:      TX: Train Loss: 0.0642, Acc: 0.9801, F1: 0.9888 Bal: 0.9853 - Val Loss: 0.1789, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.29001528, Acc: 0.89217863, F1: 0.93869526 Bal: 0.8778 - Val Loss: 0.29364395, Accuracy: 0.8910, F1: 0.9379 Bal: 0.8754\n","Epoch 326:      TX: Train Loss: 0.0640, Acc: 0.9805, F1: 0.9890 Bal: 0.9855 - Val Loss: 0.1795, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28965557, Acc: 0.88438484, F1: 0.93389596 Bal: 0.8795 - Val Loss: 0.29281163, Accuracy: 0.8834, F1: 0.9332 Bal: 0.8765\n","Epoch 327:      TX: Train Loss: 0.0639, Acc: 0.9802, F1: 0.9889 Bal: 0.9853 - Val Loss: 0.1790, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.28931916, Acc: 0.88814386, F1: 0.93621406 Bal: 0.8790 - Val Loss: 0.29273745, Accuracy: 0.8874, F1: 0.9357 Bal: 0.8764\n","Epoch 328:      TX: Train Loss: 0.0637, Acc: 0.9806, F1: 0.9891 Bal: 0.9856 - Val Loss: 0.1797, Accuracy: 0.9616, F1: 0.9785 Bal: 0.9335\n","           WALLETS: Train Loss: 0.28915805, Acc: 0.89006691, F1: 0.93739720 Bal: 0.8785 - Val Loss: 0.29273662, Accuracy: 0.8890, F1: 0.9367 Bal: 0.8762\n","Epoch 329:      TX: Train Loss: 0.0635, Acc: 0.9802, F1: 0.9889 Bal: 0.9856 - Val Loss: 0.1789, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.28905517, Acc: 0.88406191, F1: 0.93369385 Bal: 0.8797 - Val Loss: 0.29228297, Accuracy: 0.8832, F1: 0.9331 Bal: 0.8768\n","Epoch 330:      TX: Train Loss: 0.0634, Acc: 0.9808, F1: 0.9892 Bal: 0.9858 - Val Loss: 0.1800, Accuracy: 0.9620, F1: 0.9787 Bal: 0.9338\n","           WALLETS: Train Loss: 0.28881571, Acc: 0.89162712, F1: 0.93835065 Bal: 0.8785 - Val Loss: 0.29257005, Accuracy: 0.8904, F1: 0.9375 Bal: 0.8760\n","Epoch 331:      TX: Train Loss: 0.0632, Acc: 0.9802, F1: 0.9889 Bal: 0.9859 - Val Loss: 0.1787, Accuracy: 0.9603, F1: 0.9777 Bal: 0.9328\n","           WALLETS: Train Loss: 0.28849581, Acc: 0.88578540, F1: 0.93475440 Bal: 0.8798 - Val Loss: 0.29191512, Accuracy: 0.8847, F1: 0.9340 Bal: 0.8765\n","Epoch 332:      TX: Train Loss: 0.0631, Acc: 0.9811, F1: 0.9894 Bal: 0.9860 - Val Loss: 0.1806, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9340\n","           WALLETS: Train Loss: 0.28822297, Acc: 0.88790076, F1: 0.93605678 Bal: 0.8796 - Val Loss: 0.29180923, Accuracy: 0.8868, F1: 0.9353 Bal: 0.8762\n","Epoch 333:      TX: Train Loss: 0.0629, Acc: 0.9800, F1: 0.9888 Bal: 0.9859 - Val Loss: 0.1782, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9325\n","           WALLETS: Train Loss: 0.28806144, Acc: 0.89020841, F1: 0.93747585 Bal: 0.8792 - Val Loss: 0.29183593, Accuracy: 0.8889, F1: 0.9366 Bal: 0.8761\n","Epoch 334:      TX: Train Loss: 0.0628, Acc: 0.9815, F1: 0.9896 Bal: 0.9862 - Val Loss: 0.1814, Accuracy: 0.9631, F1: 0.9793 Bal: 0.9344\n","           WALLETS: Train Loss: 0.28791934, Acc: 0.88498716, F1: 0.93425725 Bal: 0.8803 - Val Loss: 0.29137930, Accuracy: 0.8842, F1: 0.9337 Bal: 0.8772\n","Epoch 335:      TX: Train Loss: 0.0627, Acc: 0.9797, F1: 0.9886 Bal: 0.9863 - Val Loss: 0.1775, Accuracy: 0.9592, F1: 0.9771 Bal: 0.9322\n","           WALLETS: Train Loss: 0.28767782, Acc: 0.89108649, F1: 0.93800894 Bal: 0.8795 - Val Loss: 0.29156569, Accuracy: 0.8898, F1: 0.9371 Bal: 0.8763\n","Epoch 336:      TX: Train Loss: 0.0625, Acc: 0.9818, F1: 0.9898 Bal: 0.9861 - Val Loss: 0.1820, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9345\n","           WALLETS: Train Loss: 0.28740197, Acc: 0.88678321, F1: 0.93536044 Bal: 0.8804 - Val Loss: 0.29103300, Accuracy: 0.8854, F1: 0.9344 Bal: 0.8767\n","Epoch 337:      TX: Train Loss: 0.0624, Acc: 0.9799, F1: 0.9887 Bal: 0.9865 - Val Loss: 0.1775, Accuracy: 0.9590, F1: 0.9770 Bal: 0.9321\n","           WALLETS: Train Loss: 0.28716201, Acc: 0.88824908, F1: 0.93626048 Bal: 0.8804 - Val Loss: 0.29090524, Accuracy: 0.8871, F1: 0.9355 Bal: 0.8767\n","Epoch 338:      TX: Train Loss: 0.0622, Acc: 0.9816, F1: 0.9897 Bal: 0.9863 - Val Loss: 0.1813, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9342\n","           WALLETS: Train Loss: 0.28698736, Acc: 0.89024833, F1: 0.93749044 Bal: 0.8800 - Val Loss: 0.29088038, Accuracy: 0.8892, F1: 0.9368 Bal: 0.8768\n","Epoch 339:      TX: Train Loss: 0.0620, Acc: 0.9808, F1: 0.9892 Bal: 0.9862 - Val Loss: 0.1791, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9330\n","           WALLETS: Train Loss: 0.28682736, Acc: 0.88614824, F1: 0.93496680 Bal: 0.8807 - Val Loss: 0.29046375, Accuracy: 0.8851, F1: 0.9343 Bal: 0.8771\n","Epoch 340:      TX: Train Loss: 0.0619, Acc: 0.9810, F1: 0.9893 Bal: 0.9863 - Val Loss: 0.1796, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28661123, Acc: 0.89101755, F1: 0.93795830 Bal: 0.8802 - Val Loss: 0.29059601, Accuracy: 0.8900, F1: 0.9373 Bal: 0.8767\n","Epoch 341:      TX: Train Loss: 0.0617, Acc: 0.9816, F1: 0.9897 Bal: 0.9866 - Val Loss: 0.1809, Accuracy: 0.9627, F1: 0.9791 Bal: 0.9341\n","           WALLETS: Train Loss: 0.28637317, Acc: 0.88722587, F1: 0.93562891 Bal: 0.8807 - Val Loss: 0.29011196, Accuracy: 0.8859, F1: 0.9348 Bal: 0.8769\n","Epoch 342:      TX: Train Loss: 0.0616, Acc: 0.9806, F1: 0.9891 Bal: 0.9869 - Val Loss: 0.1784, Accuracy: 0.9594, F1: 0.9772 Bal: 0.9323\n","           WALLETS: Train Loss: 0.28614110, Acc: 0.88922875, F1: 0.93685741 Bal: 0.8807 - Val Loss: 0.29002005, Accuracy: 0.8882, F1: 0.9362 Bal: 0.8772\n","Epoch 343:      TX: Train Loss: 0.0615, Acc: 0.9820, F1: 0.9899 Bal: 0.9866 - Val Loss: 0.1818, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9347\n","           WALLETS: Train Loss: 0.28594661, Acc: 0.88978752, F1: 0.93719905 Bal: 0.8808 - Val Loss: 0.28987944, Accuracy: 0.8888, F1: 0.9365 Bal: 0.8773\n","Epoch 344:      TX: Train Loss: 0.0613, Acc: 0.9807, F1: 0.9891 Bal: 0.9869 - Val Loss: 0.1787, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9325\n","           WALLETS: Train Loss: 0.28577510, Acc: 0.88725853, F1: 0.93564662 Bal: 0.8809 - Val Loss: 0.28956234, Accuracy: 0.8863, F1: 0.9350 Bal: 0.8771\n","Epoch 345:      TX: Train Loss: 0.0612, Acc: 0.9818, F1: 0.9898 Bal: 0.9869 - Val Loss: 0.1812, Accuracy: 0.9631, F1: 0.9793 Bal: 0.9344\n","           WALLETS: Train Loss: 0.28558624, Acc: 0.89107560, F1: 0.93798828 Bal: 0.8807 - Val Loss: 0.28965342, Accuracy: 0.8901, F1: 0.9373 Bal: 0.8768\n","Epoch 346:      TX: Train Loss: 0.0610, Acc: 0.9814, F1: 0.9896 Bal: 0.9872 - Val Loss: 0.1801, Accuracy: 0.9614, F1: 0.9783 Bal: 0.9334\n","           WALLETS: Train Loss: 0.28538436, Acc: 0.88726216, F1: 0.93564136 Bal: 0.8815 - Val Loss: 0.28920850, Accuracy: 0.8864, F1: 0.9350 Bal: 0.8777\n","Epoch 347:      TX: Train Loss: 0.0609, Acc: 0.9813, F1: 0.9895 Bal: 0.9873 - Val Loss: 0.1799, Accuracy: 0.9614, F1: 0.9783 Bal: 0.9334\n","           WALLETS: Train Loss: 0.28516001, Acc: 0.89056400, F1: 0.93766907 Bal: 0.8812 - Val Loss: 0.28922415, Accuracy: 0.8896, F1: 0.9370 Bal: 0.8775\n","Epoch 348:      TX: Train Loss: 0.0608, Acc: 0.9821, F1: 0.9899 Bal: 0.9873 - Val Loss: 0.1814, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9346\n","           WALLETS: Train Loss: 0.28494662, Acc: 0.88886591, F1: 0.93662437 Bal: 0.8816 - Val Loss: 0.28890598, Accuracy: 0.8878, F1: 0.9359 Bal: 0.8778\n","Epoch 349:      TX: Train Loss: 0.0606, Acc: 0.9810, F1: 0.9893 Bal: 0.9872 - Val Loss: 0.1792, Accuracy: 0.9601, F1: 0.9776 Bal: 0.9327\n","           WALLETS: Train Loss: 0.28474641, Acc: 0.88919609, F1: 0.93682664 Bal: 0.8816 - Val Loss: 0.28874716, Accuracy: 0.8882, F1: 0.9362 Bal: 0.8780\n","Epoch 350:      TX: Train Loss: 0.0605, Acc: 0.9821, F1: 0.9900 Bal: 0.9873 - Val Loss: 0.1818, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9347\n","           WALLETS: Train Loss: 0.28455976, Acc: 0.89046240, F1: 0.93759986 Bal: 0.8818 - Val Loss: 0.28867209, Accuracy: 0.8895, F1: 0.9369 Bal: 0.8780\n","Epoch 351:      TX: Train Loss: 0.0604, Acc: 0.9811, F1: 0.9894 Bal: 0.9873 - Val Loss: 0.1795, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28438261, Acc: 0.88811483, F1: 0.93615920 Bal: 0.8820 - Val Loss: 0.28835237, Accuracy: 0.8871, F1: 0.9355 Bal: 0.8778\n","Epoch 352:      TX: Train Loss: 0.0602, Acc: 0.9822, F1: 0.9900 Bal: 0.9877 - Val Loss: 0.1812, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9340\n","           WALLETS: Train Loss: 0.28419533, Acc: 0.89135136, F1: 0.93814118 Bal: 0.8820 - Val Loss: 0.28839889, Accuracy: 0.8905, F1: 0.9375 Bal: 0.8781\n","Epoch 353:      TX: Train Loss: 0.0601, Acc: 0.9817, F1: 0.9897 Bal: 0.9875 - Val Loss: 0.1805, Accuracy: 0.9620, F1: 0.9787 Bal: 0.9338\n","           WALLETS: Train Loss: 0.28400862, Acc: 0.88791890, F1: 0.93603813 Bal: 0.8820 - Val Loss: 0.28799465, Accuracy: 0.8871, F1: 0.9355 Bal: 0.8779\n","Epoch 354:      TX: Train Loss: 0.0599, Acc: 0.9817, F1: 0.9897 Bal: 0.9875 - Val Loss: 0.1805, Accuracy: 0.9618, F1: 0.9786 Bal: 0.9336\n","           WALLETS: Train Loss: 0.28380847, Acc: 0.89141304, F1: 0.93817694 Bal: 0.8821 - Val Loss: 0.28804222, Accuracy: 0.8905, F1: 0.9375 Bal: 0.8781\n","Epoch 355:      TX: Train Loss: 0.0598, Acc: 0.9822, F1: 0.9900 Bal: 0.9878 - Val Loss: 0.1814, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28361228, Acc: 0.88847767, F1: 0.93637835 Bal: 0.8822 - Val Loss: 0.28765804, Accuracy: 0.8877, F1: 0.9359 Bal: 0.8783\n","Epoch 356:      TX: Train Loss: 0.0597, Acc: 0.9815, F1: 0.9896 Bal: 0.9876 - Val Loss: 0.1800, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9330\n","           WALLETS: Train Loss: 0.28341055, Acc: 0.89100666, F1: 0.93792659 Bal: 0.8823 - Val Loss: 0.28764984, Accuracy: 0.8903, F1: 0.9374 Bal: 0.8785\n","Epoch 357:      TX: Train Loss: 0.0596, Acc: 0.9822, F1: 0.9900 Bal: 0.9877 - Val Loss: 0.1819, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9335\n","           WALLETS: Train Loss: 0.28321597, Acc: 0.88927592, F1: 0.93686536 Bal: 0.8824 - Val Loss: 0.28735062, Accuracy: 0.8887, F1: 0.9364 Bal: 0.8788\n","Epoch 358:      TX: Train Loss: 0.0594, Acc: 0.9816, F1: 0.9897 Bal: 0.9879 - Val Loss: 0.1800, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9330\n","           WALLETS: Train Loss: 0.28302115, Acc: 0.89049506, F1: 0.93761137 Bal: 0.8825 - Val Loss: 0.28726271, Accuracy: 0.8900, F1: 0.9372 Bal: 0.8789\n","Epoch 359:      TX: Train Loss: 0.0593, Acc: 0.9823, F1: 0.9901 Bal: 0.9880 - Val Loss: 0.1818, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28283176, Acc: 0.88996531, F1: 0.93728622 Bal: 0.8826 - Val Loss: 0.28705463, Accuracy: 0.8895, F1: 0.9369 Bal: 0.8790\n","Epoch 360:      TX: Train Loss: 0.0592, Acc: 0.9819, F1: 0.9898 Bal: 0.9880 - Val Loss: 0.1804, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9320\n","           WALLETS: Train Loss: 0.28264362, Acc: 0.89005602, F1: 0.93734012 Bal: 0.8827 - Val Loss: 0.28689420, Accuracy: 0.8895, F1: 0.9369 Bal: 0.8790\n","Epoch 361:      TX: Train Loss: 0.0590, Acc: 0.9821, F1: 0.9900 Bal: 0.9879 - Val Loss: 0.1815, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28245670, Acc: 0.89060754, F1: 0.93767739 Bal: 0.8827 - Val Loss: 0.28676111, Accuracy: 0.8899, F1: 0.9372 Bal: 0.8787\n","Epoch 362:      TX: Train Loss: 0.0589, Acc: 0.9821, F1: 0.9899 Bal: 0.9882 - Val Loss: 0.1811, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9330\n","           WALLETS: Train Loss: 0.28227291, Acc: 0.88975124, F1: 0.93715108 Bal: 0.8829 - Val Loss: 0.28653216, Accuracy: 0.8892, F1: 0.9368 Bal: 0.8795\n","Epoch 363:      TX: Train Loss: 0.0588, Acc: 0.9821, F1: 0.9900 Bal: 0.9882 - Val Loss: 0.1811, Accuracy: 0.9623, F1: 0.9788 Bal: 0.9329\n","           WALLETS: Train Loss: 0.28208810, Acc: 0.89114817, F1: 0.93800679 Bal: 0.8828 - Val Loss: 0.28646287, Accuracy: 0.8905, F1: 0.9376 Bal: 0.8789\n","Epoch 364:      TX: Train Loss: 0.0587, Acc: 0.9823, F1: 0.9901 Bal: 0.9882 - Val Loss: 0.1816, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9330\n","           WALLETS: Train Loss: 0.28191188, Acc: 0.88932672, F1: 0.93688728 Bal: 0.8832 - Val Loss: 0.28617600, Accuracy: 0.8889, F1: 0.9366 Bal: 0.8799\n","Epoch 365:      TX: Train Loss: 0.0585, Acc: 0.9820, F1: 0.9899 Bal: 0.9882 - Val Loss: 0.1808, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9323\n","           WALLETS: Train Loss: 0.28173956, Acc: 0.89221855, F1: 0.93866038 Bal: 0.8828 - Val Loss: 0.28622782, Accuracy: 0.8913, F1: 0.9381 Bal: 0.8789\n","Epoch 366:      TX: Train Loss: 0.0584, Acc: 0.9824, F1: 0.9902 Bal: 0.9883 - Val Loss: 0.1818, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9333\n","           WALLETS: Train Loss: 0.28159332, Acc: 0.88827811, F1: 0.93624379 Bal: 0.8832 - Val Loss: 0.28582823, Accuracy: 0.8880, F1: 0.9360 Bal: 0.8799\n","Epoch 367:      TX: Train Loss: 0.0583, Acc: 0.9820, F1: 0.9899 Bal: 0.9882 - Val Loss: 0.1806, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9323\n","           WALLETS: Train Loss: 0.28146994, Acc: 0.89393115, F1: 0.93970725 Bal: 0.8826 - Val Loss: 0.28612033, Accuracy: 0.8929, F1: 0.9390 Bal: 0.8786\n","Epoch 368:      TX: Train Loss: 0.0582, Acc: 0.9827, F1: 0.9903 Bal: 0.9885 - Val Loss: 0.1821, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9335\n","           WALLETS: Train Loss: 0.28142056, Acc: 0.88602125, F1: 0.93485091 Bal: 0.8837 - Val Loss: 0.28554747, Accuracy: 0.8856, F1: 0.9345 Bal: 0.8797\n","Epoch 369:      TX: Train Loss: 0.0580, Acc: 0.9820, F1: 0.9899 Bal: 0.9882 - Val Loss: 0.1805, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9323\n","           WALLETS: Train Loss: 0.28141674, Acc: 0.89679032, F1: 0.94144746 Bal: 0.8824 - Val Loss: 0.28631076, Accuracy: 0.8956, F1: 0.9407 Bal: 0.8790\n","Epoch 370:      TX: Train Loss: 0.0579, Acc: 0.9830, F1: 0.9905 Bal: 0.9887 - Val Loss: 0.1828, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9336\n","           WALLETS: Train Loss: 0.28148448, Acc: 0.88357208, F1: 0.93333610 Bal: 0.8840 - Val Loss: 0.28547341, Accuracy: 0.8827, F1: 0.9327 Bal: 0.8805\n","Epoch 371:      TX: Train Loss: 0.0578, Acc: 0.9819, F1: 0.9898 Bal: 0.9882 - Val Loss: 0.1803, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9323\n","           WALLETS: Train Loss: 0.28133446, Acc: 0.89852107, F1: 0.94250260 Bal: 0.8818 - Val Loss: 0.28640071, Accuracy: 0.8976, F1: 0.9419 Bal: 0.8795\n","Epoch 372:      TX: Train Loss: 0.0577, Acc: 0.9833, F1: 0.9906 Bal: 0.9889 - Val Loss: 0.1834, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9342\n","           WALLETS: Train Loss: 0.28093556, Acc: 0.88474042, F1: 0.93405576 Bal: 0.8841 - Val Loss: 0.28505030, Accuracy: 0.8843, F1: 0.9337 Bal: 0.8807\n","Epoch 373:      TX: Train Loss: 0.0576, Acc: 0.9817, F1: 0.9897 Bal: 0.9881 - Val Loss: 0.1798, Accuracy: 0.9605, F1: 0.9778 Bal: 0.9319\n","           WALLETS: Train Loss: 0.28036740, Acc: 0.89404363, F1: 0.93977007 Bal: 0.8831 - Val Loss: 0.28514749, Accuracy: 0.8930, F1: 0.9391 Bal: 0.8796\n","Epoch 374:      TX: Train Loss: 0.0575, Acc: 0.9834, F1: 0.9907 Bal: 0.9888 - Val Loss: 0.1838, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9331\n","           WALLETS: Train Loss: 0.28010273, Acc: 0.89220040, F1: 0.93864258 Bal: 0.8834 - Val Loss: 0.28477615, Accuracy: 0.8912, F1: 0.9380 Bal: 0.8794\n","Epoch 375:      TX: Train Loss: 0.0574, Acc: 0.9817, F1: 0.9898 Bal: 0.9882 - Val Loss: 0.1801, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9320\n","           WALLETS: Train Loss: 0.28015885, Acc: 0.88688843, F1: 0.93537916 Bal: 0.8841 - Val Loss: 0.28447282, Accuracy: 0.8864, F1: 0.9350 Bal: 0.8797\n","Epoch 376:      TX: Train Loss: 0.0572, Acc: 0.9834, F1: 0.9907 Bal: 0.9890 - Val Loss: 0.1836, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9340\n","           WALLETS: Train Loss: 0.28015128, Acc: 0.89689917, F1: 0.94150945 Bal: 0.8828 - Val Loss: 0.28519782, Accuracy: 0.8960, F1: 0.9409 Bal: 0.8795\n","Epoch 377:      TX: Train Loss: 0.0571, Acc: 0.9822, F1: 0.9900 Bal: 0.9884 - Val Loss: 0.1810, Accuracy: 0.9616, F1: 0.9785 Bal: 0.9325\n","           WALLETS: Train Loss: 0.27988726, Acc: 0.88635143, F1: 0.93504759 Bal: 0.8842 - Val Loss: 0.28420490, Accuracy: 0.8859, F1: 0.9347 Bal: 0.8805\n","Epoch 378:      TX: Train Loss: 0.0570, Acc: 0.9831, F1: 0.9905 Bal: 0.9888 - Val Loss: 0.1825, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9330\n","           WALLETS: Train Loss: 0.27946097, Acc: 0.89356831, F1: 0.93947429 Bal: 0.8836 - Val Loss: 0.28429860, Accuracy: 0.8927, F1: 0.9389 Bal: 0.8798\n","Epoch 379:      TX: Train Loss: 0.0569, Acc: 0.9829, F1: 0.9904 Bal: 0.9887 - Val Loss: 0.1820, Accuracy: 0.9623, F1: 0.9788 Bal: 0.9329\n","           WALLETS: Train Loss: 0.27925676, Acc: 0.89282449, F1: 0.93901996 Bal: 0.8837 - Val Loss: 0.28405729, Accuracy: 0.8919, F1: 0.9384 Bal: 0.8800\n","Epoch 380:      TX: Train Loss: 0.0568, Acc: 0.9827, F1: 0.9903 Bal: 0.9887 - Val Loss: 0.1816, Accuracy: 0.9623, F1: 0.9788 Bal: 0.9329\n","           WALLETS: Train Loss: 0.27925703, Acc: 0.88794430, F1: 0.93602441 Bal: 0.8844 - Val Loss: 0.28372222, Accuracy: 0.8875, F1: 0.9357 Bal: 0.8803\n","Epoch 381:      TX: Train Loss: 0.0566, Acc: 0.9833, F1: 0.9907 Bal: 0.9889 - Val Loss: 0.1829, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9324\n","           WALLETS: Train Loss: 0.27915326, Acc: 0.89622792, F1: 0.94109578 Bal: 0.8833 - Val Loss: 0.28423554, Accuracy: 0.8953, F1: 0.9405 Bal: 0.8801\n","Epoch 382:      TX: Train Loss: 0.0565, Acc: 0.9825, F1: 0.9902 Bal: 0.9886 - Val Loss: 0.1811, Accuracy: 0.9618, F1: 0.9786 Bal: 0.9327\n","           WALLETS: Train Loss: 0.27887774, Acc: 0.88850307, F1: 0.93636847 Bal: 0.8843 - Val Loss: 0.28343430, Accuracy: 0.8881, F1: 0.9361 Bal: 0.8806\n","Epoch 383:      TX: Train Loss: 0.0564, Acc: 0.9835, F1: 0.9907 Bal: 0.9890 - Val Loss: 0.1836, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9328\n","           WALLETS: Train Loss: 0.27857628, Acc: 0.89262855, F1: 0.93889612 Bal: 0.8841 - Val Loss: 0.28345031, Accuracy: 0.8918, F1: 0.9383 Bal: 0.8799\n","Epoch 384:      TX: Train Loss: 0.0563, Acc: 0.9824, F1: 0.9902 Bal: 0.9886 - Val Loss: 0.1809, Accuracy: 0.9614, F1: 0.9783 Bal: 0.9324\n","           WALLETS: Train Loss: 0.27844504, Acc: 0.89369167, F1: 0.93954444 Bal: 0.8841 - Val Loss: 0.28341427, Accuracy: 0.8928, F1: 0.9390 Bal: 0.8800\n","Epoch 385:      TX: Train Loss: 0.0562, Acc: 0.9835, F1: 0.9908 Bal: 0.9891 - Val Loss: 0.1839, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9329\n","           WALLETS: Train Loss: 0.27839631, Acc: 0.88859378, F1: 0.93642011 Bal: 0.8846 - Val Loss: 0.28301743, Accuracy: 0.8881, F1: 0.9360 Bal: 0.8806\n","Epoch 386:      TX: Train Loss: 0.0561, Acc: 0.9826, F1: 0.9902 Bal: 0.9886 - Val Loss: 0.1813, Accuracy: 0.9614, F1: 0.9784 Bal: 0.9314\n","           WALLETS: Train Loss: 0.27823296, Acc: 0.89564738, F1: 0.94073354 Bal: 0.8842 - Val Loss: 0.28338718, Accuracy: 0.8947, F1: 0.9401 Bal: 0.8803\n","Epoch 387:      TX: Train Loss: 0.0560, Acc: 0.9836, F1: 0.9908 Bal: 0.9892 - Val Loss: 0.1836, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9328\n","           WALLETS: Train Loss: 0.27798104, Acc: 0.88971495, F1: 0.93710776 Bal: 0.8846 - Val Loss: 0.28275898, Accuracy: 0.8893, F1: 0.9368 Bal: 0.8807\n","Epoch 388:      TX: Train Loss: 0.0559, Acc: 0.9829, F1: 0.9904 Bal: 0.9888 - Val Loss: 0.1817, Accuracy: 0.9620, F1: 0.9787 Bal: 0.9318\n","           WALLETS: Train Loss: 0.27775285, Acc: 0.89230200, F1: 0.93869205 Bal: 0.8845 - Val Loss: 0.28273562, Accuracy: 0.8917, F1: 0.9383 Bal: 0.8802\n","Epoch 389:      TX: Train Loss: 0.0558, Acc: 0.9834, F1: 0.9907 Bal: 0.9891 - Val Loss: 0.1831, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9326\n","           WALLETS: Train Loss: 0.27762893, Acc: 0.89410168, F1: 0.93978891 Bal: 0.8845 - Val Loss: 0.28275052, Accuracy: 0.8935, F1: 0.9393 Bal: 0.8808\n","Epoch 390:      TX: Train Loss: 0.0557, Acc: 0.9831, F1: 0.9905 Bal: 0.9889 - Val Loss: 0.1823, Accuracy: 0.9627, F1: 0.9791 Bal: 0.9322\n","           WALLETS: Train Loss: 0.27753955, Acc: 0.88942831, F1: 0.93692981 Bal: 0.8848 - Val Loss: 0.28234890, Accuracy: 0.8890, F1: 0.9366 Bal: 0.8807\n","Epoch 391:      TX: Train Loss: 0.0555, Acc: 0.9832, F1: 0.9906 Bal: 0.9890 - Val Loss: 0.1827, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9325\n","           WALLETS: Train Loss: 0.27736953, Acc: 0.89530631, F1: 0.94052218 Bal: 0.8845 - Val Loss: 0.28261435, Accuracy: 0.8945, F1: 0.9400 Bal: 0.8809\n","Epoch 392:      TX: Train Loss: 0.0554, Acc: 0.9833, F1: 0.9906 Bal: 0.9890 - Val Loss: 0.1829, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9325\n","           WALLETS: Train Loss: 0.27715307, Acc: 0.89055311, F1: 0.93761840 Bal: 0.8849 - Val Loss: 0.28209355, Accuracy: 0.8903, F1: 0.9374 Bal: 0.8812\n","Epoch 393:      TX: Train Loss: 0.0553, Acc: 0.9832, F1: 0.9906 Bal: 0.9889 - Val Loss: 0.1825, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9324\n","           WALLETS: Train Loss: 0.27695224, Acc: 0.89268661, F1: 0.93892083 Bal: 0.8850 - Val Loss: 0.28206101, Accuracy: 0.8922, F1: 0.9386 Bal: 0.8812\n","Epoch 394:      TX: Train Loss: 0.0552, Acc: 0.9833, F1: 0.9906 Bal: 0.9890 - Val Loss: 0.1833, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9328\n","           WALLETS: Train Loss: 0.27681348, Acc: 0.89392752, F1: 0.93967645 Bal: 0.8851 - Val Loss: 0.28203291, Accuracy: 0.8932, F1: 0.9392 Bal: 0.8811\n","Epoch 395:      TX: Train Loss: 0.0551, Acc: 0.9831, F1: 0.9905 Bal: 0.9889 - Val Loss: 0.1822, Accuracy: 0.9623, F1: 0.9789 Bal: 0.9319\n","           WALLETS: Train Loss: 0.27670050, Acc: 0.89035355, F1: 0.93749341 Bal: 0.8851 - Val Loss: 0.28169426, Accuracy: 0.8901, F1: 0.9373 Bal: 0.8814\n","Epoch 396:      TX: Train Loss: 0.0550, Acc: 0.9838, F1: 0.9909 Bal: 0.9893 - Val Loss: 0.1838, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9330\n","           WALLETS: Train Loss: 0.27654675, Acc: 0.89509223, F1: 0.94038815 Bal: 0.8848 - Val Loss: 0.28190249, Accuracy: 0.8941, F1: 0.9397 Bal: 0.8805\n","Epoch 397:      TX: Train Loss: 0.0549, Acc: 0.9830, F1: 0.9905 Bal: 0.9889 - Val Loss: 0.1819, Accuracy: 0.9618, F1: 0.9786 Bal: 0.9317\n","           WALLETS: Train Loss: 0.27636397, Acc: 0.89092684, F1: 0.93784336 Bal: 0.8852 - Val Loss: 0.28144222, Accuracy: 0.8905, F1: 0.9375 Bal: 0.8814\n","Epoch 398:      TX: Train Loss: 0.0548, Acc: 0.9841, F1: 0.9911 Bal: 0.9895 - Val Loss: 0.1844, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9331\n","           WALLETS: Train Loss: 0.27617145, Acc: 0.89366265, F1: 0.93951171 Bal: 0.8854 - Val Loss: 0.28146160, Accuracy: 0.8931, F1: 0.9391 Bal: 0.8817\n","Epoch 399:      TX: Train Loss: 0.0547, Acc: 0.9829, F1: 0.9904 Bal: 0.9888 - Val Loss: 0.1815, Accuracy: 0.9618, F1: 0.9786 Bal: 0.9317\n","           WALLETS: Train Loss: 0.27601144, Acc: 0.89339415, F1: 0.93934721 Bal: 0.8854 - Val Loss: 0.28130198, Accuracy: 0.8926, F1: 0.9388 Bal: 0.8815\n","Epoch 400:      TX: Train Loss: 0.0546, Acc: 0.9843, F1: 0.9912 Bal: 0.9896 - Val Loss: 0.1851, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9333\n","           WALLETS: Train Loss: 0.27587861, Acc: 0.89157269, F1: 0.93823517 Bal: 0.8854 - Val Loss: 0.28106594, Accuracy: 0.8911, F1: 0.9379 Bal: 0.8814\n","Epoch 401:      TX: Train Loss: 0.0545, Acc: 0.9827, F1: 0.9903 Bal: 0.9887 - Val Loss: 0.1812, Accuracy: 0.9614, F1: 0.9784 Bal: 0.9314\n","           WALLETS: Train Loss: 0.27574334, Acc: 0.89493258, F1: 0.94028536 Bal: 0.8853 - Val Loss: 0.28118375, Accuracy: 0.8941, F1: 0.9398 Bal: 0.8815\n","Epoch 402:      TX: Train Loss: 0.0545, Acc: 0.9845, F1: 0.9913 Bal: 0.9897 - Val Loss: 0.1857, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9335\n","           WALLETS: Train Loss: 0.27559695, Acc: 0.89111189, F1: 0.93795228 Bal: 0.8855 - Val Loss: 0.28078720, Accuracy: 0.8907, F1: 0.9377 Bal: 0.8815\n","Epoch 403:      TX: Train Loss: 0.0544, Acc: 0.9827, F1: 0.9903 Bal: 0.9887 - Val Loss: 0.1811, Accuracy: 0.9612, F1: 0.9782 Bal: 0.9313\n","           WALLETS: Train Loss: 0.27542382, Acc: 0.89479471, F1: 0.94019960 Bal: 0.8855 - Val Loss: 0.28089485, Accuracy: 0.8941, F1: 0.9397 Bal: 0.8816\n","Epoch 404:      TX: Train Loss: 0.0543, Acc: 0.9845, F1: 0.9913 Bal: 0.9897 - Val Loss: 0.1857, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9335\n","           WALLETS: Train Loss: 0.27525419, Acc: 0.89231651, F1: 0.93868613 Bal: 0.8857 - Val Loss: 0.28058419, Accuracy: 0.8914, F1: 0.9381 Bal: 0.8815\n","Epoch 405:      TX: Train Loss: 0.0541, Acc: 0.9830, F1: 0.9905 Bal: 0.9889 - Val Loss: 0.1818, Accuracy: 0.9618, F1: 0.9786 Bal: 0.9317\n","           WALLETS: Train Loss: 0.27509204, Acc: 0.89332158, F1: 0.93929865 Bal: 0.8858 - Val Loss: 0.28051984, Accuracy: 0.8924, F1: 0.9387 Bal: 0.8817\n","Epoch 406:      TX: Train Loss: 0.0540, Acc: 0.9841, F1: 0.9911 Bal: 0.9895 - Val Loss: 0.1847, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9330\n","           WALLETS: Train Loss: 0.27494493, Acc: 0.89405088, F1: 0.93974188 Bal: 0.8859 - Val Loss: 0.28043845, Accuracy: 0.8933, F1: 0.9392 Bal: 0.8817\n","Epoch 407:      TX: Train Loss: 0.0539, Acc: 0.9835, F1: 0.9908 Bal: 0.9892 - Val Loss: 0.1833, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9324\n","           WALLETS: Train Loss: 0.27480891, Acc: 0.89219315, F1: 0.93860827 Bal: 0.8859 - Val Loss: 0.28020045, Accuracy: 0.8913, F1: 0.9380 Bal: 0.8815\n","Epoch 408:      TX: Train Loss: 0.0538, Acc: 0.9836, F1: 0.9908 Bal: 0.9892 - Val Loss: 0.1835, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9325\n","           WALLETS: Train Loss: 0.27466670, Acc: 0.89511763, F1: 0.94039066 Bal: 0.8860 - Val Loss: 0.28028992, Accuracy: 0.8944, F1: 0.9399 Bal: 0.8823\n","Epoch 409:      TX: Train Loss: 0.0537, Acc: 0.9841, F1: 0.9911 Bal: 0.9895 - Val Loss: 0.1847, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9330\n","           WALLETS: Train Loss: 0.27452451, Acc: 0.89195730, F1: 0.93846316 Bal: 0.8860 - Val Loss: 0.27995393, Accuracy: 0.8912, F1: 0.9379 Bal: 0.8815\n","Epoch 410:      TX: Train Loss: 0.0536, Acc: 0.9833, F1: 0.9907 Bal: 0.9890 - Val Loss: 0.1825, Accuracy: 0.9620, F1: 0.9787 Bal: 0.9318\n","           WALLETS: Train Loss: 0.27436793, Acc: 0.89528454, F1: 0.94049116 Bal: 0.8861 - Val Loss: 0.28005153, Accuracy: 0.8945, F1: 0.9400 Bal: 0.8822\n","Epoch 411:      TX: Train Loss: 0.0536, Acc: 0.9847, F1: 0.9914 Bal: 0.9898 - Val Loss: 0.1858, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9336\n","           WALLETS: Train Loss: 0.27421471, Acc: 0.89247253, F1: 0.93877534 Bal: 0.8862 - Val Loss: 0.27971697, Accuracy: 0.8916, F1: 0.9382 Bal: 0.8817\n","Epoch 412:      TX: Train Loss: 0.0535, Acc: 0.9831, F1: 0.9905 Bal: 0.9891 - Val Loss: 0.1819, Accuracy: 0.9614, F1: 0.9784 Bal: 0.9314\n","           WALLETS: Train Loss: 0.27405509, Acc: 0.89481648, F1: 0.94020556 Bal: 0.8861 - Val Loss: 0.27975261, Accuracy: 0.8941, F1: 0.9397 Bal: 0.8821\n","Epoch 413:      TX: Train Loss: 0.0534, Acc: 0.9847, F1: 0.9914 Bal: 0.9898 - Val Loss: 0.1861, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9325\n","           WALLETS: Train Loss: 0.27390230, Acc: 0.89314379, F1: 0.93918380 Bal: 0.8863 - Val Loss: 0.27952144, Accuracy: 0.8921, F1: 0.9385 Bal: 0.8818\n","Epoch 414:      TX: Train Loss: 0.0533, Acc: 0.9833, F1: 0.9906 Bal: 0.9892 - Val Loss: 0.1821, Accuracy: 0.9614, F1: 0.9784 Bal: 0.9314\n","           WALLETS: Train Loss: 0.27375126, Acc: 0.89432664, F1: 0.93990269 Bal: 0.8865 - Val Loss: 0.27946970, Accuracy: 0.8933, F1: 0.9392 Bal: 0.8823\n","Epoch 415:      TX: Train Loss: 0.0532, Acc: 0.9846, F1: 0.9914 Bal: 0.9898 - Val Loss: 0.1857, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9335\n","           WALLETS: Train Loss: 0.27360415, Acc: 0.89424319, F1: 0.93985113 Bal: 0.8866 - Val Loss: 0.27934027, Accuracy: 0.8933, F1: 0.9392 Bal: 0.8824\n","Epoch 416:      TX: Train Loss: 0.0531, Acc: 0.9836, F1: 0.9908 Bal: 0.9893 - Val Loss: 0.1831, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9323\n","           WALLETS: Train Loss: 0.27346003, Acc: 0.89376061, F1: 0.93955783 Bal: 0.8865 - Val Loss: 0.27918935, Accuracy: 0.8928, F1: 0.9389 Bal: 0.8823\n","Epoch 417:      TX: Train Loss: 0.0530, Acc: 0.9842, F1: 0.9912 Bal: 0.9895 - Val Loss: 0.1845, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9329\n","           WALLETS: Train Loss: 0.27331769, Acc: 0.89495073, F1: 0.94028077 Bal: 0.8867 - Val Loss: 0.27915010, Accuracy: 0.8940, F1: 0.9397 Bal: 0.8825\n","Epoch 418:      TX: Train Loss: 0.0529, Acc: 0.9841, F1: 0.9911 Bal: 0.9895 - Val Loss: 0.1842, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9329\n","           WALLETS: Train Loss: 0.27317926, Acc: 0.89328166, F1: 0.93926579 Bal: 0.8865 - Val Loss: 0.27892900, Accuracy: 0.8922, F1: 0.9386 Bal: 0.8820\n","Epoch 419:      TX: Train Loss: 0.0528, Acc: 0.9839, F1: 0.9910 Bal: 0.9895 - Val Loss: 0.1835, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9328\n","           WALLETS: Train Loss: 0.27304000, Acc: 0.89559295, F1: 0.94067071 Bal: 0.8868 - Val Loss: 0.27897528, Accuracy: 0.8946, F1: 0.9400 Bal: 0.8824\n","Epoch 420:      TX: Train Loss: 0.0527, Acc: 0.9846, F1: 0.9913 Bal: 0.9897 - Val Loss: 0.1852, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9333\n","           WALLETS: Train Loss: 0.27291119, Acc: 0.89287166, F1: 0.93901343 Bal: 0.8867 - Val Loss: 0.27868348, Accuracy: 0.8918, F1: 0.9383 Bal: 0.8821\n","Epoch 421:      TX: Train Loss: 0.0526, Acc: 0.9838, F1: 0.9909 Bal: 0.9894 - Val Loss: 0.1830, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9323\n","           WALLETS: Train Loss: 0.27278057, Acc: 0.89656536, F1: 0.94125938 Bal: 0.8870 - Val Loss: 0.27883989, Accuracy: 0.8954, F1: 0.9405 Bal: 0.8822\n","Epoch 422:      TX: Train Loss: 0.0525, Acc: 0.9847, F1: 0.9914 Bal: 0.9898 - Val Loss: 0.1858, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9335\n","           WALLETS: Train Loss: 0.27266786, Acc: 0.89214598, F1: 0.93857037 Bal: 0.8867 - Val Loss: 0.27844611, Accuracy: 0.8915, F1: 0.9381 Bal: 0.8823\n","Epoch 423:      TX: Train Loss: 0.0525, Acc: 0.9837, F1: 0.9909 Bal: 0.9894 - Val Loss: 0.1829, Accuracy: 0.9627, F1: 0.9791 Bal: 0.9322\n","           WALLETS: Train Loss: 0.27255765, Acc: 0.89765388, F1: 0.94192183 Bal: 0.8868 - Val Loss: 0.27875042, Accuracy: 0.8969, F1: 0.9414 Bal: 0.8825\n","Epoch 424:      TX: Train Loss: 0.0524, Acc: 0.9848, F1: 0.9915 Bal: 0.9899 - Val Loss: 0.1859, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9325\n","           WALLETS: Train Loss: 0.27248123, Acc: 0.89102480, F1: 0.93788262 Bal: 0.8869 - Val Loss: 0.27821410, Accuracy: 0.8906, F1: 0.9376 Bal: 0.8823\n","Epoch 425:      TX: Train Loss: 0.0523, Acc: 0.9838, F1: 0.9909 Bal: 0.9895 - Val Loss: 0.1831, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9324\n","           WALLETS: Train Loss: 0.27241161, Acc: 0.89919595, F1: 0.94285797 Bal: 0.8866 - Val Loss: 0.27876163, Accuracy: 0.8980, F1: 0.9421 Bal: 0.8819\n","Epoch 426:      TX: Train Loss: 0.0522, Acc: 0.9847, F1: 0.9914 Bal: 0.9898 - Val Loss: 0.1857, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9322\n","           WALLETS: Train Loss: 0.27239090, Acc: 0.88942831, F1: 0.93690422 Bal: 0.8869 - Val Loss: 0.27804396, Accuracy: 0.8887, F1: 0.9364 Bal: 0.8815\n","Epoch 427:      TX: Train Loss: 0.0521, Acc: 0.9841, F1: 0.9911 Bal: 0.9896 - Val Loss: 0.1836, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9330\n","           WALLETS: Train Loss: 0.27233502, Acc: 0.90078518, F1: 0.94382170 Bal: 0.8864 - Val Loss: 0.27884859, Accuracy: 0.8996, F1: 0.9431 Bal: 0.8818\n","Epoch 428:      TX: Train Loss: 0.0520, Acc: 0.9848, F1: 0.9915 Bal: 0.9898 - Val Loss: 0.1852, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9322\n","           WALLETS: Train Loss: 0.27226844, Acc: 0.88842687, F1: 0.93629056 Bal: 0.8869 - Val Loss: 0.27788782, Accuracy: 0.8875, F1: 0.9357 Bal: 0.8815\n","Epoch 429:      TX: Train Loss: 0.0519, Acc: 0.9845, F1: 0.9913 Bal: 0.9898 - Val Loss: 0.1843, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9331\n","           WALLETS: Train Loss: 0.27204892, Acc: 0.90073076, F1: 0.94378661 Bal: 0.8866 - Val Loss: 0.27860007, Accuracy: 0.8996, F1: 0.9430 Bal: 0.8819\n","Epoch 430:      TX: Train Loss: 0.0518, Acc: 0.9847, F1: 0.9914 Bal: 0.9899 - Val Loss: 0.1849, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9320\n","           WALLETS: Train Loss: 0.27177259, Acc: 0.89046966, F1: 0.93753841 Bal: 0.8873 - Val Loss: 0.27757698, Accuracy: 0.8897, F1: 0.9371 Bal: 0.8818\n","Epoch 431:      TX: Train Loss: 0.0517, Acc: 0.9847, F1: 0.9914 Bal: 0.9899 - Val Loss: 0.1849, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9320\n","           WALLETS: Train Loss: 0.27146465, Acc: 0.89769379, F1: 0.94193981 Bal: 0.8874 - Val Loss: 0.27782145, Accuracy: 0.8965, F1: 0.9412 Bal: 0.8824\n","Epoch 432:      TX: Train Loss: 0.0517, Acc: 0.9847, F1: 0.9914 Bal: 0.9899 - Val Loss: 0.1846, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9320\n","           WALLETS: Train Loss: 0.27126652, Acc: 0.89510312, F1: 0.94036593 Bal: 0.8874 - Val Loss: 0.27744934, Accuracy: 0.8941, F1: 0.9397 Bal: 0.8827\n","Epoch 433:      TX: Train Loss: 0.0516, Acc: 0.9848, F1: 0.9915 Bal: 0.9900 - Val Loss: 0.1853, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9320\n","           WALLETS: Train Loss: 0.27118728, Acc: 0.89314016, F1: 0.93917056 Bal: 0.8873 - Val Loss: 0.27725452, Accuracy: 0.8923, F1: 0.9386 Bal: 0.8825\n","Epoch 434:      TX: Train Loss: 0.0515, Acc: 0.9846, F1: 0.9914 Bal: 0.9900 - Val Loss: 0.1843, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9319\n","           WALLETS: Train Loss: 0.27116296, Acc: 0.89886939, F1: 0.94265304 Bal: 0.8873 - Val Loss: 0.27766722, Accuracy: 0.8976, F1: 0.9418 Bal: 0.8827\n","Epoch 435:      TX: Train Loss: 0.0514, Acc: 0.9849, F1: 0.9916 Bal: 0.9901 - Val Loss: 0.1858, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9322\n","           WALLETS: Train Loss: 0.27113679, Acc: 0.89074905, F1: 0.93770508 Bal: 0.8876 - Val Loss: 0.27705655, Accuracy: 0.8901, F1: 0.9373 Bal: 0.8820\n","Epoch 436:      TX: Train Loss: 0.0513, Acc: 0.9845, F1: 0.9913 Bal: 0.9899 - Val Loss: 0.1839, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9319\n","           WALLETS: Train Loss: 0.27100697, Acc: 0.89986357, F1: 0.94325579 Bal: 0.8872 - Val Loss: 0.27764162, Accuracy: 0.8986, F1: 0.9425 Bal: 0.8827\n","Epoch 437:      TX: Train Loss: 0.0513, Acc: 0.9851, F1: 0.9917 Bal: 0.9902 - Val Loss: 0.1867, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9322\n","           WALLETS: Train Loss: 0.27081600, Acc: 0.89157632, F1: 0.93821156 Bal: 0.8876 - Val Loss: 0.27684775, Accuracy: 0.8907, F1: 0.9376 Bal: 0.8818\n","Epoch 438:      TX: Train Loss: 0.0512, Acc: 0.9843, F1: 0.9912 Bal: 0.9900 - Val Loss: 0.1833, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9314\n","           WALLETS: Train Loss: 0.27057719, Acc: 0.89790424, F1: 0.94206450 Bal: 0.8876 - Val Loss: 0.27710262, Accuracy: 0.8966, F1: 0.9412 Bal: 0.8825\n","Epoch 439:      TX: Train Loss: 0.0511, Acc: 0.9854, F1: 0.9918 Bal: 0.9903 - Val Loss: 0.1876, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9330\n","           WALLETS: Train Loss: 0.27039483, Acc: 0.89504869, F1: 0.94032773 Bal: 0.8878 - Val Loss: 0.27672672, Accuracy: 0.8940, F1: 0.9396 Bal: 0.8825\n","Epoch 440:      TX: Train Loss: 0.0511, Acc: 0.9840, F1: 0.9910 Bal: 0.9901 - Val Loss: 0.1828, Accuracy: 0.9620, F1: 0.9787 Bal: 0.9318\n","           WALLETS: Train Loss: 0.27028325, Acc: 0.89455160, F1: 0.94002493 Bal: 0.8878 - Val Loss: 0.27659619, Accuracy: 0.8933, F1: 0.9392 Bal: 0.8823\n","Epoch 441:      TX: Train Loss: 0.0510, Acc: 0.9856, F1: 0.9919 Bal: 0.9904 - Val Loss: 0.1884, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9321\n","           WALLETS: Train Loss: 0.27021500, Acc: 0.89811469, F1: 0.94219130 Bal: 0.8877 - Val Loss: 0.27681449, Accuracy: 0.8968, F1: 0.9413 Bal: 0.8824\n","Epoch 442:      TX: Train Loss: 0.0509, Acc: 0.9840, F1: 0.9911 Bal: 0.9901 - Val Loss: 0.1827, Accuracy: 0.9620, F1: 0.9787 Bal: 0.9318\n","           WALLETS: Train Loss: 0.27015918, Acc: 0.89221492, F1: 0.93860012 Bal: 0.8877 - Val Loss: 0.27634180, Accuracy: 0.8915, F1: 0.9381 Bal: 0.8824\n","Epoch 443:      TX: Train Loss: 0.0508, Acc: 0.9855, F1: 0.9919 Bal: 0.9904 - Val Loss: 0.1879, Accuracy: 0.9658, F1: 0.9809 Bal: 0.9319\n","           WALLETS: Train Loss: 0.27005219, Acc: 0.89936285, F1: 0.94294695 Bal: 0.8877 - Val Loss: 0.27678731, Accuracy: 0.8982, F1: 0.9422 Bal: 0.8831\n","Epoch 444:      TX: Train Loss: 0.0507, Acc: 0.9845, F1: 0.9913 Bal: 0.9902 - Val Loss: 0.1838, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26991257, Acc: 0.89244713, F1: 0.93874025 Bal: 0.8879 - Val Loss: 0.27616143, Accuracy: 0.8917, F1: 0.9382 Bal: 0.8824\n","Epoch 445:      TX: Train Loss: 0.0506, Acc: 0.9851, F1: 0.9916 Bal: 0.9903 - Val Loss: 0.1863, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9324\n","           WALLETS: Train Loss: 0.26973155, Acc: 0.89829611, F1: 0.94230112 Bal: 0.8877 - Val Loss: 0.27643454, Accuracy: 0.8971, F1: 0.9415 Bal: 0.8828\n","Epoch 446:      TX: Train Loss: 0.0505, Acc: 0.9850, F1: 0.9916 Bal: 0.9904 - Val Loss: 0.1857, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9320\n","           WALLETS: Train Loss: 0.26956674, Acc: 0.89472214, F1: 0.94012526 Bal: 0.8881 - Val Loss: 0.27601025, Accuracy: 0.8934, F1: 0.9393 Bal: 0.8822\n","Epoch 447:      TX: Train Loss: 0.0505, Acc: 0.9848, F1: 0.9915 Bal: 0.9903 - Val Loss: 0.1848, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26943055, Acc: 0.89595216, F1: 0.94087447 Bal: 0.8881 - Val Loss: 0.27598312, Accuracy: 0.8947, F1: 0.9401 Bal: 0.8824\n","Epoch 448:      TX: Train Loss: 0.0504, Acc: 0.9853, F1: 0.9918 Bal: 0.9904 - Val Loss: 0.1873, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26932693, Acc: 0.89708422, F1: 0.94156211 Bal: 0.8881 - Val Loss: 0.27597663, Accuracy: 0.8957, F1: 0.9407 Bal: 0.8824\n","Epoch 449:      TX: Train Loss: 0.0503, Acc: 0.9846, F1: 0.9913 Bal: 0.9904 - Val Loss: 0.1840, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9311\n","           WALLETS: Train Loss: 0.26924551, Acc: 0.89398920, F1: 0.93967929 Bal: 0.8881 - Val Loss: 0.27568430, Accuracy: 0.8929, F1: 0.9390 Bal: 0.8829\n","Epoch 450:      TX: Train Loss: 0.0503, Acc: 0.9858, F1: 0.9920 Bal: 0.9907 - Val Loss: 0.1881, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26915520, Acc: 0.89872063, F1: 0.94255556 Bal: 0.8880 - Val Loss: 0.27596098, Accuracy: 0.8975, F1: 0.9418 Bal: 0.8830\n","Epoch 451:      TX: Train Loss: 0.0502, Acc: 0.9845, F1: 0.9913 Bal: 0.9903 - Val Loss: 0.1838, Accuracy: 0.9627, F1: 0.9791 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26906317, Acc: 0.89321635, F1: 0.93920627 Bal: 0.8882 - Val Loss: 0.27549317, Accuracy: 0.8923, F1: 0.9386 Bal: 0.8827\n","Epoch 452:      TX: Train Loss: 0.0501, Acc: 0.9858, F1: 0.9921 Bal: 0.9908 - Val Loss: 0.1878, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26893967, Acc: 0.89923949, F1: 0.94286831 Bal: 0.8881 - Val Loss: 0.27583483, Accuracy: 0.8980, F1: 0.9421 Bal: 0.8831\n","Epoch 453:      TX: Train Loss: 0.0500, Acc: 0.9849, F1: 0.9915 Bal: 0.9904 - Val Loss: 0.1847, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26881170, Acc: 0.89366265, F1: 0.93947798 Bal: 0.8883 - Val Loss: 0.27532011, Accuracy: 0.8926, F1: 0.9388 Bal: 0.8826\n","Epoch 454:      TX: Train Loss: 0.0499, Acc: 0.9852, F1: 0.9917 Bal: 0.9905 - Val Loss: 0.1868, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26866537, Acc: 0.89850655, F1: 0.94242170 Bal: 0.8883 - Val Loss: 0.27553993, Accuracy: 0.8973, F1: 0.9417 Bal: 0.8831\n","Epoch 455:      TX: Train Loss: 0.0499, Acc: 0.9851, F1: 0.9916 Bal: 0.9904 - Val Loss: 0.1861, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26852864, Acc: 0.89493621, F1: 0.94025034 Bal: 0.8886 - Val Loss: 0.27515131, Accuracy: 0.8938, F1: 0.9396 Bal: 0.8826\n","Epoch 456:      TX: Train Loss: 0.0498, Acc: 0.9850, F1: 0.9916 Bal: 0.9904 - Val Loss: 0.1857, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26839402, Acc: 0.89746520, F1: 0.94178839 Bal: 0.8885 - Val Loss: 0.27521893, Accuracy: 0.8959, F1: 0.9408 Bal: 0.8826\n","Epoch 457:      TX: Train Loss: 0.0497, Acc: 0.9854, F1: 0.9918 Bal: 0.9906 - Val Loss: 0.1874, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9313\n","           WALLETS: Train Loss: 0.26827276, Acc: 0.89642023, F1: 0.94115489 Bal: 0.8884 - Val Loss: 0.27506056, Accuracy: 0.8950, F1: 0.9403 Bal: 0.8823\n","Epoch 458:      TX: Train Loss: 0.0497, Acc: 0.9849, F1: 0.9915 Bal: 0.9906 - Val Loss: 0.1850, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9304\n","           WALLETS: Train Loss: 0.26815790, Acc: 0.89631863, F1: 0.94109158 Bal: 0.8886 - Val Loss: 0.27496651, Accuracy: 0.8949, F1: 0.9402 Bal: 0.8822\n","Epoch 459:      TX: Train Loss: 0.0496, Acc: 0.9858, F1: 0.9920 Bal: 0.9908 - Val Loss: 0.1881, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26804835, Acc: 0.89776636, F1: 0.94196929 Bal: 0.8887 - Val Loss: 0.27498227, Accuracy: 0.8963, F1: 0.9410 Bal: 0.8828\n","Epoch 460:      TX: Train Loss: 0.0495, Acc: 0.9848, F1: 0.9915 Bal: 0.9905 - Val Loss: 0.1847, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9303\n","           WALLETS: Train Loss: 0.26794648, Acc: 0.89550224, F1: 0.94059283 Bal: 0.8888 - Val Loss: 0.27472937, Accuracy: 0.8942, F1: 0.9398 Bal: 0.8823\n","Epoch 461:      TX: Train Loss: 0.0495, Acc: 0.9857, F1: 0.9920 Bal: 0.9907 - Val Loss: 0.1880, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26784191, Acc: 0.89885488, F1: 0.94262686 Bal: 0.8889 - Val Loss: 0.27489191, Accuracy: 0.8978, F1: 0.9419 Bal: 0.8835\n","Epoch 462:      TX: Train Loss: 0.0494, Acc: 0.9849, F1: 0.9915 Bal: 0.9906 - Val Loss: 0.1852, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9304\n","           WALLETS: Train Loss: 0.26775023, Acc: 0.89464594, F1: 0.94007314 Bal: 0.8886 - Val Loss: 0.27451450, Accuracy: 0.8935, F1: 0.9394 Bal: 0.8826\n","Epoch 463:      TX: Train Loss: 0.0493, Acc: 0.9855, F1: 0.9919 Bal: 0.9907 - Val Loss: 0.1875, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9313\n","           WALLETS: Train Loss: 0.26765251, Acc: 0.89977649, F1: 0.94318542 Bal: 0.8888 - Val Loss: 0.27482790, Accuracy: 0.8983, F1: 0.9423 Bal: 0.8833\n","Epoch 464:      TX: Train Loss: 0.0492, Acc: 0.9852, F1: 0.9917 Bal: 0.9906 - Val Loss: 0.1861, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26757473, Acc: 0.89378601, F1: 0.93954870 Bal: 0.8886 - Val Loss: 0.27432734, Accuracy: 0.8926, F1: 0.9388 Bal: 0.8825\n","Epoch 465:      TX: Train Loss: 0.0492, Acc: 0.9853, F1: 0.9918 Bal: 0.9906 - Val Loss: 0.1867, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26748964, Acc: 0.90072350, F1: 0.94375754 Bal: 0.8889 - Val Loss: 0.27479801, Accuracy: 0.8992, F1: 0.9428 Bal: 0.8835\n","Epoch 466:      TX: Train Loss: 0.0491, Acc: 0.9854, F1: 0.9918 Bal: 0.9906 - Val Loss: 0.1870, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26742905, Acc: 0.89295148, F1: 0.93903747 Bal: 0.8888 - Val Loss: 0.27415839, Accuracy: 0.8918, F1: 0.9383 Bal: 0.8824\n","Epoch 467:      TX: Train Loss: 0.0490, Acc: 0.9853, F1: 0.9918 Bal: 0.9908 - Val Loss: 0.1862, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26734909, Acc: 0.90155078, F1: 0.94425715 Bal: 0.8889 - Val Loss: 0.27477661, Accuracy: 0.8999, F1: 0.9433 Bal: 0.8835\n","Epoch 468:      TX: Train Loss: 0.0490, Acc: 0.9857, F1: 0.9920 Bal: 0.9908 - Val Loss: 0.1876, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9313\n","           WALLETS: Train Loss: 0.26728663, Acc: 0.89225483, F1: 0.93860877 Bal: 0.8891 - Val Loss: 0.27399397, Accuracy: 0.8913, F1: 0.9380 Bal: 0.8823\n","Epoch 469:      TX: Train Loss: 0.0489, Acc: 0.9851, F1: 0.9916 Bal: 0.9907 - Val Loss: 0.1856, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26717347, Acc: 0.90195716, F1: 0.94450435 Bal: 0.8887 - Val Loss: 0.27468488, Accuracy: 0.9006, F1: 0.9436 Bal: 0.8839\n","Epoch 470:      TX: Train Loss: 0.0488, Acc: 0.9860, F1: 0.9921 Bal: 0.9909 - Val Loss: 0.1883, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9315\n","           WALLETS: Train Loss: 0.26705420, Acc: 0.89249430, F1: 0.93875281 Bal: 0.8893 - Val Loss: 0.27381310, Accuracy: 0.8914, F1: 0.9381 Bal: 0.8824\n","Epoch 471:      TX: Train Loss: 0.0488, Acc: 0.9850, F1: 0.9916 Bal: 0.9906 - Val Loss: 0.1853, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9303\n","           WALLETS: Train Loss: 0.26687291, Acc: 0.90143467, F1: 0.94418567 Bal: 0.8890 - Val Loss: 0.27436644, Accuracy: 0.8999, F1: 0.9433 Bal: 0.8835\n","Epoch 472:      TX: Train Loss: 0.0487, Acc: 0.9861, F1: 0.9922 Bal: 0.9910 - Val Loss: 0.1889, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26668978, Acc: 0.89410531, F1: 0.93973665 Bal: 0.8892 - Val Loss: 0.27359843, Accuracy: 0.8928, F1: 0.9389 Bal: 0.8823\n","Epoch 473:      TX: Train Loss: 0.0486, Acc: 0.9849, F1: 0.9915 Bal: 0.9906 - Val Loss: 0.1850, Accuracy: 0.9629, F1: 0.9792 Bal: 0.9303\n","           WALLETS: Train Loss: 0.26649788, Acc: 0.89982366, F1: 0.94320737 Bal: 0.8894 - Val Loss: 0.27386737, Accuracy: 0.8984, F1: 0.9423 Bal: 0.8832\n","Epoch 474:      TX: Train Loss: 0.0486, Acc: 0.9862, F1: 0.9923 Bal: 0.9910 - Val Loss: 0.1891, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9304\n","           WALLETS: Train Loss: 0.26634359, Acc: 0.89671775, F1: 0.94132609 Bal: 0.8893 - Val Loss: 0.27348503, Accuracy: 0.8953, F1: 0.9405 Bal: 0.8823\n","Epoch 475:      TX: Train Loss: 0.0485, Acc: 0.9850, F1: 0.9916 Bal: 0.9906 - Val Loss: 0.1852, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9304\n","           WALLETS: Train Loss: 0.26622045, Acc: 0.89742529, F1: 0.94175601 Bal: 0.8892 - Val Loss: 0.27344096, Accuracy: 0.8959, F1: 0.9408 Bal: 0.8826\n","Epoch 476:      TX: Train Loss: 0.0484, Acc: 0.9860, F1: 0.9922 Bal: 0.9909 - Val Loss: 0.1886, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9303\n","           WALLETS: Train Loss: 0.26612753, Acc: 0.89909435, F1: 0.94276388 Bal: 0.8896 - Val Loss: 0.27349332, Accuracy: 0.8976, F1: 0.9419 Bal: 0.8832\n","Epoch 477:      TX: Train Loss: 0.0484, Acc: 0.9854, F1: 0.9918 Bal: 0.9908 - Val Loss: 0.1860, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.26605889, Acc: 0.89557844, F1: 0.94063089 Bal: 0.8895 - Val Loss: 0.27316561, Accuracy: 0.8940, F1: 0.9397 Bal: 0.8821\n","Epoch 478:      TX: Train Loss: 0.0483, Acc: 0.9858, F1: 0.9921 Bal: 0.9911 - Val Loss: 0.1880, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26598960, Acc: 0.90065093, F1: 0.94370740 Bal: 0.8894 - Val Loss: 0.27353010, Accuracy: 0.8992, F1: 0.9428 Bal: 0.8836\n","Epoch 479:      TX: Train Loss: 0.0482, Acc: 0.9855, F1: 0.9919 Bal: 0.9909 - Val Loss: 0.1870, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.26593071, Acc: 0.89436293, F1: 0.93988933 Bal: 0.8896 - Val Loss: 0.27297121, Accuracy: 0.8930, F1: 0.9390 Bal: 0.8824\n","Epoch 480:      TX: Train Loss: 0.0481, Acc: 0.9857, F1: 0.9920 Bal: 0.9910 - Val Loss: 0.1873, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.26584250, Acc: 0.90154715, F1: 0.94424925 Bal: 0.8894 - Val Loss: 0.27349234, Accuracy: 0.9003, F1: 0.9435 Bal: 0.8839\n","Epoch 481:      TX: Train Loss: 0.0481, Acc: 0.9858, F1: 0.9920 Bal: 0.9911 - Val Loss: 0.1877, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26575485, Acc: 0.89406903, F1: 0.93970778 Bal: 0.8898 - Val Loss: 0.27279010, Accuracy: 0.8925, F1: 0.9387 Bal: 0.8823\n","Epoch 482:      TX: Train Loss: 0.0480, Acc: 0.9855, F1: 0.9919 Bal: 0.9909 - Val Loss: 0.1867, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26562470, Acc: 0.90161972, F1: 0.94429218 Bal: 0.8895 - Val Loss: 0.27330747, Accuracy: 0.9003, F1: 0.9435 Bal: 0.8839\n","Epoch 483:      TX: Train Loss: 0.0480, Acc: 0.9861, F1: 0.9922 Bal: 0.9912 - Val Loss: 0.1885, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9302\n","           WALLETS: Train Loss: 0.26549587, Acc: 0.89464594, F1: 0.94005855 Bal: 0.8899 - Val Loss: 0.27259713, Accuracy: 0.8931, F1: 0.9391 Bal: 0.8827\n","Epoch 484:      TX: Train Loss: 0.0479, Acc: 0.9854, F1: 0.9918 Bal: 0.9908 - Val Loss: 0.1860, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26533791, Acc: 0.90089041, F1: 0.94385094 Bal: 0.8896 - Val Loss: 0.27297878, Accuracy: 0.8997, F1: 0.9431 Bal: 0.8839\n","Epoch 485:      TX: Train Loss: 0.0479, Acc: 0.9862, F1: 0.9923 Bal: 0.9910 - Val Loss: 0.1894, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9303\n","           WALLETS: Train Loss: 0.26519355, Acc: 0.89605739, F1: 0.94091611 Bal: 0.8900 - Val Loss: 0.27243370, Accuracy: 0.8944, F1: 0.9399 Bal: 0.8824\n","Epoch 486:      TX: Train Loss: 0.0478, Acc: 0.9852, F1: 0.9917 Bal: 0.9908 - Val Loss: 0.1854, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26504871, Acc: 0.89976923, F1: 0.94316868 Bal: 0.8900 - Val Loss: 0.27262443, Accuracy: 0.8982, F1: 0.9422 Bal: 0.8832\n","Epoch 487:      TX: Train Loss: 0.0478, Acc: 0.9864, F1: 0.9924 Bal: 0.9911 - Val Loss: 0.1900, Accuracy: 0.9658, F1: 0.9809 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26492295, Acc: 0.89757406, F1: 0.94183725 Bal: 0.8901 - Val Loss: 0.27233121, Accuracy: 0.8962, F1: 0.9410 Bal: 0.8832\n","Epoch 488:      TX: Train Loss: 0.0477, Acc: 0.9851, F1: 0.9917 Bal: 0.9907 - Val Loss: 0.1852, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26480564, Acc: 0.89845938, F1: 0.94237655 Bal: 0.8898 - Val Loss: 0.27230984, Accuracy: 0.8970, F1: 0.9415 Bal: 0.8834\n","Epoch 489:      TX: Train Loss: 0.0476, Acc: 0.9865, F1: 0.9925 Bal: 0.9915 - Val Loss: 0.1901, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26469874, Acc: 0.89883311, F1: 0.94260223 Bal: 0.8899 - Val Loss: 0.27224720, Accuracy: 0.8973, F1: 0.9417 Bal: 0.8834\n","Epoch 490:      TX: Train Loss: 0.0476, Acc: 0.9853, F1: 0.9918 Bal: 0.9908 - Val Loss: 0.1856, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9314\n","           WALLETS: Train Loss: 0.26460046, Acc: 0.89746883, F1: 0.94177258 Bal: 0.8901 - Val Loss: 0.27203891, Accuracy: 0.8959, F1: 0.9408 Bal: 0.8834\n","Epoch 491:      TX: Train Loss: 0.0475, Acc: 0.9863, F1: 0.9923 Bal: 0.9913 - Val Loss: 0.1894, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9304\n","           WALLETS: Train Loss: 0.26450524, Acc: 0.90000508, F1: 0.94331045 Bal: 0.8900 - Val Loss: 0.27217031, Accuracy: 0.8984, F1: 0.9423 Bal: 0.8835\n","Epoch 492:      TX: Train Loss: 0.0474, Acc: 0.9856, F1: 0.9920 Bal: 0.9910 - Val Loss: 0.1867, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9318\n","           WALLETS: Train Loss: 0.26442465, Acc: 0.89653271, F1: 0.94119927 Bal: 0.8905 - Val Loss: 0.27180618, Accuracy: 0.8950, F1: 0.9403 Bal: 0.8832\n","Epoch 493:      TX: Train Loss: 0.0473, Acc: 0.9860, F1: 0.9922 Bal: 0.9912 - Val Loss: 0.1882, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9299\n","           WALLETS: Train Loss: 0.26434335, Acc: 0.90111537, F1: 0.94398231 Bal: 0.8900 - Val Loss: 0.27214807, Accuracy: 0.8999, F1: 0.9432 Bal: 0.8843\n","Epoch 494:      TX: Train Loss: 0.0473, Acc: 0.9860, F1: 0.9921 Bal: 0.9912 - Val Loss: 0.1880, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9298\n","           WALLETS: Train Loss: 0.26428828, Acc: 0.89546596, F1: 0.94054817 Bal: 0.8907 - Val Loss: 0.27160949, Accuracy: 0.8940, F1: 0.9396 Bal: 0.8836\n","Epoch 495:      TX: Train Loss: 0.0472, Acc: 0.9858, F1: 0.9921 Bal: 0.9911 - Val Loss: 0.1874, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26422977, Acc: 0.90236354, F1: 0.94473483 Bal: 0.8901 - Val Loss: 0.27217889, Accuracy: 0.9014, F1: 0.9441 Bal: 0.8845\n","Epoch 496:      TX: Train Loss: 0.0472, Acc: 0.9862, F1: 0.9923 Bal: 0.9913 - Val Loss: 0.1891, Accuracy: 0.9647, F1: 0.9802 Bal: 0.9303\n","           WALLETS: Train Loss: 0.26420489, Acc: 0.89409805, F1: 0.93971310 Bal: 0.8909 - Val Loss: 0.27144095, Accuracy: 0.8925, F1: 0.9387 Bal: 0.8831\n","Epoch 497:      TX: Train Loss: 0.0471, Acc: 0.9856, F1: 0.9919 Bal: 0.9911 - Val Loss: 0.1864, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9318\n","           WALLETS: Train Loss: 0.26415440, Acc: 0.90357179, F1: 0.94546589 Bal: 0.8898 - Val Loss: 0.27224222, Accuracy: 0.9024, F1: 0.9448 Bal: 0.8847\n","Epoch 498:      TX: Train Loss: 0.0471, Acc: 0.9864, F1: 0.9924 Bal: 0.9914 - Val Loss: 0.1899, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9306\n","           WALLETS: Train Loss: 0.26412204, Acc: 0.89287891, F1: 0.93897092 Bal: 0.8907 - Val Loss: 0.27130887, Accuracy: 0.8916, F1: 0.9382 Bal: 0.8834\n","Epoch 499:      TX: Train Loss: 0.0470, Acc: 0.9854, F1: 0.9918 Bal: 0.9911 - Val Loss: 0.1859, Accuracy: 0.9631, F1: 0.9794 Bal: 0.9304\n","           WALLETS: Train Loss: 0.26400682, Acc: 0.90410517, F1: 0.94578633 Bal: 0.8898 - Val Loss: 0.27218014, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8845\n","Epoch 500:      TX: Train Loss: 0.0470, Acc: 0.9865, F1: 0.9925 Bal: 0.9915 - Val Loss: 0.1905, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26386255, Acc: 0.89329255, F1: 0.93922241 Bal: 0.8908 - Val Loss: 0.27110079, Accuracy: 0.8917, F1: 0.9383 Bal: 0.8835\n","Epoch 501:      TX: Train Loss: 0.0469, Acc: 0.9854, F1: 0.9918 Bal: 0.9911 - Val Loss: 0.1860, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9317\n","           WALLETS: Train Loss: 0.26362646, Acc: 0.90296222, F1: 0.94509186 Bal: 0.8904 - Val Loss: 0.27170345, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8848\n","Epoch 502:      TX: Train Loss: 0.0468, Acc: 0.9866, F1: 0.9925 Bal: 0.9915 - Val Loss: 0.1905, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26340207, Acc: 0.89598845, F1: 0.94086119 Bal: 0.8912 - Val Loss: 0.27087238, Accuracy: 0.8944, F1: 0.9399 Bal: 0.8835\n","Epoch 503:      TX: Train Loss: 0.0467, Acc: 0.9857, F1: 0.9920 Bal: 0.9913 - Val Loss: 0.1865, Accuracy: 0.9634, F1: 0.9795 Bal: 0.9306\n","           WALLETS: Train Loss: 0.26320267, Acc: 0.90019738, F1: 0.94341982 Bal: 0.8907 - Val Loss: 0.27105516, Accuracy: 0.8987, F1: 0.9425 Bal: 0.8843\n","Epoch 504:      TX: Train Loss: 0.0467, Acc: 0.9864, F1: 0.9924 Bal: 0.9915 - Val Loss: 0.1895, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9306\n","           WALLETS: Train Loss: 0.26308000, Acc: 0.89943905, F1: 0.94296140 Bal: 0.8906 - Val Loss: 0.27088824, Accuracy: 0.8978, F1: 0.9419 Bal: 0.8841\n","Epoch 505:      TX: Train Loss: 0.0466, Acc: 0.9860, F1: 0.9922 Bal: 0.9915 - Val Loss: 0.1875, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26302052, Acc: 0.89699351, F1: 0.94147334 Bal: 0.8911 - Val Loss: 0.27064112, Accuracy: 0.8954, F1: 0.9405 Bal: 0.8839\n","Epoch 506:      TX: Train Loss: 0.0465, Acc: 0.9863, F1: 0.9923 Bal: 0.9915 - Val Loss: 0.1885, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26298144, Acc: 0.90187370, F1: 0.94443257 Bal: 0.8907 - Val Loss: 0.27104911, Accuracy: 0.9010, F1: 0.9439 Bal: 0.8851\n","Epoch 507:      TX: Train Loss: 0.0465, Acc: 0.9863, F1: 0.9923 Bal: 0.9915 - Val Loss: 0.1886, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26295072, Acc: 0.89516117, F1: 0.94035612 Bal: 0.8913 - Val Loss: 0.27043724, Accuracy: 0.8933, F1: 0.9392 Bal: 0.8834\n","Epoch 508:      TX: Train Loss: 0.0464, Acc: 0.9860, F1: 0.9922 Bal: 0.9915 - Val Loss: 0.1878, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26286751, Acc: 0.90312187, F1: 0.94518534 Bal: 0.8907 - Val Loss: 0.27107796, Accuracy: 0.9021, F1: 0.9446 Bal: 0.8851\n","Epoch 509:      TX: Train Loss: 0.0464, Acc: 0.9864, F1: 0.9924 Bal: 0.9915 - Val Loss: 0.1892, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9306\n","           WALLETS: Train Loss: 0.26276037, Acc: 0.89492533, F1: 0.94021343 Bal: 0.8912 - Val Loss: 0.27025890, Accuracy: 0.8932, F1: 0.9391 Bal: 0.8838\n","Epoch 510:      TX: Train Loss: 0.0463, Acc: 0.9859, F1: 0.9921 Bal: 0.9914 - Val Loss: 0.1874, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26258746, Acc: 0.90254496, F1: 0.94483729 Bal: 0.8907 - Val Loss: 0.27075997, Accuracy: 0.9016, F1: 0.9443 Bal: 0.8846\n","Epoch 511:      TX: Train Loss: 0.0463, Acc: 0.9866, F1: 0.9925 Bal: 0.9916 - Val Loss: 0.1898, Accuracy: 0.9656, F1: 0.9807 Bal: 0.9318\n","           WALLETS: Train Loss: 0.26241565, Acc: 0.89661616, F1: 0.94124052 Bal: 0.8914 - Val Loss: 0.27006811, Accuracy: 0.8951, F1: 0.9403 Bal: 0.8844\n","Epoch 512:      TX: Train Loss: 0.0462, Acc: 0.9860, F1: 0.9921 Bal: 0.9914 - Val Loss: 0.1873, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26224738, Acc: 0.90065456, F1: 0.94369059 Bal: 0.8912 - Val Loss: 0.27027088, Accuracy: 0.8995, F1: 0.9430 Bal: 0.8851\n","Epoch 513:      TX: Train Loss: 0.0461, Acc: 0.9866, F1: 0.9925 Bal: 0.9916 - Val Loss: 0.1901, Accuracy: 0.9658, F1: 0.9809 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26211920, Acc: 0.89887665, F1: 0.94261488 Bal: 0.8912 - Val Loss: 0.27001995, Accuracy: 0.8970, F1: 0.9415 Bal: 0.8838\n","Epoch 514:      TX: Train Loss: 0.0461, Acc: 0.9859, F1: 0.9921 Bal: 0.9914 - Val Loss: 0.1872, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26202595, Acc: 0.89819451, F1: 0.94220208 Bal: 0.8911 - Val Loss: 0.26988786, Accuracy: 0.8964, F1: 0.9411 Bal: 0.8837\n","Epoch 515:      TX: Train Loss: 0.0460, Acc: 0.9867, F1: 0.9926 Bal: 0.9917 - Val Loss: 0.1903, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26195377, Acc: 0.90102829, F1: 0.94391591 Bal: 0.8913 - Val Loss: 0.27007282, Accuracy: 0.8999, F1: 0.9432 Bal: 0.8848\n","Epoch 516:      TX: Train Loss: 0.0460, Acc: 0.9859, F1: 0.9921 Bal: 0.9914 - Val Loss: 0.1874, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.26189789, Acc: 0.89662342, F1: 0.94124586 Bal: 0.8913 - Val Loss: 0.26964271, Accuracy: 0.8949, F1: 0.9402 Bal: 0.8843\n","Epoch 517:      TX: Train Loss: 0.0459, Acc: 0.9868, F1: 0.9926 Bal: 0.9918 - Val Loss: 0.1904, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26182759, Acc: 0.90227645, F1: 0.94467076 Bal: 0.8911 - Val Loss: 0.27008626, Accuracy: 0.9012, F1: 0.9440 Bal: 0.8850\n","Epoch 518:      TX: Train Loss: 0.0458, Acc: 0.9860, F1: 0.9921 Bal: 0.9914 - Val Loss: 0.1874, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26175925, Acc: 0.89586871, F1: 0.94078175 Bal: 0.8917 - Val Loss: 0.26945552, Accuracy: 0.8943, F1: 0.9398 Bal: 0.8849\n","Epoch 519:      TX: Train Loss: 0.0458, Acc: 0.9869, F1: 0.9927 Bal: 0.9918 - Val Loss: 0.1904, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26165265, Acc: 0.90261027, F1: 0.94487290 Bal: 0.8911 - Val Loss: 0.26997203, Accuracy: 0.9015, F1: 0.9442 Bal: 0.8852\n","Epoch 520:      TX: Train Loss: 0.0457, Acc: 0.9860, F1: 0.9922 Bal: 0.9915 - Val Loss: 0.1877, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26154646, Acc: 0.89612995, F1: 0.94093958 Bal: 0.8918 - Val Loss: 0.26929858, Accuracy: 0.8945, F1: 0.9399 Bal: 0.8850\n","Epoch 521:      TX: Train Loss: 0.0457, Acc: 0.9869, F1: 0.9927 Bal: 0.9920 - Val Loss: 0.1904, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26141226, Acc: 0.90216035, F1: 0.94459683 Bal: 0.8915 - Val Loss: 0.26971960, Accuracy: 0.9010, F1: 0.9439 Bal: 0.8851\n","Epoch 522:      TX: Train Loss: 0.0456, Acc: 0.9861, F1: 0.9922 Bal: 0.9915 - Val Loss: 0.1879, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26128706, Acc: 0.89705157, F1: 0.94150416 Bal: 0.8915 - Val Loss: 0.26915500, Accuracy: 0.8956, F1: 0.9406 Bal: 0.8848\n","Epoch 523:      TX: Train Loss: 0.0455, Acc: 0.9870, F1: 0.9927 Bal: 0.9920 - Val Loss: 0.1904, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9320\n","           WALLETS: Train Loss: 0.26115507, Acc: 0.90088678, F1: 0.94382799 Bal: 0.8915 - Val Loss: 0.26939723, Accuracy: 0.8995, F1: 0.9430 Bal: 0.8847\n","Epoch 524:      TX: Train Loss: 0.0455, Acc: 0.9861, F1: 0.9922 Bal: 0.9915 - Val Loss: 0.1880, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26103961, Acc: 0.89823442, F1: 0.94222224 Bal: 0.8915 - Val Loss: 0.26907480, Accuracy: 0.8970, F1: 0.9415 Bal: 0.8848\n","Epoch 525:      TX: Train Loss: 0.0454, Acc: 0.9870, F1: 0.9927 Bal: 0.9920 - Val Loss: 0.1906, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9321\n","           WALLETS: Train Loss: 0.26093078, Acc: 0.89951887, F1: 0.94300269 Bal: 0.8913 - Val Loss: 0.26911569, Accuracy: 0.8983, F1: 0.9422 Bal: 0.8847\n","Epoch 526:      TX: Train Loss: 0.0454, Acc: 0.9862, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1881, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26083446, Acc: 0.89950799, F1: 0.94299405 Bal: 0.8915 - Val Loss: 0.26904124, Accuracy: 0.8983, F1: 0.9422 Bal: 0.8852\n","Epoch 527:      TX: Train Loss: 0.0453, Acc: 0.9871, F1: 0.9928 Bal: 0.9920 - Val Loss: 0.1908, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26074550, Acc: 0.89857912, F1: 0.94243040 Bal: 0.8915 - Val Loss: 0.26888779, Accuracy: 0.8973, F1: 0.9416 Bal: 0.8849\n","Epoch 528:      TX: Train Loss: 0.0453, Acc: 0.9862, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1880, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26065889, Acc: 0.90059651, F1: 0.94365235 Bal: 0.8915 - Val Loss: 0.26900965, Accuracy: 0.8994, F1: 0.9429 Bal: 0.8848\n","Epoch 529:      TX: Train Loss: 0.0452, Acc: 0.9873, F1: 0.9929 Bal: 0.9922 - Val Loss: 0.1911, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9312\n","           WALLETS: Train Loss: 0.26058528, Acc: 0.89779902, F1: 0.94195375 Bal: 0.8918 - Val Loss: 0.26868051, Accuracy: 0.8964, F1: 0.9411 Bal: 0.8849\n","Epoch 530:      TX: Train Loss: 0.0452, Acc: 0.9862, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1877, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26051208, Acc: 0.90172494, F1: 0.94433518 Bal: 0.8914 - Val Loss: 0.26898041, Accuracy: 0.9003, F1: 0.9435 Bal: 0.8849\n","Epoch 531:      TX: Train Loss: 0.0451, Acc: 0.9875, F1: 0.9930 Bal: 0.9923 - Val Loss: 0.1915, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9305\n","           WALLETS: Train Loss: 0.26045513, Acc: 0.89691006, F1: 0.94141300 Bal: 0.8919 - Val Loss: 0.26849431, Accuracy: 0.8955, F1: 0.9405 Bal: 0.8852\n","Epoch 532:      TX: Train Loss: 0.0451, Acc: 0.9861, F1: 0.9922 Bal: 0.9916 - Val Loss: 0.1873, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26039755, Acc: 0.90289328, F1: 0.94504055 Bal: 0.8913 - Val Loss: 0.26899499, Accuracy: 0.9014, F1: 0.9441 Bal: 0.8851\n","Epoch 533:      TX: Train Loss: 0.0450, Acc: 0.9876, F1: 0.9931 Bal: 0.9923 - Val Loss: 0.1919, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26036799, Acc: 0.89583968, F1: 0.94075742 Bal: 0.8923 - Val Loss: 0.26832730, Accuracy: 0.8945, F1: 0.9400 Bal: 0.8855\n","Epoch 534:      TX: Train Loss: 0.0450, Acc: 0.9860, F1: 0.9922 Bal: 0.9916 - Val Loss: 0.1869, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.26032931, Acc: 0.90430473, F1: 0.94588728 Bal: 0.8917 - Val Loss: 0.26906550, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8858\n","Epoch 535:      TX: Train Loss: 0.0449, Acc: 0.9877, F1: 0.9931 Bal: 0.9924 - Val Loss: 0.1922, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.26032186, Acc: 0.89467497, F1: 0.94004808 Bal: 0.8923 - Val Loss: 0.26820630, Accuracy: 0.8933, F1: 0.9392 Bal: 0.8855\n","Epoch 536:      TX: Train Loss: 0.0449, Acc: 0.9861, F1: 0.9922 Bal: 0.9916 - Val Loss: 0.1872, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.26027277, Acc: 0.90523360, F1: 0.94644878 Bal: 0.8914 - Val Loss: 0.26913947, Accuracy: 0.9039, F1: 0.9456 Bal: 0.8854\n","Epoch 537:      TX: Train Loss: 0.0448, Acc: 0.9877, F1: 0.9931 Bal: 0.9924 - Val Loss: 0.1920, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.26023287, Acc: 0.89401460, F1: 0.93964477 Bal: 0.8924 - Val Loss: 0.26807225, Accuracy: 0.8926, F1: 0.9387 Bal: 0.8852\n","Epoch 538:      TX: Train Loss: 0.0447, Acc: 0.9863, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1879, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9310\n","           WALLETS: Train Loss: 0.26010180, Acc: 0.90538599, F1: 0.94654038 Bal: 0.8914 - Val Loss: 0.26897806, Accuracy: 0.9041, F1: 0.9458 Bal: 0.8853\n","Epoch 539:      TX: Train Loss: 0.0446, Acc: 0.9875, F1: 0.9930 Bal: 0.9924 - Val Loss: 0.1911, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9314\n","           WALLETS: Train Loss: 0.25994971, Acc: 0.89491081, F1: 0.94019085 Bal: 0.8924 - Val Loss: 0.26787746, Accuracy: 0.8936, F1: 0.9394 Bal: 0.8853\n","Epoch 540:      TX: Train Loss: 0.0446, Acc: 0.9867, F1: 0.9926 Bal: 0.9920 - Val Loss: 0.1889, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9306\n","           WALLETS: Train Loss: 0.25972834, Acc: 0.90381852, F1: 0.94559292 Bal: 0.8918 - Val Loss: 0.26848140, Accuracy: 0.9025, F1: 0.9448 Bal: 0.8855\n","Epoch 541:      TX: Train Loss: 0.0445, Acc: 0.9872, F1: 0.9928 Bal: 0.9922 - Val Loss: 0.1900, Accuracy: 0.9664, F1: 0.9812 Bal: 0.9313\n","           WALLETS: Train Loss: 0.25953710, Acc: 0.89762122, F1: 0.94183755 Bal: 0.8926 - Val Loss: 0.26773393, Accuracy: 0.8961, F1: 0.9409 Bal: 0.8852\n","Epoch 542:      TX: Train Loss: 0.0445, Acc: 0.9872, F1: 0.9928 Bal: 0.9922 - Val Loss: 0.1901, Accuracy: 0.9664, F1: 0.9812 Bal: 0.9313\n","           WALLETS: Train Loss: 0.25938421, Acc: 0.90070899, F1: 0.94371507 Bal: 0.8920 - Val Loss: 0.26788563, Accuracy: 0.8994, F1: 0.9429 Bal: 0.8853\n","Epoch 543:      TX: Train Loss: 0.0444, Acc: 0.9867, F1: 0.9926 Bal: 0.9920 - Val Loss: 0.1891, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25929525, Acc: 0.90066908, F1: 0.94368932 Bal: 0.8921 - Val Loss: 0.26780632, Accuracy: 0.8993, F1: 0.9429 Bal: 0.8857\n","Epoch 544:      TX: Train Loss: 0.0444, Acc: 0.9875, F1: 0.9930 Bal: 0.9924 - Val Loss: 0.1910, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9317\n","           WALLETS: Train Loss: 0.25925431, Acc: 0.89799132, F1: 0.94206238 Bal: 0.8926 - Val Loss: 0.26753780, Accuracy: 0.8965, F1: 0.9411 Bal: 0.8854\n","Epoch 545:      TX: Train Loss: 0.0443, Acc: 0.9864, F1: 0.9924 Bal: 0.9918 - Val Loss: 0.1884, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25922620, Acc: 0.90323072, F1: 0.94523614 Bal: 0.8921 - Val Loss: 0.26800030, Accuracy: 0.9018, F1: 0.9443 Bal: 0.8855\n","Epoch 546:      TX: Train Loss: 0.0443, Acc: 0.9877, F1: 0.9931 Bal: 0.9925 - Val Loss: 0.1918, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25920796, Acc: 0.89636943, F1: 0.94107526 Bal: 0.8927 - Val Loss: 0.26737148, Accuracy: 0.8949, F1: 0.9402 Bal: 0.8855\n","Epoch 547:      TX: Train Loss: 0.0442, Acc: 0.9863, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1877, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9299\n","           WALLETS: Train Loss: 0.25914657, Acc: 0.90439907, F1: 0.94594084 Bal: 0.8920 - Val Loss: 0.26806277, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8852\n","Epoch 548:      TX: Train Loss: 0.0442, Acc: 0.9879, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1924, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25907120, Acc: 0.89595942, F1: 0.94082540 Bal: 0.8928 - Val Loss: 0.26723379, Accuracy: 0.8947, F1: 0.9400 Bal: 0.8857\n","Epoch 549:      TX: Train Loss: 0.0442, Acc: 0.9862, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1875, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25893405, Acc: 0.90415959, F1: 0.94579498 Bal: 0.8921 - Val Loss: 0.26785558, Accuracy: 0.9027, F1: 0.9449 Bal: 0.8852\n","Epoch 550:      TX: Train Loss: 0.0441, Acc: 0.9879, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1926, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25879359, Acc: 0.89722573, F1: 0.94159420 Bal: 0.8929 - Val Loss: 0.26709810, Accuracy: 0.8958, F1: 0.9407 Bal: 0.8854\n","Epoch 551:      TX: Train Loss: 0.0440, Acc: 0.9863, F1: 0.9923 Bal: 0.9917 - Val Loss: 0.1876, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9298\n","           WALLETS: Train Loss: 0.25863785, Acc: 0.90230185, F1: 0.94467366 Bal: 0.8923 - Val Loss: 0.26743737, Accuracy: 0.9009, F1: 0.9438 Bal: 0.8856\n","Epoch 552:      TX: Train Loss: 0.0440, Acc: 0.9879, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1921, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9319\n","           WALLETS: Train Loss: 0.25851196, Acc: 0.89929029, F1: 0.94284891 Bal: 0.8927 - Val Loss: 0.26704815, Accuracy: 0.8979, F1: 0.9420 Bal: 0.8857\n","Epoch 553:      TX: Train Loss: 0.0439, Acc: 0.9867, F1: 0.9925 Bal: 0.9919 - Val Loss: 0.1883, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25841272, Acc: 0.90023730, F1: 0.94342395 Bal: 0.8925 - Val Loss: 0.26705477, Accuracy: 0.8989, F1: 0.9426 Bal: 0.8860\n","Epoch 554:      TX: Train Loss: 0.0439, Acc: 0.9878, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1915, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9317\n","           WALLETS: Train Loss: 0.25833860, Acc: 0.90152901, F1: 0.94420562 Bal: 0.8925 - Val Loss: 0.26711178, Accuracy: 0.9000, F1: 0.9433 Bal: 0.8858\n","Epoch 555:      TX: Train Loss: 0.0438, Acc: 0.9870, F1: 0.9927 Bal: 0.9921 - Val Loss: 0.1891, Accuracy: 0.9664, F1: 0.9812 Bal: 0.9313\n","           WALLETS: Train Loss: 0.25828618, Acc: 0.89852832, F1: 0.94238400 Bal: 0.8930 - Val Loss: 0.26679519, Accuracy: 0.8972, F1: 0.9415 Bal: 0.8858\n","Epoch 556:      TX: Train Loss: 0.0437, Acc: 0.9876, F1: 0.9931 Bal: 0.9925 - Val Loss: 0.1907, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9317\n","           WALLETS: Train Loss: 0.25823420, Acc: 0.90316541, F1: 0.94519265 Bal: 0.8925 - Val Loss: 0.26717719, Accuracy: 0.9017, F1: 0.9443 Bal: 0.8855\n","Epoch 557:      TX: Train Loss: 0.0437, Acc: 0.9872, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1898, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9314\n","           WALLETS: Train Loss: 0.25819483, Acc: 0.89739989, F1: 0.94169655 Bal: 0.8932 - Val Loss: 0.26661396, Accuracy: 0.8960, F1: 0.9409 Bal: 0.8862\n","Epoch 558:      TX: Train Loss: 0.0436, Acc: 0.9874, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1902, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9314\n","           WALLETS: Train Loss: 0.25813434, Acc: 0.90429747, F1: 0.94587518 Bal: 0.8924 - Val Loss: 0.26721177, Accuracy: 0.9025, F1: 0.9448 Bal: 0.8851\n","Epoch 559:      TX: Train Loss: 0.0436, Acc: 0.9875, F1: 0.9930 Bal: 0.9924 - Val Loss: 0.1904, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9315\n","           WALLETS: Train Loss: 0.25808164, Acc: 0.89684112, F1: 0.94135363 Bal: 0.8935 - Val Loss: 0.26648197, Accuracy: 0.8958, F1: 0.9407 Bal: 0.8867\n","Epoch 560:      TX: Train Loss: 0.0435, Acc: 0.9873, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1899, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9315\n","           WALLETS: Train Loss: 0.25799385, Acc: 0.90474013, F1: 0.94614122 Bal: 0.8924 - Val Loss: 0.26714009, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8854\n","Epoch 561:      TX: Train Loss: 0.0435, Acc: 0.9877, F1: 0.9931 Bal: 0.9925 - Val Loss: 0.1908, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9315\n","           WALLETS: Train Loss: 0.25790986, Acc: 0.89692457, F1: 0.94140216 Bal: 0.8937 - Val Loss: 0.26634255, Accuracy: 0.8957, F1: 0.9407 Bal: 0.8868\n","Epoch 562:      TX: Train Loss: 0.0434, Acc: 0.9873, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1898, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9314\n","           WALLETS: Train Loss: 0.25778735, Acc: 0.90444623, F1: 0.94596386 Bal: 0.8925 - Val Loss: 0.26694593, Accuracy: 0.9027, F1: 0.9449 Bal: 0.8854\n","Epoch 563:      TX: Train Loss: 0.0434, Acc: 0.9877, F1: 0.9931 Bal: 0.9925 - Val Loss: 0.1910, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9317\n","           WALLETS: Train Loss: 0.25767320, Acc: 0.89779539, F1: 0.94193123 Bal: 0.8937 - Val Loss: 0.26623899, Accuracy: 0.8963, F1: 0.9410 Bal: 0.8868\n","Epoch 564:      TX: Train Loss: 0.0433, Acc: 0.9872, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1897, Accuracy: 0.9664, F1: 0.9812 Bal: 0.9313\n","           WALLETS: Train Loss: 0.25754157, Acc: 0.90335046, F1: 0.94530356 Bal: 0.8925 - Val Loss: 0.26666728, Accuracy: 0.9017, F1: 0.9443 Bal: 0.8854\n","Epoch 565:      TX: Train Loss: 0.0433, Acc: 0.9878, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1912, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9305\n","           WALLETS: Train Loss: 0.25742742, Acc: 0.89900727, F1: 0.94266870 Bal: 0.8935 - Val Loss: 0.26616129, Accuracy: 0.8976, F1: 0.9418 Bal: 0.8867\n","Epoch 566:      TX: Train Loss: 0.0432, Acc: 0.9871, F1: 0.9928 Bal: 0.9922 - Val Loss: 0.1894, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9312\n","           WALLETS: Train Loss: 0.25731489, Acc: 0.90209503, F1: 0.94454139 Bal: 0.8930 - Val Loss: 0.26636255, Accuracy: 0.9004, F1: 0.9435 Bal: 0.8852\n","Epoch 567:      TX: Train Loss: 0.0432, Acc: 0.9878, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1918, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25721779, Acc: 0.90026270, F1: 0.94343125 Bal: 0.8933 - Val Loss: 0.26611653, Accuracy: 0.8986, F1: 0.9424 Bal: 0.8858\n","Epoch 568:      TX: Train Loss: 0.0431, Acc: 0.9869, F1: 0.9927 Bal: 0.9921 - Val Loss: 0.1891, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25712734, Acc: 0.90095935, F1: 0.94385457 Bal: 0.8931 - Val Loss: 0.26611474, Accuracy: 0.8993, F1: 0.9429 Bal: 0.8856\n","Epoch 569:      TX: Train Loss: 0.0431, Acc: 0.9880, F1: 0.9933 Bal: 0.9927 - Val Loss: 0.1927, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25704437, Acc: 0.90148909, F1: 0.94417325 Bal: 0.8932 - Val Loss: 0.26609883, Accuracy: 0.8999, F1: 0.9432 Bal: 0.8854\n","Epoch 570:      TX: Train Loss: 0.0431, Acc: 0.9867, F1: 0.9926 Bal: 0.9920 - Val Loss: 0.1881, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25696918, Acc: 0.90002322, F1: 0.94328375 Bal: 0.8935 - Val Loss: 0.26590574, Accuracy: 0.8985, F1: 0.9423 Bal: 0.8867\n","Epoch 571:      TX: Train Loss: 0.0431, Acc: 0.9883, F1: 0.9934 Bal: 0.9928 - Val Loss: 0.1939, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25689799, Acc: 0.90272638, F1: 0.94492029 Bal: 0.8932 - Val Loss: 0.26610079, Accuracy: 0.9010, F1: 0.9439 Bal: 0.8852\n","Epoch 572:      TX: Train Loss: 0.0430, Acc: 0.9864, F1: 0.9924 Bal: 0.9919 - Val Loss: 0.1871, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9299\n","           WALLETS: Train Loss: 0.25684395, Acc: 0.89899276, F1: 0.94265503 Bal: 0.8939 - Val Loss: 0.26571131, Accuracy: 0.8975, F1: 0.9418 Bal: 0.8876\n","Epoch 573:      TX: Train Loss: 0.0430, Acc: 0.9885, F1: 0.9936 Bal: 0.9930 - Val Loss: 0.1951, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9288\n","           WALLETS: Train Loss: 0.25679171, Acc: 0.90409791, F1: 0.94574884 Bal: 0.8930 - Val Loss: 0.26614681, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8855\n","Epoch 574:      TX: Train Loss: 0.0430, Acc: 0.9863, F1: 0.9923 Bal: 0.9918 - Val Loss: 0.1866, Accuracy: 0.9638, F1: 0.9797 Bal: 0.9298\n","           WALLETS: Train Loss: 0.25676763, Acc: 0.89780990, F1: 0.94193349 Bal: 0.8943 - Val Loss: 0.26554143, Accuracy: 0.8963, F1: 0.9410 Bal: 0.8874\n","Epoch 575:      TX: Train Loss: 0.0429, Acc: 0.9884, F1: 0.9935 Bal: 0.9929 - Val Loss: 0.1945, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9299\n","           WALLETS: Train Loss: 0.25674400, Acc: 0.90553838, F1: 0.94661488 Bal: 0.8930 - Val Loss: 0.26627797, Accuracy: 0.9038, F1: 0.9455 Bal: 0.8856\n","Epoch 576:      TX: Train Loss: 0.0428, Acc: 0.9868, F1: 0.9926 Bal: 0.9920 - Val Loss: 0.1882, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9306\n","           WALLETS: Train Loss: 0.25676486, Acc: 0.89621341, F1: 0.94096474 Bal: 0.8941 - Val Loss: 0.26542634, Accuracy: 0.8950, F1: 0.9402 Bal: 0.8876\n","Epoch 577:      TX: Train Loss: 0.0427, Acc: 0.9880, F1: 0.9933 Bal: 0.9927 - Val Loss: 0.1922, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25676414, Acc: 0.90706594, F1: 0.94753359 Bal: 0.8929 - Val Loss: 0.26648638, Accuracy: 0.9057, F1: 0.9467 Bal: 0.8862\n","Epoch 578:      TX: Train Loss: 0.0426, Acc: 0.9877, F1: 0.9931 Bal: 0.9925 - Val Loss: 0.1911, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25679308, Acc: 0.89500152, F1: 0.94022285 Bal: 0.8944 - Val Loss: 0.26535749, Accuracy: 0.8941, F1: 0.9396 Bal: 0.8882\n","Epoch 579:      TX: Train Loss: 0.0426, Acc: 0.9872, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1898, Accuracy: 0.9656, F1: 0.9808 Bal: 0.9298\n","           WALLETS: Train Loss: 0.25671843, Acc: 0.90794038, F1: 0.94805865 Bal: 0.8928 - Val Loss: 0.26656440, Accuracy: 0.9067, F1: 0.9473 Bal: 0.8861\n","Epoch 580:      TX: Train Loss: 0.0426, Acc: 0.9882, F1: 0.9934 Bal: 0.9928 - Val Loss: 0.1934, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25660861, Acc: 0.89519383, F1: 0.94033985 Bal: 0.8944 - Val Loss: 0.26523185, Accuracy: 0.8943, F1: 0.9398 Bal: 0.8883\n","Epoch 581:      TX: Train Loss: 0.0426, Acc: 0.9868, F1: 0.9926 Bal: 0.9920 - Val Loss: 0.1883, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25635415, Acc: 0.90669221, F1: 0.94730781 Bal: 0.8930 - Val Loss: 0.26612067, Accuracy: 0.9053, F1: 0.9465 Bal: 0.8862\n","Epoch 582:      TX: Train Loss: 0.0425, Acc: 0.9883, F1: 0.9935 Bal: 0.9929 - Val Loss: 0.1940, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25610477, Acc: 0.89814734, F1: 0.94213561 Bal: 0.8945 - Val Loss: 0.26504114, Accuracy: 0.8966, F1: 0.9412 Bal: 0.8877\n","Epoch 583:      TX: Train Loss: 0.0424, Acc: 0.9870, F1: 0.9928 Bal: 0.9922 - Val Loss: 0.1887, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9296\n","           WALLETS: Train Loss: 0.25589174, Acc: 0.90310373, F1: 0.94514140 Bal: 0.8938 - Val Loss: 0.26533306, Accuracy: 0.9015, F1: 0.9442 Bal: 0.8867\n","Epoch 584:      TX: Train Loss: 0.0424, Acc: 0.9882, F1: 0.9934 Bal: 0.9928 - Val Loss: 0.1929, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25578472, Acc: 0.90209141, F1: 0.94452896 Bal: 0.8940 - Val Loss: 0.26514301, Accuracy: 0.9003, F1: 0.9434 Bal: 0.8866\n","Epoch 585:      TX: Train Loss: 0.0423, Acc: 0.9876, F1: 0.9930 Bal: 0.9924 - Val Loss: 0.1905, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9302\n","           WALLETS: Train Loss: 0.25576547, Acc: 0.89941365, F1: 0.94290293 Bal: 0.8946 - Val Loss: 0.26487750, Accuracy: 0.8978, F1: 0.9419 Bal: 0.8879\n","Epoch 586:      TX: Train Loss: 0.0423, Acc: 0.9877, F1: 0.9931 Bal: 0.9925 - Val Loss: 0.1911, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25577641, Acc: 0.90537873, F1: 0.94651413 Bal: 0.8935 - Val Loss: 0.26548436, Accuracy: 0.9036, F1: 0.9454 Bal: 0.8860\n","Epoch 587:      TX: Train Loss: 0.0422, Acc: 0.9881, F1: 0.9933 Bal: 0.9927 - Val Loss: 0.1922, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25579545, Acc: 0.89718945, F1: 0.94155334 Bal: 0.8945 - Val Loss: 0.26472664, Accuracy: 0.8958, F1: 0.9407 Bal: 0.8879\n","Epoch 588:      TX: Train Loss: 0.0422, Acc: 0.9873, F1: 0.9929 Bal: 0.9923 - Val Loss: 0.1899, Accuracy: 0.9658, F1: 0.9809 Bal: 0.9299\n","           WALLETS: Train Loss: 0.25573298, Acc: 0.90657610, F1: 0.94723597 Bal: 0.8932 - Val Loss: 0.26559803, Accuracy: 0.9051, F1: 0.9463 Bal: 0.8862\n","Epoch 589:      TX: Train Loss: 0.0421, Acc: 0.9882, F1: 0.9934 Bal: 0.9928 - Val Loss: 0.1931, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25562927, Acc: 0.89734547, F1: 0.94164745 Bal: 0.8946 - Val Loss: 0.26460353, Accuracy: 0.8959, F1: 0.9408 Bal: 0.8880\n","Epoch 590:      TX: Train Loss: 0.0421, Acc: 0.9873, F1: 0.9929 Bal: 0.9924 - Val Loss: 0.1897, Accuracy: 0.9656, F1: 0.9808 Bal: 0.9298\n","           WALLETS: Train Loss: 0.25544354, Acc: 0.90547670, F1: 0.94657005 Bal: 0.8938 - Val Loss: 0.26523623, Accuracy: 0.9038, F1: 0.9456 Bal: 0.8866\n","Epoch 591:      TX: Train Loss: 0.0420, Acc: 0.9882, F1: 0.9934 Bal: 0.9928 - Val Loss: 0.1931, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25527111, Acc: 0.89968578, F1: 0.94306502 Bal: 0.8948 - Val Loss: 0.26450300, Accuracy: 0.8981, F1: 0.9421 Bal: 0.8879\n","Epoch 592:      TX: Train Loss: 0.0420, Acc: 0.9875, F1: 0.9930 Bal: 0.9924 - Val Loss: 0.1904, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9301\n","           WALLETS: Train Loss: 0.25512818, Acc: 0.90271912, F1: 0.94490079 Bal: 0.8946 - Val Loss: 0.26469159, Accuracy: 0.9010, F1: 0.9438 Bal: 0.8869\n","Epoch 593:      TX: Train Loss: 0.0419, Acc: 0.9881, F1: 0.9933 Bal: 0.9927 - Val Loss: 0.1922, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25504255, Acc: 0.90259575, F1: 0.94482502 Bal: 0.8948 - Val Loss: 0.26460594, Accuracy: 0.9008, F1: 0.9437 Bal: 0.8871\n","Epoch 594:      TX: Train Loss: 0.0419, Acc: 0.9879, F1: 0.9932 Bal: 0.9926 - Val Loss: 0.1914, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25500280, Acc: 0.90019013, F1: 0.94337028 Bal: 0.8948 - Val Loss: 0.26434106, Accuracy: 0.8984, F1: 0.9423 Bal: 0.8879\n","Epoch 595:      TX: Train Loss: 0.0418, Acc: 0.9878, F1: 0.9932 Bal: 0.9927 - Val Loss: 0.1913, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25497392, Acc: 0.90490341, F1: 0.94621975 Bal: 0.8943 - Val Loss: 0.26479611, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8867\n","Epoch 596:      TX: Train Loss: 0.0418, Acc: 0.9881, F1: 0.9933 Bal: 0.9928 - Val Loss: 0.1922, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9305\n","           WALLETS: Train Loss: 0.25494960, Acc: 0.89859001, F1: 0.94240134 Bal: 0.8948 - Val Loss: 0.26417398, Accuracy: 0.8971, F1: 0.9415 Bal: 0.8882\n","Epoch 597:      TX: Train Loss: 0.0418, Acc: 0.9877, F1: 0.9931 Bal: 0.9927 - Val Loss: 0.1909, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9302\n","           WALLETS: Train Loss: 0.25488111, Acc: 0.90585768, F1: 0.94679272 Bal: 0.8944 - Val Loss: 0.26482755, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8869\n","Epoch 598:      TX: Train Loss: 0.0417, Acc: 0.9881, F1: 0.9933 Bal: 0.9929 - Val Loss: 0.1926, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9305\n","           WALLETS: Train Loss: 0.25479966, Acc: 0.89860452, F1: 0.94240911 Bal: 0.8949 - Val Loss: 0.26405036, Accuracy: 0.8971, F1: 0.9415 Bal: 0.8882\n","Epoch 599:      TX: Train Loss: 0.0417, Acc: 0.9877, F1: 0.9931 Bal: 0.9927 - Val Loss: 0.1908, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25467166, Acc: 0.90540413, F1: 0.94651894 Bal: 0.8945 - Val Loss: 0.26461333, Accuracy: 0.9036, F1: 0.9454 Bal: 0.8868\n","Epoch 600:      TX: Train Loss: 0.0416, Acc: 0.9881, F1: 0.9933 Bal: 0.9927 - Val Loss: 0.1926, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25454760, Acc: 0.89988171, F1: 0.94318208 Bal: 0.8950 - Val Loss: 0.26396829, Accuracy: 0.8982, F1: 0.9422 Bal: 0.8881\n","Epoch 601:      TX: Train Loss: 0.0416, Acc: 0.9877, F1: 0.9931 Bal: 0.9927 - Val Loss: 0.1910, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25442204, Acc: 0.90385481, F1: 0.94558374 Bal: 0.8948 - Val Loss: 0.26424333, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8873\n","Epoch 602:      TX: Train Loss: 0.0415, Acc: 0.9882, F1: 0.9934 Bal: 0.9928 - Val Loss: 0.1928, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9305\n","           WALLETS: Train Loss: 0.25432131, Acc: 0.90168140, F1: 0.94427089 Bal: 0.8950 - Val Loss: 0.26395282, Accuracy: 0.8998, F1: 0.9431 Bal: 0.8875\n","Epoch 603:      TX: Train Loss: 0.0415, Acc: 0.9878, F1: 0.9932 Bal: 0.9927 - Val Loss: 0.1911, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25424021, Acc: 0.90207689, F1: 0.94450819 Bal: 0.8951 - Val Loss: 0.26392481, Accuracy: 0.8999, F1: 0.9432 Bal: 0.8873\n","Epoch 604:      TX: Train Loss: 0.0415, Acc: 0.9881, F1: 0.9934 Bal: 0.9929 - Val Loss: 0.1925, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25417385, Acc: 0.90349197, F1: 0.94536334 Bal: 0.8950 - Val Loss: 0.26401451, Accuracy: 0.9016, F1: 0.9442 Bal: 0.8873\n","Epoch 605:      TX: Train Loss: 0.0414, Acc: 0.9878, F1: 0.9932 Bal: 0.9927 - Val Loss: 0.1911, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25412202, Acc: 0.90072350, F1: 0.94368832 Bal: 0.8953 - Val Loss: 0.26371124, Accuracy: 0.8990, F1: 0.9426 Bal: 0.8882\n","Epoch 606:      TX: Train Loss: 0.0414, Acc: 0.9882, F1: 0.9934 Bal: 0.9929 - Val Loss: 0.1925, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25406840, Acc: 0.90481996, F1: 0.94616404 Bal: 0.8949 - Val Loss: 0.26406333, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8875\n","Epoch 607:      TX: Train Loss: 0.0413, Acc: 0.9879, F1: 0.9932 Bal: 0.9928 - Val Loss: 0.1913, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25402755, Acc: 0.89976561, F1: 0.94310751 Bal: 0.8954 - Val Loss: 0.26354542, Accuracy: 0.8981, F1: 0.9421 Bal: 0.8884\n","Epoch 608:      TX: Train Loss: 0.0413, Acc: 0.9882, F1: 0.9934 Bal: 0.9929 - Val Loss: 0.1927, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25396946, Acc: 0.90569440, F1: 0.94669071 Bal: 0.8948 - Val Loss: 0.26409325, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8874\n","Epoch 609:      TX: Train Loss: 0.0413, Acc: 0.9880, F1: 0.9933 Bal: 0.9928 - Val Loss: 0.1911, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25392273, Acc: 0.89918143, F1: 0.94275342 Bal: 0.8954 - Val Loss: 0.26343173, Accuracy: 0.8974, F1: 0.9417 Bal: 0.8882\n","Epoch 610:      TX: Train Loss: 0.0412, Acc: 0.9882, F1: 0.9934 Bal: 0.9929 - Val Loss: 0.1927, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25385061, Acc: 0.90626406, F1: 0.94703065 Bal: 0.8950 - Val Loss: 0.26406854, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8873\n","Epoch 611:      TX: Train Loss: 0.0412, Acc: 0.9879, F1: 0.9932 Bal: 0.9927 - Val Loss: 0.1908, Accuracy: 0.9662, F1: 0.9811 Bal: 0.9302\n","           WALLETS: Train Loss: 0.25378788, Acc: 0.89909072, F1: 0.94269660 Bal: 0.8955 - Val Loss: 0.26330596, Accuracy: 0.8974, F1: 0.9416 Bal: 0.8883\n","Epoch 612:      TX: Train Loss: 0.0411, Acc: 0.9884, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25369805, Acc: 0.90628946, F1: 0.94704576 Bal: 0.8950 - Val Loss: 0.26393387, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8873\n","Epoch 613:      TX: Train Loss: 0.0411, Acc: 0.9877, F1: 0.9931 Bal: 0.9927 - Val Loss: 0.1905, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9301\n","           WALLETS: Train Loss: 0.25361732, Acc: 0.89934108, F1: 0.94284926 Bal: 0.8954 - Val Loss: 0.26318908, Accuracy: 0.8975, F1: 0.9417 Bal: 0.8882\n","Epoch 614:      TX: Train Loss: 0.0411, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1937, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25351265, Acc: 0.90595202, F1: 0.94684124 Bal: 0.8952 - Val Loss: 0.26374635, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8876\n","Epoch 615:      TX: Train Loss: 0.0410, Acc: 0.9875, F1: 0.9930 Bal: 0.9926 - Val Loss: 0.1899, Accuracy: 0.9656, F1: 0.9808 Bal: 0.9298\n","           WALLETS: Train Loss: 0.25342086, Acc: 0.89993614, F1: 0.94321004 Bal: 0.8954 - Val Loss: 0.26310092, Accuracy: 0.8982, F1: 0.9421 Bal: 0.8878\n","Epoch 616:      TX: Train Loss: 0.0410, Acc: 0.9886, F1: 0.9936 Bal: 0.9930 - Val Loss: 0.1946, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25331613, Acc: 0.90531342, F1: 0.94645656 Bal: 0.8953 - Val Loss: 0.26352209, Accuracy: 0.9037, F1: 0.9455 Bal: 0.8881\n","Epoch 617:      TX: Train Loss: 0.0410, Acc: 0.9874, F1: 0.9929 Bal: 0.9925 - Val Loss: 0.1891, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9296\n","           WALLETS: Train Loss: 0.25322616, Acc: 0.90089766, F1: 0.94378942 Bal: 0.8957 - Val Loss: 0.26301950, Accuracy: 0.8988, F1: 0.9425 Bal: 0.8873\n","Epoch 618:      TX: Train Loss: 0.0410, Acc: 0.9889, F1: 0.9938 Bal: 0.9932 - Val Loss: 0.1951, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.25313425, Acc: 0.90451880, F1: 0.94597896 Bal: 0.8953 - Val Loss: 0.26330164, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8882\n","Epoch 619:      TX: Train Loss: 0.0409, Acc: 0.9874, F1: 0.9929 Bal: 0.9925 - Val Loss: 0.1886, Accuracy: 0.9647, F1: 0.9803 Bal: 0.9293\n","           WALLETS: Train Loss: 0.25305369, Acc: 0.90154715, F1: 0.94418274 Bal: 0.8956 - Val Loss: 0.26296121, Accuracy: 0.8995, F1: 0.9430 Bal: 0.8876\n","Epoch 620:      TX: Train Loss: 0.0409, Acc: 0.9888, F1: 0.9938 Bal: 0.9931 - Val Loss: 0.1953, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.25297141, Acc: 0.90403985, F1: 0.94568747 Bal: 0.8956 - Val Loss: 0.26313019, Accuracy: 0.9023, F1: 0.9446 Bal: 0.8881\n","Epoch 621:      TX: Train Loss: 0.0408, Acc: 0.9874, F1: 0.9929 Bal: 0.9925 - Val Loss: 0.1892, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9297\n","           WALLETS: Train Loss: 0.25289628, Acc: 0.90205875, F1: 0.94449094 Bal: 0.8957 - Val Loss: 0.26287115, Accuracy: 0.9003, F1: 0.9434 Bal: 0.8878\n","Epoch 622:      TX: Train Loss: 0.0408, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1945, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25282061, Acc: 0.90377498, F1: 0.94552715 Bal: 0.8956 - Val Loss: 0.26297680, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8884\n","Epoch 623:      TX: Train Loss: 0.0407, Acc: 0.9880, F1: 0.9933 Bal: 0.9928 - Val Loss: 0.1906, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25274953, Acc: 0.90223291, F1: 0.94459626 Bal: 0.8957 - Val Loss: 0.26277238, Accuracy: 0.9004, F1: 0.9435 Bal: 0.8877\n","Epoch 624:      TX: Train Loss: 0.0407, Acc: 0.9884, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.1928, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25267673, Acc: 0.90383666, F1: 0.94556374 Bal: 0.8957 - Val Loss: 0.26288402, Accuracy: 0.9022, F1: 0.9446 Bal: 0.8884\n","Epoch 625:      TX: Train Loss: 0.0406, Acc: 0.9883, F1: 0.9934 Bal: 0.9930 - Val Loss: 0.1922, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25260848, Acc: 0.90212769, F1: 0.94453332 Bal: 0.8956 - Val Loss: 0.26267573, Accuracy: 0.9002, F1: 0.9434 Bal: 0.8876\n","Epoch 626:      TX: Train Loss: 0.0406, Acc: 0.9881, F1: 0.9933 Bal: 0.9929 - Val Loss: 0.1914, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9305\n","           WALLETS: Train Loss: 0.25253800, Acc: 0.90424304, F1: 0.94580714 Bal: 0.8958 - Val Loss: 0.26281837, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8885\n","Epoch 627:      TX: Train Loss: 0.0405, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1937, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25247550, Acc: 0.90174308, F1: 0.94429978 Bal: 0.8957 - Val Loss: 0.26253644, Accuracy: 0.9000, F1: 0.9433 Bal: 0.8880\n","Epoch 628:      TX: Train Loss: 0.0405, Acc: 0.9879, F1: 0.9932 Bal: 0.9928 - Val Loss: 0.1903, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9303\n","           WALLETS: Train Loss: 0.25241327, Acc: 0.90488890, F1: 0.94619719 Bal: 0.8957 - Val Loss: 0.26279595, Accuracy: 0.9035, F1: 0.9454 Bal: 0.8883\n","Epoch 629:      TX: Train Loss: 0.0405, Acc: 0.9888, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1945, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25236857, Acc: 0.90096660, F1: 0.94382910 Bal: 0.8959 - Val Loss: 0.26238519, Accuracy: 0.8988, F1: 0.9425 Bal: 0.8876\n","Epoch 630:      TX: Train Loss: 0.0405, Acc: 0.9878, F1: 0.9932 Bal: 0.9927 - Val Loss: 0.1900, Accuracy: 0.9658, F1: 0.9809 Bal: 0.9299\n","           WALLETS: Train Loss: 0.25233606, Acc: 0.90624592, F1: 0.94701181 Bal: 0.8958 - Val Loss: 0.26287898, Accuracy: 0.9048, F1: 0.9462 Bal: 0.8884\n","Epoch 631:      TX: Train Loss: 0.0404, Acc: 0.9888, F1: 0.9937 Bal: 0.9933 - Val Loss: 0.1946, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25235382, Acc: 0.89934834, F1: 0.94285079 Bal: 0.8957 - Val Loss: 0.26223347, Accuracy: 0.8973, F1: 0.9416 Bal: 0.8879\n","Epoch 632:      TX: Train Loss: 0.0404, Acc: 0.9880, F1: 0.9933 Bal: 0.9928 - Val Loss: 0.1903, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9301\n","           WALLETS: Train Loss: 0.25241047, Acc: 0.90848827, F1: 0.94835646 Bal: 0.8958 - Val Loss: 0.26322666, Accuracy: 0.9070, F1: 0.9475 Bal: 0.8880\n","Epoch 633:      TX: Train Loss: 0.0403, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1942, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25259486, Acc: 0.89646377, F1: 0.94109998 Bal: 0.8956 - Val Loss: 0.26222903, Accuracy: 0.8948, F1: 0.9401 Bal: 0.8891\n","Epoch 634:      TX: Train Loss: 0.0403, Acc: 0.9881, F1: 0.9934 Bal: 0.9929 - Val Loss: 0.1913, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9304\n","           WALLETS: Train Loss: 0.25281867, Acc: 0.91156152, F1: 0.95019982 Bal: 0.8951 - Val Loss: 0.26401606, Accuracy: 0.9101, F1: 0.9493 Bal: 0.8878\n","Epoch 635:      TX: Train Loss: 0.0402, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25317395, Acc: 0.89293697, F1: 0.93894897 Bal: 0.8956 - Val Loss: 0.26248664, Accuracy: 0.8922, F1: 0.9385 Bal: 0.8902\n","Epoch 636:      TX: Train Loss: 0.0402, Acc: 0.9884, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.1926, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25319001, Acc: 0.91356076, F1: 0.95139740 Bal: 0.8943 - Val Loss: 0.26464605, Accuracy: 0.9128, F1: 0.9509 Bal: 0.8878\n","Epoch 637:      TX: Train Loss: 0.0402, Acc: 0.9883, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.1920, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25294524, Acc: 0.89356105, F1: 0.93932920 Bal: 0.8957 - Val Loss: 0.26234430, Accuracy: 0.8926, F1: 0.9387 Bal: 0.8899\n","Epoch 638:      TX: Train Loss: 0.0401, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1929, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25175893, Acc: 0.90179388, F1: 0.94432834 Bal: 0.8959 - Val Loss: 0.26200512, Accuracy: 0.9000, F1: 0.9433 Bal: 0.8880\n","Epoch 639:      TX: Train Loss: 0.0401, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1933, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25261015, Acc: 0.91195701, F1: 0.95043600 Bal: 0.8951 - Val Loss: 0.26391470, Accuracy: 0.9107, F1: 0.9497 Bal: 0.8880\n","Epoch 640:      TX: Train Loss: 0.0401, Acc: 0.9884, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.1925, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25172830, Acc: 0.90608990, F1: 0.94691699 Bal: 0.8959 - Val Loss: 0.26241022, Accuracy: 0.9047, F1: 0.9461 Bal: 0.8887\n","Epoch 641:      TX: Train Loss: 0.0401, Acc: 0.9884, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.1922, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25230914, Acc: 0.89607553, F1: 0.94086190 Bal: 0.8958 - Val Loss: 0.26197714, Accuracy: 0.8946, F1: 0.9399 Bal: 0.8901\n","Epoch 642:      TX: Train Loss: 0.0401, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25174341, Acc: 0.89995428, F1: 0.94321554 Bal: 0.8959 - Val Loss: 0.26183039, Accuracy: 0.8979, F1: 0.9420 Bal: 0.8881\n","Epoch 643:      TX: Train Loss: 0.0400, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25201946, Acc: 0.90963121, F1: 0.94903893 Bal: 0.8960 - Val Loss: 0.26309580, Accuracy: 0.9083, F1: 0.9482 Bal: 0.8882\n","Epoch 644:      TX: Train Loss: 0.0400, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1926, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.25172094, Acc: 0.90759205, F1: 0.94781789 Bal: 0.8960 - Val Loss: 0.26259413, Accuracy: 0.9066, F1: 0.9472 Bal: 0.8888\n","Epoch 645:      TX: Train Loss: 0.0400, Acc: 0.9884, F1: 0.9935 Bal: 0.9931 - Val Loss: 0.1925, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.25179410, Acc: 0.89861178, F1: 0.94240136 Bal: 0.8960 - Val Loss: 0.26177272, Accuracy: 0.8968, F1: 0.9413 Bal: 0.8882\n","Epoch 646:      TX: Train Loss: 0.0400, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25171450, Acc: 0.89904356, F1: 0.94266403 Bal: 0.8959 - Val Loss: 0.26175267, Accuracy: 0.8972, F1: 0.9415 Bal: 0.8882\n","Epoch 647:      TX: Train Loss: 0.0400, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25158709, Acc: 0.90729815, F1: 0.94764002 Bal: 0.8961 - Val Loss: 0.26246506, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8888\n","Epoch 648:      TX: Train Loss: 0.0399, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1925, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25165841, Acc: 0.90830322, F1: 0.94824324 Bal: 0.8961 - Val Loss: 0.26265234, Accuracy: 0.9071, F1: 0.9475 Bal: 0.8885\n","Epoch 649:      TX: Train Loss: 0.0399, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1926, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25144732, Acc: 0.90111900, F1: 0.94391923 Bal: 0.8960 - Val Loss: 0.26172608, Accuracy: 0.8990, F1: 0.9427 Bal: 0.8879\n","Epoch 650:      TX: Train Loss: 0.0399, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25160146, Acc: 0.89898187, F1: 0.94262604 Bal: 0.8959 - Val Loss: 0.26166716, Accuracy: 0.8971, F1: 0.9415 Bal: 0.8883\n","Epoch 651:      TX: Train Loss: 0.0399, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25132868, Acc: 0.90507758, F1: 0.94630546 Bal: 0.8962 - Val Loss: 0.26201376, Accuracy: 0.9036, F1: 0.9454 Bal: 0.8890\n","Epoch 652:      TX: Train Loss: 0.0399, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1926, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25150719, Acc: 0.90802020, F1: 0.94807307 Bal: 0.8961 - Val Loss: 0.26250738, Accuracy: 0.9071, F1: 0.9475 Bal: 0.8890\n","Epoch 653:      TX: Train Loss: 0.0399, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1927, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25124878, Acc: 0.90314727, F1: 0.94514374 Bal: 0.8961 - Val Loss: 0.26176494, Accuracy: 0.9011, F1: 0.9439 Bal: 0.8883\n","Epoch 654:      TX: Train Loss: 0.0398, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25141650, Acc: 0.89955153, F1: 0.94297203 Bal: 0.8959 - Val Loss: 0.26158187, Accuracy: 0.8976, F1: 0.9418 Bal: 0.8881\n","Epoch 655:      TX: Train Loss: 0.0398, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25118390, Acc: 0.90338674, F1: 0.94528725 Bal: 0.8962 - Val Loss: 0.26174647, Accuracy: 0.9014, F1: 0.9441 Bal: 0.8882\n","Epoch 656:      TX: Train Loss: 0.0398, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1928, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25130618, Acc: 0.90735258, F1: 0.94767258 Bal: 0.8961 - Val Loss: 0.26227039, Accuracy: 0.9062, F1: 0.9470 Bal: 0.8890\n","Epoch 657:      TX: Train Loss: 0.0398, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1929, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25112769, Acc: 0.90458774, F1: 0.94601009 Bal: 0.8963 - Val Loss: 0.26182577, Accuracy: 0.9029, F1: 0.9450 Bal: 0.8888\n","Epoch 658:      TX: Train Loss: 0.0398, Acc: 0.9885, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25121051, Acc: 0.90062191, F1: 0.94361723 Bal: 0.8962 - Val Loss: 0.26151890, Accuracy: 0.8986, F1: 0.9424 Bal: 0.8880\n","Epoch 659:      TX: Train Loss: 0.0397, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25107953, Acc: 0.90242885, F1: 0.94471093 Bal: 0.8960 - Val Loss: 0.26158682, Accuracy: 0.9003, F1: 0.9434 Bal: 0.8880\n","Epoch 660:      TX: Train Loss: 0.0397, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1929, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25110936, Acc: 0.90642734, F1: 0.94711608 Bal: 0.8963 - Val Loss: 0.26201221, Accuracy: 0.9049, F1: 0.9462 Bal: 0.8889\n","Epoch 661:      TX: Train Loss: 0.0397, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1929, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25102484, Acc: 0.90531705, F1: 0.94644928 Bal: 0.8962 - Val Loss: 0.26182747, Accuracy: 0.9040, F1: 0.9456 Bal: 0.8891\n","Epoch 662:      TX: Train Loss: 0.0397, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25102419, Acc: 0.90159432, F1: 0.94420707 Bal: 0.8960 - Val Loss: 0.26147112, Accuracy: 0.8994, F1: 0.9429 Bal: 0.8878\n","Epoch 663:      TX: Train Loss: 0.0397, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25097290, Acc: 0.90197893, F1: 0.94443885 Bal: 0.8961 - Val Loss: 0.26147607, Accuracy: 0.8999, F1: 0.9432 Bal: 0.8881\n","Epoch 664:      TX: Train Loss: 0.0397, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25093791, Acc: 0.90548033, F1: 0.94654744 Bal: 0.8962 - Val Loss: 0.26178864, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8891\n","Epoch 665:      TX: Train Loss: 0.0396, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25091043, Acc: 0.90561095, F1: 0.94662591 Bal: 0.8962 - Val Loss: 0.26177803, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8890\n","Epoch 666:      TX: Train Loss: 0.0396, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25086525, Acc: 0.90250867, F1: 0.94475775 Bal: 0.8962 - Val Loss: 0.26143605, Accuracy: 0.9004, F1: 0.9435 Bal: 0.8881\n","Epoch 667:      TX: Train Loss: 0.0396, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25085276, Acc: 0.90201884, F1: 0.94446318 Bal: 0.8960 - Val Loss: 0.26138338, Accuracy: 0.8999, F1: 0.9432 Bal: 0.8879\n","Epoch 668:      TX: Train Loss: 0.0396, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25079283, Acc: 0.90485624, F1: 0.94617021 Bal: 0.8964 - Val Loss: 0.26160201, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8890\n","Epoch 669:      TX: Train Loss: 0.0396, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25078624, Acc: 0.90558555, F1: 0.94660924 Bal: 0.8964 - Val Loss: 0.26168510, Accuracy: 0.9040, F1: 0.9457 Bal: 0.8891\n","Epoch 670:      TX: Train Loss: 0.0396, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25072882, Acc: 0.90328515, F1: 0.94522544 Bal: 0.8962 - Val Loss: 0.26140746, Accuracy: 0.9012, F1: 0.9439 Bal: 0.8883\n","Epoch 671:      TX: Train Loss: 0.0395, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25072548, Acc: 0.90229822, F1: 0.94462985 Bal: 0.8962 - Val Loss: 0.26131475, Accuracy: 0.9001, F1: 0.9433 Bal: 0.8880\n","Epoch 672:      TX: Train Loss: 0.0395, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1930, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25066441, Acc: 0.90445349, F1: 0.94592558 Bal: 0.8966 - Val Loss: 0.26145956, Accuracy: 0.9023, F1: 0.9446 Bal: 0.8886\n","Epoch 673:      TX: Train Loss: 0.0395, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25065717, Acc: 0.90544041, F1: 0.94652168 Bal: 0.8964 - Val Loss: 0.26156983, Accuracy: 0.9039, F1: 0.9456 Bal: 0.8890\n","Epoch 674:      TX: Train Loss: 0.0395, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25060287, Acc: 0.90393100, F1: 0.94561223 Bal: 0.8965 - Val Loss: 0.26135850, Accuracy: 0.9018, F1: 0.9443 Bal: 0.8887\n","Epoch 675:      TX: Train Loss: 0.0395, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25059438, Acc: 0.90263929, F1: 0.94483494 Bal: 0.8963 - Val Loss: 0.26124385, Accuracy: 0.9005, F1: 0.9435 Bal: 0.8882\n","Epoch 676:      TX: Train Loss: 0.0395, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25054210, Acc: 0.90414871, F1: 0.94574261 Bal: 0.8966 - Val Loss: 0.26133943, Accuracy: 0.9020, F1: 0.9444 Bal: 0.8886\n","Epoch 677:      TX: Train Loss: 0.0394, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25052720, Acc: 0.90518643, F1: 0.94636858 Bal: 0.8964 - Val Loss: 0.26145354, Accuracy: 0.9036, F1: 0.9454 Bal: 0.8891\n","Epoch 678:      TX: Train Loss: 0.0394, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25048169, Acc: 0.90421039, F1: 0.94577964 Bal: 0.8966 - Val Loss: 0.26131091, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8886\n","Epoch 679:      TX: Train Loss: 0.0394, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25046584, Acc: 0.90307833, F1: 0.94509894 Bal: 0.8964 - Val Loss: 0.26118818, Accuracy: 0.9009, F1: 0.9438 Bal: 0.8883\n","Epoch 680:      TX: Train Loss: 0.0394, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25042191, Acc: 0.90401083, F1: 0.94565965 Bal: 0.8965 - Val Loss: 0.26123306, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8887\n","Epoch 681:      TX: Train Loss: 0.0394, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25040099, Acc: 0.90498687, F1: 0.94624609 Bal: 0.8967 - Val Loss: 0.26132271, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8889\n","Epoch 682:      TX: Train Loss: 0.0393, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1931, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25036162, Acc: 0.90442809, F1: 0.94590998 Bal: 0.8966 - Val Loss: 0.26121858, Accuracy: 0.9024, F1: 0.9447 Bal: 0.8888\n","Epoch 683:      TX: Train Loss: 0.0393, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25033972, Acc: 0.90345205, F1: 0.94532356 Bal: 0.8965 - Val Loss: 0.26110274, Accuracy: 0.9012, F1: 0.9440 Bal: 0.8883\n","Epoch 684:      TX: Train Loss: 0.0393, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25030181, Acc: 0.90402534, F1: 0.94566742 Bal: 0.8966 - Val Loss: 0.26113078, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8887\n","Epoch 685:      TX: Train Loss: 0.0393, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25027630, Acc: 0.90489253, F1: 0.94618786 Bal: 0.8968 - Val Loss: 0.26120725, Accuracy: 0.9029, F1: 0.9450 Bal: 0.8889\n","Epoch 686:      TX: Train Loss: 0.0393, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1932, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25024167, Acc: 0.90451517, F1: 0.94596193 Bal: 0.8967 - Val Loss: 0.26113775, Accuracy: 0.9024, F1: 0.9447 Bal: 0.8888\n","Epoch 687:      TX: Train Loss: 0.0393, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1933, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25021577, Acc: 0.90372781, F1: 0.94548869 Bal: 0.8966 - Val Loss: 0.26103768, Accuracy: 0.9017, F1: 0.9442 Bal: 0.8886\n","Epoch 688:      TX: Train Loss: 0.0392, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.1933, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25018212, Acc: 0.90405437, F1: 0.94568453 Bal: 0.8967 - Val Loss: 0.26104847, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8887\n","Epoch 689:      TX: Train Loss: 0.0392, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1932, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.25015390, Acc: 0.90476190, F1: 0.94610975 Bal: 0.8968 - Val Loss: 0.26110616, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8890\n","Epoch 690:      TX: Train Loss: 0.0392, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1932, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25012136, Acc: 0.90455146, F1: 0.94598335 Bal: 0.8967 - Val Loss: 0.26105416, Accuracy: 0.9024, F1: 0.9447 Bal: 0.8888\n","Epoch 691:      TX: Train Loss: 0.0392, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25009418, Acc: 0.90387658, F1: 0.94557706 Bal: 0.8967 - Val Loss: 0.26096559, Accuracy: 0.9018, F1: 0.9443 Bal: 0.8888\n","Epoch 692:      TX: Train Loss: 0.0392, Acc: 0.9886, F1: 0.9936 Bal: 0.9932 - Val Loss: 0.1933, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25006217, Acc: 0.90407977, F1: 0.94569968 Bal: 0.8967 - Val Loss: 0.26096466, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8888\n","Epoch 693:      TX: Train Loss: 0.0391, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1933, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25003293, Acc: 0.90470748, F1: 0.94607707 Bal: 0.8967 - Val Loss: 0.26100299, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8889\n","Epoch 694:      TX: Train Loss: 0.0391, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1933, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.25000134, Acc: 0.90457686, F1: 0.94599784 Bal: 0.8968 - Val Loss: 0.26095691, Accuracy: 0.9025, F1: 0.9447 Bal: 0.8889\n","Epoch 695:      TX: Train Loss: 0.0391, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24997324, Acc: 0.90406525, F1: 0.94569013 Bal: 0.8968 - Val Loss: 0.26087970, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8889\n","Epoch 696:      TX: Train Loss: 0.0391, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24994218, Acc: 0.90425030, F1: 0.94580079 Bal: 0.8968 - Val Loss: 0.26087335, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8888\n","Epoch 697:      TX: Train Loss: 0.0391, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24991232, Acc: 0.90468571, F1: 0.94606342 Bal: 0.8968 - Val Loss: 0.26089978, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8889\n","Epoch 698:      TX: Train Loss: 0.0391, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24988151, Acc: 0.90459137, F1: 0.94600605 Bal: 0.8969 - Val Loss: 0.26085892, Accuracy: 0.9025, F1: 0.9447 Bal: 0.8890\n","Epoch 699:      TX: Train Loss: 0.0390, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24985293, Acc: 0.90417410, F1: 0.94575465 Bal: 0.8969 - Val Loss: 0.26079360, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8891\n","Epoch 700:      TX: Train Loss: 0.0390, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24982250, Acc: 0.90434101, F1: 0.94585403 Bal: 0.8970 - Val Loss: 0.26078758, Accuracy: 0.9022, F1: 0.9446 Bal: 0.8892\n","Epoch 701:      TX: Train Loss: 0.0390, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1934, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24979274, Acc: 0.90466031, F1: 0.94604739 Bal: 0.8969 - Val Loss: 0.26081017, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8891\n","Epoch 702:      TX: Train Loss: 0.0390, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1935, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24976282, Acc: 0.90454783, F1: 0.94597897 Bal: 0.8969 - Val Loss: 0.26077884, Accuracy: 0.9025, F1: 0.9447 Bal: 0.8892\n","Epoch 703:      TX: Train Loss: 0.0390, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1935, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24973392, Acc: 0.90434464, F1: 0.94585575 Bal: 0.8970 - Val Loss: 0.26072386, Accuracy: 0.9022, F1: 0.9446 Bal: 0.8892\n","Epoch 704:      TX: Train Loss: 0.0390, Acc: 0.9888, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.1935, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24970384, Acc: 0.90443898, F1: 0.94591248 Bal: 0.8970 - Val Loss: 0.26071051, Accuracy: 0.9023, F1: 0.9446 Bal: 0.8892\n","Epoch 705:      TX: Train Loss: 0.0389, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1935, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24967442, Acc: 0.90468934, F1: 0.94606382 Bal: 0.8970 - Val Loss: 0.26071474, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8894\n","Epoch 706:      TX: Train Loss: 0.0389, Acc: 0.9888, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24964450, Acc: 0.90460951, F1: 0.94601443 Bal: 0.8971 - Val Loss: 0.26068136, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8894\n","Epoch 707:      TX: Train Loss: 0.0389, Acc: 0.9888, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24961545, Acc: 0.90443898, F1: 0.94591181 Bal: 0.8971 - Val Loss: 0.26063859, Accuracy: 0.9024, F1: 0.9447 Bal: 0.8893\n","Epoch 708:      TX: Train Loss: 0.0389, Acc: 0.9888, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24958515, Acc: 0.90452243, F1: 0.94596226 Bal: 0.8971 - Val Loss: 0.26062864, Accuracy: 0.9025, F1: 0.9447 Bal: 0.8893\n","Epoch 709:      TX: Train Loss: 0.0389, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24955556, Acc: 0.90469659, F1: 0.94606659 Bal: 0.8971 - Val Loss: 0.26062411, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8894\n","Epoch 710:      TX: Train Loss: 0.0388, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24952604, Acc: 0.90464217, F1: 0.94603369 Bal: 0.8971 - Val Loss: 0.26059264, Accuracy: 0.9025, F1: 0.9448 Bal: 0.8894\n","Epoch 711:      TX: Train Loss: 0.0388, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24949701, Acc: 0.90451880, F1: 0.94595988 Bal: 0.8971 - Val Loss: 0.26055712, Accuracy: 0.9024, F1: 0.9447 Bal: 0.8893\n","Epoch 712:      TX: Train Loss: 0.0388, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24946716, Acc: 0.90462403, F1: 0.94602287 Bal: 0.8971 - Val Loss: 0.26054725, Accuracy: 0.9025, F1: 0.9447 Bal: 0.8893\n","Epoch 713:      TX: Train Loss: 0.0388, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24943788, Acc: 0.90470022, F1: 0.94606920 Bal: 0.8971 - Val Loss: 0.26053959, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8894\n","Epoch 714:      TX: Train Loss: 0.0388, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24940851, Acc: 0.90465668, F1: 0.94604323 Bal: 0.8971 - Val Loss: 0.26051331, Accuracy: 0.9025, F1: 0.9448 Bal: 0.8894\n","Epoch 715:      TX: Train Loss: 0.0388, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24937922, Acc: 0.90458411, F1: 0.94599950 Bal: 0.8971 - Val Loss: 0.26048285, Accuracy: 0.9025, F1: 0.9447 Bal: 0.8895\n","Epoch 716:      TX: Train Loss: 0.0387, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24934985, Acc: 0.90467119, F1: 0.94605145 Bal: 0.8971 - Val Loss: 0.26046753, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8896\n","Epoch 717:      TX: Train Loss: 0.0387, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24932015, Acc: 0.90470748, F1: 0.94607309 Bal: 0.8971 - Val Loss: 0.26045123, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8896\n","Epoch 718:      TX: Train Loss: 0.0387, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1936, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24929105, Acc: 0.90464217, F1: 0.94603435 Bal: 0.8971 - Val Loss: 0.26042548, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8896\n","Epoch 719:      TX: Train Loss: 0.0387, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24926238, Acc: 0.90463491, F1: 0.94603025 Bal: 0.8971 - Val Loss: 0.26040351, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8895\n","Epoch 720:      TX: Train Loss: 0.0387, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24923329, Acc: 0.90469297, F1: 0.94606487 Bal: 0.8971 - Val Loss: 0.26038736, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8896\n","Epoch 721:      TX: Train Loss: 0.0387, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24920434, Acc: 0.90469659, F1: 0.94606682 Bal: 0.8971 - Val Loss: 0.26036528, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8896\n","Epoch 722:      TX: Train Loss: 0.0386, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24917515, Acc: 0.90466031, F1: 0.94604517 Bal: 0.8971 - Val Loss: 0.26034224, Accuracy: 0.9026, F1: 0.9448 Bal: 0.8896\n","Epoch 723:      TX: Train Loss: 0.0386, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24914584, Acc: 0.90470748, F1: 0.94607353 Bal: 0.8971 - Val Loss: 0.26032722, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8896\n","Epoch 724:      TX: Train Loss: 0.0386, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1937, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24911645, Acc: 0.90476553, F1: 0.94610837 Bal: 0.8971 - Val Loss: 0.26031020, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8896\n","Epoch 725:      TX: Train Loss: 0.0386, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1938, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24908760, Acc: 0.90475828, F1: 0.94610360 Bal: 0.8971 - Val Loss: 0.26028875, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8896\n","Epoch 726:      TX: Train Loss: 0.0386, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1938, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24905819, Acc: 0.90473651, F1: 0.94609062 Bal: 0.8971 - Val Loss: 0.26026842, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8898\n","Epoch 727:      TX: Train Loss: 0.0386, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24902929, Acc: 0.90475465, F1: 0.94610166 Bal: 0.8971 - Val Loss: 0.26025358, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8898\n","Epoch 728:      TX: Train Loss: 0.0385, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1938, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24900042, Acc: 0.90479819, F1: 0.94612785 Bal: 0.8971 - Val Loss: 0.26023790, Accuracy: 0.9027, F1: 0.9449 Bal: 0.8898\n","Epoch 729:      TX: Train Loss: 0.0385, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24897170, Acc: 0.90479093, F1: 0.94612330 Bal: 0.8971 - Val Loss: 0.26021609, Accuracy: 0.9027, F1: 0.9449 Bal: 0.8898\n","Epoch 730:      TX: Train Loss: 0.0385, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24894284, Acc: 0.90483084, F1: 0.94614710 Bal: 0.8972 - Val Loss: 0.26019481, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8898\n","Epoch 731:      TX: Train Loss: 0.0385, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24891379, Acc: 0.90484173, F1: 0.94615381 Bal: 0.8971 - Val Loss: 0.26017448, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8898\n","Epoch 732:      TX: Train Loss: 0.0385, Acc: 0.9888, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24888466, Acc: 0.90488164, F1: 0.94617761 Bal: 0.8972 - Val Loss: 0.26015395, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8898\n","Epoch 733:      TX: Train Loss: 0.0384, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24885601, Acc: 0.90489978, F1: 0.94618865 Bal: 0.8972 - Val Loss: 0.26013619, Accuracy: 0.9028, F1: 0.9449 Bal: 0.8898\n","Epoch 734:      TX: Train Loss: 0.0384, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24882737, Acc: 0.90489616, F1: 0.94618671 Bal: 0.8971 - Val Loss: 0.26011738, Accuracy: 0.9029, F1: 0.9450 Bal: 0.8899\n","Epoch 735:      TX: Train Loss: 0.0384, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1938, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24879868, Acc: 0.90490704, F1: 0.94619298 Bal: 0.8972 - Val Loss: 0.26009727, Accuracy: 0.9029, F1: 0.9450 Bal: 0.8900\n","Epoch 736:      TX: Train Loss: 0.0384, Acc: 0.9888, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1939, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24877003, Acc: 0.90492881, F1: 0.94620574 Bal: 0.8972 - Val Loss: 0.26008168, Accuracy: 0.9029, F1: 0.9450 Bal: 0.8900\n","Epoch 737:      TX: Train Loss: 0.0384, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24874108, Acc: 0.90496872, F1: 0.94622932 Bal: 0.8972 - Val Loss: 0.26006791, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8901\n","Epoch 738:      TX: Train Loss: 0.0384, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24871194, Acc: 0.90501226, F1: 0.94625528 Bal: 0.8973 - Val Loss: 0.26004997, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8901\n","Epoch 739:      TX: Train Loss: 0.0383, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24868304, Acc: 0.90499775, F1: 0.94624663 Bal: 0.8973 - Val Loss: 0.26003024, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8901\n","Epoch 740:      TX: Train Loss: 0.0383, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24865362, Acc: 0.90500501, F1: 0.94625117 Bal: 0.8972 - Val Loss: 0.26001036, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8901\n","Epoch 741:      TX: Train Loss: 0.0383, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24862485, Acc: 0.90500501, F1: 0.94625117 Bal: 0.8972 - Val Loss: 0.25998908, Accuracy: 0.9030, F1: 0.9451 Bal: 0.8899\n","Epoch 742:      TX: Train Loss: 0.0383, Acc: 0.9890, F1: 0.9938 Bal: 0.9934 - Val Loss: 0.1940, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.24859571, Acc: 0.90501589, F1: 0.94625788 Bal: 0.8972 - Val Loss: 0.25996697, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 743:      TX: Train Loss: 0.0383, Acc: 0.9890, F1: 0.9939 Bal: 0.9934 - Val Loss: 0.1941, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.24856699, Acc: 0.90504492, F1: 0.94627519 Bal: 0.8972 - Val Loss: 0.25994632, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 744:      TX: Train Loss: 0.0383, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.24853820, Acc: 0.90501589, F1: 0.94625810 Bal: 0.8972 - Val Loss: 0.25992435, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 745:      TX: Train Loss: 0.0383, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.1940, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.24850899, Acc: 0.90499775, F1: 0.94624729 Bal: 0.8972 - Val Loss: 0.25990462, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 746:      TX: Train Loss: 0.0382, Acc: 0.9890, F1: 0.9939 Bal: 0.9934 - Val Loss: 0.1941, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24848038, Acc: 0.90500864, F1: 0.94625378 Bal: 0.8972 - Val Loss: 0.25988758, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 747:      TX: Train Loss: 0.0382, Acc: 0.9891, F1: 0.9939 Bal: 0.9934 - Val Loss: 0.1941, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24845113, Acc: 0.90503403, F1: 0.94626892 Bal: 0.8972 - Val Loss: 0.25986972, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 748:      TX: Train Loss: 0.0382, Acc: 0.9890, F1: 0.9939 Bal: 0.9935 - Val Loss: 0.1940, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9307\n","           WALLETS: Train Loss: 0.24842209, Acc: 0.90499049, F1: 0.94624296 Bal: 0.8972 - Val Loss: 0.25984576, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 749:      TX: Train Loss: 0.0382, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1942, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9308\n","           WALLETS: Train Loss: 0.24839306, Acc: 0.90500501, F1: 0.94625139 Bal: 0.8972 - Val Loss: 0.25982863, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8899\n","Epoch 750:      TX: Train Loss: 0.0382, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1942, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24836430, Acc: 0.90505943, F1: 0.94628384 Bal: 0.8972 - Val Loss: 0.25981498, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 751:      TX: Train Loss: 0.0382, Acc: 0.9891, F1: 0.9939 Bal: 0.9935 - Val Loss: 0.1941, Accuracy: 0.9675, F1: 0.9819 Bal: 0.9309\n","           WALLETS: Train Loss: 0.24833581, Acc: 0.90506669, F1: 0.94628817 Bal: 0.8972 - Val Loss: 0.25979486, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 752:      TX: Train Loss: 0.0381, Acc: 0.9891, F1: 0.9939 Bal: 0.9935 - Val Loss: 0.1941, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24830730, Acc: 0.90502315, F1: 0.94626199 Bal: 0.8972 - Val Loss: 0.25976923, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 753:      TX: Train Loss: 0.0381, Acc: 0.9891, F1: 0.9939 Bal: 0.9935 - Val Loss: 0.1943, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24827845, Acc: 0.90504492, F1: 0.94627497 Bal: 0.8973 - Val Loss: 0.25974810, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 754:      TX: Train Loss: 0.0381, Acc: 0.9891, F1: 0.9939 Bal: 0.9935 - Val Loss: 0.1942, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24824964, Acc: 0.90507758, F1: 0.94629444 Bal: 0.8973 - Val Loss: 0.25972998, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 755:      TX: Train Loss: 0.0381, Acc: 0.9891, F1: 0.9939 Bal: 0.9935 - Val Loss: 0.1942, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24822101, Acc: 0.90507395, F1: 0.94629205 Bal: 0.8973 - Val Loss: 0.25970954, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 756:      TX: Train Loss: 0.0381, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24819221, Acc: 0.90505580, F1: 0.94628102 Bal: 0.8973 - Val Loss: 0.25968537, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8900\n","Epoch 757:      TX: Train Loss: 0.0381, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24816355, Acc: 0.90507758, F1: 0.94629400 Bal: 0.8973 - Val Loss: 0.25966704, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8901\n","Epoch 758:      TX: Train Loss: 0.0380, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1942, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24813500, Acc: 0.90510660, F1: 0.94631152 Bal: 0.8973 - Val Loss: 0.25965476, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8901\n","Epoch 759:      TX: Train Loss: 0.0380, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24810655, Acc: 0.90508846, F1: 0.94630049 Bal: 0.8973 - Val Loss: 0.25963375, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8901\n","Epoch 760:      TX: Train Loss: 0.0380, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1944, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24807794, Acc: 0.90508120, F1: 0.94629616 Bal: 0.8973 - Val Loss: 0.25961232, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8901\n","Epoch 761:      TX: Train Loss: 0.0380, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24804930, Acc: 0.90516466, F1: 0.94634591 Bal: 0.8974 - Val Loss: 0.25959992, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8899\n","Epoch 762:      TX: Train Loss: 0.0380, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1944, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24802081, Acc: 0.90514651, F1: 0.94633531 Bal: 0.8973 - Val Loss: 0.25958270, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8899\n","Epoch 763:      TX: Train Loss: 0.0380, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24799249, Acc: 0.90513563, F1: 0.94632839 Bal: 0.8974 - Val Loss: 0.25955805, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8901\n","Epoch 764:      TX: Train Loss: 0.0379, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24796376, Acc: 0.90513926, F1: 0.94633033 Bal: 0.8974 - Val Loss: 0.25953290, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8901\n","Epoch 765:      TX: Train Loss: 0.0379, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24793559, Acc: 0.90525174, F1: 0.94639738 Bal: 0.8975 - Val Loss: 0.25951898, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8899\n","Epoch 766:      TX: Train Loss: 0.0379, Acc: 0.9893, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24790747, Acc: 0.90527714, F1: 0.94641274 Bal: 0.8974 - Val Loss: 0.25950235, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8898\n","Epoch 767:      TX: Train Loss: 0.0379, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24787891, Acc: 0.90520457, F1: 0.94636904 Bal: 0.8974 - Val Loss: 0.25947729, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8899\n","Epoch 768:      TX: Train Loss: 0.0379, Acc: 0.9891, F1: 0.9939 Bal: 0.9936 - Val Loss: 0.1943, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9310\n","           WALLETS: Train Loss: 0.24785009, Acc: 0.90520820, F1: 0.94637076 Bal: 0.8975 - Val Loss: 0.25945812, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8898\n","Epoch 769:      TX: Train Loss: 0.0379, Acc: 0.9893, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24782199, Acc: 0.90533519, F1: 0.94644690 Bal: 0.8975 - Val Loss: 0.25944450, Accuracy: 0.9034, F1: 0.9453 Bal: 0.8898\n","Epoch 770:      TX: Train Loss: 0.0378, Acc: 0.9893, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1946, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24779315, Acc: 0.90529891, F1: 0.94642505 Bal: 0.8975 - Val Loss: 0.25942358, Accuracy: 0.9034, F1: 0.9453 Bal: 0.8898\n","Epoch 771:      TX: Train Loss: 0.0378, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24776478, Acc: 0.90526625, F1: 0.94640559 Bal: 0.8975 - Val Loss: 0.25940099, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8898\n","Epoch 772:      TX: Train Loss: 0.0378, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9312\n","           WALLETS: Train Loss: 0.24773639, Acc: 0.90537873, F1: 0.94647241 Bal: 0.8976 - Val Loss: 0.25938398, Accuracy: 0.9034, F1: 0.9453 Bal: 0.8899\n","Epoch 773:      TX: Train Loss: 0.0378, Acc: 0.9893, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1947, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24770804, Acc: 0.90542953, F1: 0.94650268 Bal: 0.8976 - Val Loss: 0.25936922, Accuracy: 0.9035, F1: 0.9453 Bal: 0.8899\n","Epoch 774:      TX: Train Loss: 0.0378, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1946, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24767932, Acc: 0.90537873, F1: 0.94647285 Bal: 0.8975 - Val Loss: 0.25934741, Accuracy: 0.9034, F1: 0.9453 Bal: 0.8899\n","Epoch 775:      TX: Train Loss: 0.0378, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1945, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24765088, Acc: 0.90536422, F1: 0.94646420 Bal: 0.8975 - Val Loss: 0.25933099, Accuracy: 0.9034, F1: 0.9453 Bal: 0.8900\n","Epoch 776:      TX: Train Loss: 0.0377, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1947, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24762243, Acc: 0.90548758, F1: 0.94653772 Bal: 0.8976 - Val Loss: 0.25932240, Accuracy: 0.9036, F1: 0.9454 Bal: 0.8901\n","Epoch 777:      TX: Train Loss: 0.0377, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24759369, Acc: 0.90550210, F1: 0.94654637 Bal: 0.8976 - Val Loss: 0.25930336, Accuracy: 0.9037, F1: 0.9454 Bal: 0.8901\n","Epoch 778:      TX: Train Loss: 0.0377, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1946, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24756506, Acc: 0.90546944, F1: 0.94652647 Bal: 0.8976 - Val Loss: 0.25927633, Accuracy: 0.9036, F1: 0.9454 Bal: 0.8901\n","Epoch 779:      TX: Train Loss: 0.0377, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9313\n","           WALLETS: Train Loss: 0.24753655, Acc: 0.90552387, F1: 0.94655846 Bal: 0.8977 - Val Loss: 0.25925785, Accuracy: 0.9039, F1: 0.9455 Bal: 0.8902\n","Epoch 780:      TX: Train Loss: 0.0377, Acc: 0.9893, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1948, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24750845, Acc: 0.90557467, F1: 0.94658873 Bal: 0.8977 - Val Loss: 0.25924137, Accuracy: 0.9039, F1: 0.9456 Bal: 0.8903\n","Epoch 781:      TX: Train Loss: 0.0377, Acc: 0.9892, F1: 0.9940 Bal: 0.9936 - Val Loss: 0.1946, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24748005, Acc: 0.90553838, F1: 0.94656711 Bal: 0.8977 - Val Loss: 0.25921825, Accuracy: 0.9038, F1: 0.9455 Bal: 0.8902\n","Epoch 782:      TX: Train Loss: 0.0377, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24745138, Acc: 0.90554564, F1: 0.94657143 Bal: 0.8977 - Val Loss: 0.25920168, Accuracy: 0.9038, F1: 0.9455 Bal: 0.8902\n","Epoch 783:      TX: Train Loss: 0.0376, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24742284, Acc: 0.90556015, F1: 0.94658052 Bal: 0.8977 - Val Loss: 0.25918916, Accuracy: 0.9039, F1: 0.9456 Bal: 0.8903\n","Epoch 784:      TX: Train Loss: 0.0376, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24739455, Acc: 0.90555289, F1: 0.94657598 Bal: 0.8977 - Val Loss: 0.25916842, Accuracy: 0.9039, F1: 0.9456 Bal: 0.8903\n","Epoch 785:      TX: Train Loss: 0.0376, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24736638, Acc: 0.90559644, F1: 0.94660148 Bal: 0.8978 - Val Loss: 0.25914770, Accuracy: 0.9039, F1: 0.9456 Bal: 0.8903\n","Epoch 786:      TX: Train Loss: 0.0376, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1947, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24733785, Acc: 0.90561821, F1: 0.94661446 Bal: 0.8978 - Val Loss: 0.25913182, Accuracy: 0.9040, F1: 0.9456 Bal: 0.8902\n","Epoch 787:      TX: Train Loss: 0.0376, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1947, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24730928, Acc: 0.90559281, F1: 0.94659910 Bal: 0.8978 - Val Loss: 0.25911564, Accuracy: 0.9040, F1: 0.9456 Bal: 0.8902\n","Epoch 788:      TX: Train Loss: 0.0376, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24728131, Acc: 0.90559281, F1: 0.94659910 Bal: 0.8978 - Val Loss: 0.25909790, Accuracy: 0.9040, F1: 0.9456 Bal: 0.8901\n","Epoch 789:      TX: Train Loss: 0.0375, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9315\n","           WALLETS: Train Loss: 0.24725281, Acc: 0.90565449, F1: 0.94663585 Bal: 0.8978 - Val Loss: 0.25907981, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 790:      TX: Train Loss: 0.0375, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24722441, Acc: 0.90566537, F1: 0.94664256 Bal: 0.8978 - Val Loss: 0.25905725, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 791:      TX: Train Loss: 0.0375, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24719593, Acc: 0.90561458, F1: 0.94661207 Bal: 0.8978 - Val Loss: 0.25903177, Accuracy: 0.9040, F1: 0.9457 Bal: 0.8902\n","Epoch 792:      TX: Train Loss: 0.0375, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24716766, Acc: 0.90561095, F1: 0.94660991 Bal: 0.8978 - Val Loss: 0.25901490, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 793:      TX: Train Loss: 0.0375, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24713916, Acc: 0.90570892, F1: 0.94666872 Bal: 0.8978 - Val Loss: 0.25900298, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 794:      TX: Train Loss: 0.0375, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1948, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24711099, Acc: 0.90570529, F1: 0.94666656 Bal: 0.8978 - Val Loss: 0.25898057, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 795:      TX: Train Loss: 0.0374, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24708278, Acc: 0.90566175, F1: 0.94664018 Bal: 0.8978 - Val Loss: 0.25895333, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 796:      TX: Train Loss: 0.0374, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9314\n","           WALLETS: Train Loss: 0.24705479, Acc: 0.90569077, F1: 0.94665769 Bal: 0.8978 - Val Loss: 0.25893834, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 797:      TX: Train Loss: 0.0374, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24702655, Acc: 0.90576334, F1: 0.94670114 Bal: 0.8978 - Val Loss: 0.25892428, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8903\n","Epoch 798:      TX: Train Loss: 0.0374, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1950, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24699801, Acc: 0.90571617, F1: 0.94667217 Bal: 0.8979 - Val Loss: 0.25889552, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8902\n","Epoch 799:      TX: Train Loss: 0.0374, Acc: 0.9893, F1: 0.9940 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24697007, Acc: 0.90571617, F1: 0.94667217 Bal: 0.8979 - Val Loss: 0.25887102, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8902\n","Epoch 800:      TX: Train Loss: 0.0374, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1950, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24694212, Acc: 0.90579963, F1: 0.94672188 Bal: 0.8979 - Val Loss: 0.25885677, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8901\n","Epoch 801:      TX: Train Loss: 0.0374, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1950, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24691376, Acc: 0.90575971, F1: 0.94669767 Bal: 0.8980 - Val Loss: 0.25883421, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8901\n","Epoch 802:      TX: Train Loss: 0.0373, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1949, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24688537, Acc: 0.90571617, F1: 0.94667173 Bal: 0.8979 - Val Loss: 0.25880858, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8902\n","Epoch 803:      TX: Train Loss: 0.0373, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1950, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24685758, Acc: 0.90578511, F1: 0.94671302 Bal: 0.8980 - Val Loss: 0.25879356, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8899\n","Epoch 804:      TX: Train Loss: 0.0373, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1951, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24682973, Acc: 0.90582502, F1: 0.94673658 Bal: 0.8980 - Val Loss: 0.25877872, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 805:      TX: Train Loss: 0.0373, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1951, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24680161, Acc: 0.90575608, F1: 0.94669551 Bal: 0.8980 - Val Loss: 0.25875530, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 806:      TX: Train Loss: 0.0373, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1950, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24677351, Acc: 0.90577786, F1: 0.94670870 Bal: 0.8980 - Val Loss: 0.25873727, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 807:      TX: Train Loss: 0.0373, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1951, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24674544, Acc: 0.90581414, F1: 0.94673009 Bal: 0.8980 - Val Loss: 0.25871909, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 808:      TX: Train Loss: 0.0372, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1951, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24671724, Acc: 0.90577060, F1: 0.94670350 Bal: 0.8980 - Val Loss: 0.25869304, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8897\n","Epoch 809:      TX: Train Loss: 0.0372, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1951, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24668919, Acc: 0.90575971, F1: 0.94669679 Bal: 0.8980 - Val Loss: 0.25867096, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 810:      TX: Train Loss: 0.0372, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1952, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24666148, Acc: 0.90580688, F1: 0.94672489 Bal: 0.8981 - Val Loss: 0.25865635, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 811:      TX: Train Loss: 0.0372, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1952, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24663354, Acc: 0.90580325, F1: 0.94672273 Bal: 0.8981 - Val Loss: 0.25863612, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 812:      TX: Train Loss: 0.0372, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1951, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24660568, Acc: 0.90573794, F1: 0.94668382 Bal: 0.8980 - Val Loss: 0.25861418, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 813:      TX: Train Loss: 0.0372, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1952, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24657781, Acc: 0.90583591, F1: 0.94674240 Bal: 0.8981 - Val Loss: 0.25860244, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8897\n","Epoch 814:      TX: Train Loss: 0.0372, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1952, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24655065, Acc: 0.90589396, F1: 0.94677655 Bal: 0.8981 - Val Loss: 0.25858799, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8898\n","Epoch 815:      TX: Train Loss: 0.0371, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1952, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24652264, Acc: 0.90580688, F1: 0.94672402 Bal: 0.8982 - Val Loss: 0.25856379, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8897\n","Epoch 816:      TX: Train Loss: 0.0371, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1952, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24649450, Acc: 0.90583228, F1: 0.94673915 Bal: 0.8982 - Val Loss: 0.25854379, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8897\n","Epoch 817:      TX: Train Loss: 0.0371, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1953, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24646622, Acc: 0.90593750, F1: 0.94680183 Bal: 0.8982 - Val Loss: 0.25852743, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8898\n","Epoch 818:      TX: Train Loss: 0.0371, Acc: 0.9894, F1: 0.9941 Bal: 0.9937 - Val Loss: 0.1952, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24643850, Acc: 0.90590485, F1: 0.94678216 Bal: 0.8982 - Val Loss: 0.25850600, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8897\n","Epoch 819:      TX: Train Loss: 0.0371, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1952, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24641100, Acc: 0.90589034, F1: 0.94677373 Bal: 0.8982 - Val Loss: 0.25848871, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8898\n","Epoch 820:      TX: Train Loss: 0.0371, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1953, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24638349, Acc: 0.90593388, F1: 0.94679967 Bal: 0.8982 - Val Loss: 0.25847760, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8900\n","Epoch 821:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1953, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24635555, Acc: 0.90591573, F1: 0.94678886 Bal: 0.8982 - Val Loss: 0.25845942, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8899\n","Epoch 822:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24632771, Acc: 0.90594113, F1: 0.94680356 Bal: 0.8983 - Val Loss: 0.25844282, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 823:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1953, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24630031, Acc: 0.90594476, F1: 0.94680550 Bal: 0.8983 - Val Loss: 0.25842765, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 824:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24627289, Acc: 0.90596653, F1: 0.94681868 Bal: 0.8983 - Val Loss: 0.25841299, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 825:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24624519, Acc: 0.90598105, F1: 0.94682733 Bal: 0.8983 - Val Loss: 0.25839931, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8901\n","Epoch 826:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9682, F1: 0.9822 Bal: 0.9323\n","           WALLETS: Train Loss: 0.24621782, Acc: 0.90601007, F1: 0.94684418 Bal: 0.8984 - Val Loss: 0.25837958, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8901\n","Epoch 827:      TX: Train Loss: 0.0370, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24619046, Acc: 0.90602096, F1: 0.94685023 Bal: 0.8984 - Val Loss: 0.25835857, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8901\n","Epoch 828:      TX: Train Loss: 0.0369, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24616286, Acc: 0.90601370, F1: 0.94684612 Bal: 0.8984 - Val Loss: 0.25834182, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8901\n","Epoch 829:      TX: Train Loss: 0.0369, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24613515, Acc: 0.90602821, F1: 0.94685433 Bal: 0.8984 - Val Loss: 0.25832537, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8901\n","Epoch 830:      TX: Train Loss: 0.0369, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24610707, Acc: 0.90604273, F1: 0.94686319 Bal: 0.8984 - Val Loss: 0.25831208, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8900\n","Epoch 831:      TX: Train Loss: 0.0369, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24607928, Acc: 0.90610078, F1: 0.94689777 Bal: 0.8984 - Val Loss: 0.25829864, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8901\n","Epoch 832:      TX: Train Loss: 0.0369, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24605168, Acc: 0.90608627, F1: 0.94688934 Bal: 0.8984 - Val Loss: 0.25827774, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 833:      TX: Train Loss: 0.0369, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24602427, Acc: 0.90603547, F1: 0.94685931 Bal: 0.8984 - Val Loss: 0.25825781, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 834:      TX: Train Loss: 0.0369, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24599648, Acc: 0.90607901, F1: 0.94688546 Bal: 0.8984 - Val Loss: 0.25824338, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 835:      TX: Train Loss: 0.0368, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1956, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24596910, Acc: 0.90614069, F1: 0.94692219 Bal: 0.8984 - Val Loss: 0.25823283, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8900\n","Epoch 836:      TX: Train Loss: 0.0368, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1954, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24594136, Acc: 0.90611892, F1: 0.94690901 Bal: 0.8984 - Val Loss: 0.25821051, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8899\n","Epoch 837:      TX: Train Loss: 0.0368, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24591389, Acc: 0.90610441, F1: 0.94690037 Bal: 0.8984 - Val Loss: 0.25818920, Accuracy: 0.9042, F1: 0.9457 Bal: 0.8899\n","Epoch 838:      TX: Train Loss: 0.0368, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24588653, Acc: 0.90612981, F1: 0.94691527 Bal: 0.8984 - Val Loss: 0.25817117, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8900\n","Epoch 839:      TX: Train Loss: 0.0368, Acc: 0.9895, F1: 0.9941 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24585916, Acc: 0.90616246, F1: 0.94693494 Bal: 0.8984 - Val Loss: 0.25815210, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8900\n","Epoch 840:      TX: Train Loss: 0.0368, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1957, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24583142, Acc: 0.90615158, F1: 0.94692802 Bal: 0.8985 - Val Loss: 0.25813437, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8900\n","Epoch 841:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1956, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24580415, Acc: 0.90617698, F1: 0.94694336 Bal: 0.8985 - Val Loss: 0.25811493, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8900\n","Epoch 842:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1955, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24577706, Acc: 0.90623503, F1: 0.94697815 Bal: 0.8985 - Val Loss: 0.25809714, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8900\n","Epoch 843:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9938 - Val Loss: 0.1957, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24574904, Acc: 0.90624229, F1: 0.94698247 Bal: 0.8985 - Val Loss: 0.25807911, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8900\n","Epoch 844:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24572174, Acc: 0.90619512, F1: 0.94695460 Bal: 0.8984 - Val Loss: 0.25805861, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8900\n","Epoch 845:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1956, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24569447, Acc: 0.90622052, F1: 0.94696951 Bal: 0.8985 - Val Loss: 0.25804150, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8901\n","Epoch 846:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24566683, Acc: 0.90625680, F1: 0.94699090 Bal: 0.8985 - Val Loss: 0.25802481, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8899\n","Epoch 847:      TX: Train Loss: 0.0367, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24563946, Acc: 0.90625680, F1: 0.94699090 Bal: 0.8985 - Val Loss: 0.25800177, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8899\n","Epoch 848:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24561222, Acc: 0.90625680, F1: 0.94699068 Bal: 0.8985 - Val Loss: 0.25798014, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8899\n","Epoch 849:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24558462, Acc: 0.90632937, F1: 0.94703367 Bal: 0.8986 - Val Loss: 0.25796443, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8899\n","Epoch 850:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24555735, Acc: 0.90634026, F1: 0.94704037 Bal: 0.8986 - Val Loss: 0.25794512, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8899\n","Epoch 851:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24552950, Acc: 0.90630760, F1: 0.94702071 Bal: 0.8986 - Val Loss: 0.25792250, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8899\n","Epoch 852:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24550191, Acc: 0.90637654, F1: 0.94706154 Bal: 0.8986 - Val Loss: 0.25790730, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 853:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24547407, Acc: 0.90639468, F1: 0.94707234 Bal: 0.8987 - Val Loss: 0.25788686, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 854:      TX: Train Loss: 0.0366, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24544632, Acc: 0.90633663, F1: 0.94703778 Bal: 0.8986 - Val Loss: 0.25786102, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8898\n","Epoch 855:      TX: Train Loss: 0.0365, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24541895, Acc: 0.90636566, F1: 0.94705506 Bal: 0.8986 - Val Loss: 0.25784504, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 856:      TX: Train Loss: 0.0365, Acc: 0.9896, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24539107, Acc: 0.90641282, F1: 0.94708292 Bal: 0.8987 - Val Loss: 0.25782901, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 857:      TX: Train Loss: 0.0365, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24536356, Acc: 0.90639831, F1: 0.94707428 Bal: 0.8987 - Val Loss: 0.25780016, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 858:      TX: Train Loss: 0.0365, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24533619, Acc: 0.90638380, F1: 0.94706564 Bal: 0.8987 - Val Loss: 0.25777540, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 859:      TX: Train Loss: 0.0365, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24530913, Acc: 0.90640557, F1: 0.94707860 Bal: 0.8987 - Val Loss: 0.25776148, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8897\n","Epoch 860:      TX: Train Loss: 0.0365, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24528204, Acc: 0.90639468, F1: 0.94707212 Bal: 0.8987 - Val Loss: 0.25774187, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8897\n","Epoch 861:      TX: Train Loss: 0.0365, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24525441, Acc: 0.90644911, F1: 0.94710453 Bal: 0.8987 - Val Loss: 0.25772578, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8898\n","Epoch 862:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24522671, Acc: 0.90643459, F1: 0.94709588 Bal: 0.8987 - Val Loss: 0.25770107, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8898\n","Epoch 863:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1957, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24519949, Acc: 0.90640920, F1: 0.94708033 Bal: 0.8987 - Val Loss: 0.25767595, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8898\n","Epoch 864:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24517205, Acc: 0.90643822, F1: 0.94709761 Bal: 0.8987 - Val Loss: 0.25765863, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8897\n","Epoch 865:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24514532, Acc: 0.90650716, F1: 0.94713822 Bal: 0.8988 - Val Loss: 0.25764450, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8898\n","Epoch 866:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24511814, Acc: 0.90646362, F1: 0.94711295 Bal: 0.8987 - Val Loss: 0.25762111, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8898\n","Epoch 867:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24509123, Acc: 0.90645636, F1: 0.94710863 Bal: 0.8987 - Val Loss: 0.25759977, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8898\n","Epoch 868:      TX: Train Loss: 0.0364, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24506414, Acc: 0.90648902, F1: 0.94712829 Bal: 0.8987 - Val Loss: 0.25758702, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8898\n","Epoch 869:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1959, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24503706, Acc: 0.90652530, F1: 0.94714967 Bal: 0.8988 - Val Loss: 0.25757211, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8898\n","Epoch 870:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1958, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24501018, Acc: 0.90651805, F1: 0.94714578 Bal: 0.8987 - Val Loss: 0.25755429, Accuracy: 0.9044, F1: 0.9459 Bal: 0.8896\n","Epoch 871:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1959, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24498275, Acc: 0.90651805, F1: 0.94714513 Bal: 0.8988 - Val Loss: 0.25753540, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 872:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1959, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24495523, Acc: 0.90652530, F1: 0.94715010 Bal: 0.8987 - Val Loss: 0.25751707, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 873:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1959, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24492842, Acc: 0.90655433, F1: 0.94716716 Bal: 0.8988 - Val Loss: 0.25749880, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8897\n","Epoch 874:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1960, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24490136, Acc: 0.90656522, F1: 0.94717343 Bal: 0.8988 - Val Loss: 0.25747854, Accuracy: 0.9045, F1: 0.9460 Bal: 0.8897\n","Epoch 875:      TX: Train Loss: 0.0363, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1959, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24487433, Acc: 0.90658336, F1: 0.94718401 Bal: 0.8988 - Val Loss: 0.25746259, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 876:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1960, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24484681, Acc: 0.90658336, F1: 0.94718401 Bal: 0.8988 - Val Loss: 0.25745058, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 877:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24481985, Acc: 0.90658336, F1: 0.94718401 Bal: 0.8988 - Val Loss: 0.25743219, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 878:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1960, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24479263, Acc: 0.90659424, F1: 0.94719005 Bal: 0.8989 - Val Loss: 0.25740984, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 879:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24476506, Acc: 0.90661239, F1: 0.94720064 Bal: 0.8989 - Val Loss: 0.25738949, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 880:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1960, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9337\n","           WALLETS: Train Loss: 0.24473773, Acc: 0.90660150, F1: 0.94719394 Bal: 0.8989 - Val Loss: 0.25737256, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8895\n","Epoch 881:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1959, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24471056, Acc: 0.90667407, F1: 0.94723713 Bal: 0.8990 - Val Loss: 0.25736186, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8895\n","Epoch 882:      TX: Train Loss: 0.0362, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9336\n","           WALLETS: Train Loss: 0.24468356, Acc: 0.90663778, F1: 0.94721619 Bal: 0.8989 - Val Loss: 0.25734413, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8897\n","Epoch 883:      TX: Train Loss: 0.0361, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24465604, Acc: 0.90660876, F1: 0.94719891 Bal: 0.8989 - Val Loss: 0.25732064, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8898\n","Epoch 884:      TX: Train Loss: 0.0361, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24462876, Acc: 0.90664141, F1: 0.94721835 Bal: 0.8989 - Val Loss: 0.25730479, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8898\n","Epoch 885:      TX: Train Loss: 0.0361, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24460129, Acc: 0.90669221, F1: 0.94724880 Bal: 0.8989 - Val Loss: 0.25729224, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8897\n","Epoch 886:      TX: Train Loss: 0.0361, Acc: 0.9897, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24457394, Acc: 0.90669947, F1: 0.94725333 Bal: 0.8989 - Val Loss: 0.25727555, Accuracy: 0.9047, F1: 0.9460 Bal: 0.8897\n","Epoch 887:      TX: Train Loss: 0.0361, Acc: 0.9897, F1: 0.9942 Bal: 0.9940 - Val Loss: 0.1961, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24454711, Acc: 0.90668495, F1: 0.94724426 Bal: 0.8989 - Val Loss: 0.25725183, Accuracy: 0.9047, F1: 0.9460 Bal: 0.8899\n","Epoch 888:      TX: Train Loss: 0.0361, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24451956, Acc: 0.90667770, F1: 0.94724038 Bal: 0.8988 - Val Loss: 0.25723514, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8897\n","Epoch 889:      TX: Train Loss: 0.0361, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1961, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24449232, Acc: 0.90671761, F1: 0.94726413 Bal: 0.8989 - Val Loss: 0.25722355, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8897\n","Epoch 890:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1961, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24446519, Acc: 0.90683735, F1: 0.94733517 Bal: 0.8990 - Val Loss: 0.25720525, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8900\n","Epoch 891:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1961, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24443783, Acc: 0.90682283, F1: 0.94732610 Bal: 0.8990 - Val Loss: 0.25718117, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8901\n","Epoch 892:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24441017, Acc: 0.90680106, F1: 0.94731315 Bal: 0.8990 - Val Loss: 0.25716057, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8901\n","Epoch 893:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9335\n","           WALLETS: Train Loss: 0.24438302, Acc: 0.90685549, F1: 0.94734553 Bal: 0.8990 - Val Loss: 0.25715178, Accuracy: 0.9049, F1: 0.9462 Bal: 0.8902\n","Epoch 894:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24435557, Acc: 0.90685912, F1: 0.94734834 Bal: 0.8989 - Val Loss: 0.25713679, Accuracy: 0.9049, F1: 0.9462 Bal: 0.8900\n","Epoch 895:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24432857, Acc: 0.90682646, F1: 0.94732934 Bal: 0.8989 - Val Loss: 0.25711554, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8900\n","Epoch 896:      TX: Train Loss: 0.0360, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24430123, Acc: 0.90688089, F1: 0.94736151 Bal: 0.8989 - Val Loss: 0.25709885, Accuracy: 0.9049, F1: 0.9462 Bal: 0.8900\n","Epoch 897:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24427363, Acc: 0.90686275, F1: 0.94735093 Bal: 0.8989 - Val Loss: 0.25707731, Accuracy: 0.9049, F1: 0.9462 Bal: 0.8900\n","Epoch 898:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24424605, Acc: 0.90686275, F1: 0.94735072 Bal: 0.8989 - Val Loss: 0.25705963, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8898\n","Epoch 899:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9334\n","           WALLETS: Train Loss: 0.24421875, Acc: 0.90689903, F1: 0.94737274 Bal: 0.8989 - Val Loss: 0.25704744, Accuracy: 0.9049, F1: 0.9462 Bal: 0.8897\n","Epoch 900:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24419126, Acc: 0.90689903, F1: 0.94737252 Bal: 0.8989 - Val Loss: 0.25702816, Accuracy: 0.9051, F1: 0.9463 Bal: 0.8901\n","Epoch 901:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24416354, Acc: 0.90691354, F1: 0.94738051 Bal: 0.8990 - Val Loss: 0.25700793, Accuracy: 0.9051, F1: 0.9463 Bal: 0.8901\n","Epoch 902:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24413590, Acc: 0.90696434, F1: 0.94741095 Bal: 0.8990 - Val Loss: 0.25699329, Accuracy: 0.9050, F1: 0.9463 Bal: 0.8901\n","Epoch 903:      TX: Train Loss: 0.0359, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24410835, Acc: 0.90700788, F1: 0.94743664 Bal: 0.8990 - Val Loss: 0.25697392, Accuracy: 0.9051, F1: 0.9463 Bal: 0.8899\n","Epoch 904:      TX: Train Loss: 0.0358, Acc: 0.9898, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24408115, Acc: 0.90694983, F1: 0.94740167 Bal: 0.8991 - Val Loss: 0.25694749, Accuracy: 0.9050, F1: 0.9463 Bal: 0.8899\n","Epoch 905:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24405375, Acc: 0.90696797, F1: 0.94741268 Bal: 0.8990 - Val Loss: 0.25693810, Accuracy: 0.9051, F1: 0.9463 Bal: 0.8899\n","Epoch 906:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24402636, Acc: 0.90702239, F1: 0.94744571 Bal: 0.8990 - Val Loss: 0.25692931, Accuracy: 0.9050, F1: 0.9463 Bal: 0.8899\n","Epoch 907:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24399863, Acc: 0.90697523, F1: 0.94741678 Bal: 0.8991 - Val Loss: 0.25690621, Accuracy: 0.9050, F1: 0.9462 Bal: 0.8899\n","Epoch 908:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24397083, Acc: 0.90703691, F1: 0.94745370 Bal: 0.8991 - Val Loss: 0.25689113, Accuracy: 0.9050, F1: 0.9463 Bal: 0.8899\n","Epoch 909:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1962, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24394329, Acc: 0.90705505, F1: 0.94746427 Bal: 0.8991 - Val Loss: 0.25687653, Accuracy: 0.9051, F1: 0.9463 Bal: 0.8901\n","Epoch 910:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9943 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24391557, Acc: 0.90706231, F1: 0.94746859 Bal: 0.8991 - Val Loss: 0.25686362, Accuracy: 0.9052, F1: 0.9464 Bal: 0.8902\n","Epoch 911:      TX: Train Loss: 0.0358, Acc: 0.9899, F1: 0.9944 Bal: 0.9941 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24388798, Acc: 0.90709133, F1: 0.94748586 Bal: 0.8991 - Val Loss: 0.25685102, Accuracy: 0.9052, F1: 0.9464 Bal: 0.8902\n","Epoch 912:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24386002, Acc: 0.90712036, F1: 0.94750291 Bal: 0.8992 - Val Loss: 0.25683179, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8902\n","Epoch 913:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24383241, Acc: 0.90708045, F1: 0.94747895 Bal: 0.8992 - Val Loss: 0.25680602, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8902\n","Epoch 914:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24380510, Acc: 0.90712036, F1: 0.94750270 Bal: 0.8992 - Val Loss: 0.25679210, Accuracy: 0.9052, F1: 0.9464 Bal: 0.8900\n","Epoch 915:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24377711, Acc: 0.90715665, F1: 0.94752471 Bal: 0.8992 - Val Loss: 0.25678200, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8902\n","Epoch 916:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24374923, Acc: 0.90712036, F1: 0.94750313 Bal: 0.8992 - Val Loss: 0.25676358, Accuracy: 0.9052, F1: 0.9464 Bal: 0.8899\n","Epoch 917:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24372172, Acc: 0.90715302, F1: 0.94752234 Bal: 0.8992 - Val Loss: 0.25675470, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8901\n","Epoch 918:      TX: Train Loss: 0.0357, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1962, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24369392, Acc: 0.90716390, F1: 0.94752881 Bal: 0.8992 - Val Loss: 0.25673717, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8901\n","Epoch 919:      TX: Train Loss: 0.0356, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24366622, Acc: 0.90716390, F1: 0.94752903 Bal: 0.8992 - Val Loss: 0.25671870, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8901\n","Epoch 920:      TX: Train Loss: 0.0356, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24363813, Acc: 0.90719656, F1: 0.94754867 Bal: 0.8992 - Val Loss: 0.25671107, Accuracy: 0.9054, F1: 0.9465 Bal: 0.8899\n","Epoch 921:      TX: Train Loss: 0.0356, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24361046, Acc: 0.90721107, F1: 0.94755730 Bal: 0.8992 - Val Loss: 0.25670031, Accuracy: 0.9054, F1: 0.9464 Bal: 0.8901\n","Epoch 922:      TX: Train Loss: 0.0356, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24358295, Acc: 0.90718567, F1: 0.94754176 Bal: 0.8992 - Val Loss: 0.25667855, Accuracy: 0.9053, F1: 0.9464 Bal: 0.8902\n","Epoch 923:      TX: Train Loss: 0.0356, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24355540, Acc: 0.90721833, F1: 0.94756183 Bal: 0.8992 - Val Loss: 0.25666258, Accuracy: 0.9054, F1: 0.9465 Bal: 0.8901\n","Epoch 924:      TX: Train Loss: 0.0356, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24352778, Acc: 0.90730178, F1: 0.94761147 Bal: 0.8992 - Val Loss: 0.25664961, Accuracy: 0.9054, F1: 0.9465 Bal: 0.8901\n","Epoch 925:      TX: Train Loss: 0.0356, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24350041, Acc: 0.90728727, F1: 0.94760262 Bal: 0.8992 - Val Loss: 0.25663051, Accuracy: 0.9055, F1: 0.9465 Bal: 0.8903\n","Epoch 926:      TX: Train Loss: 0.0355, Acc: 0.9899, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24347353, Acc: 0.90728001, F1: 0.94759831 Bal: 0.8992 - Val Loss: 0.25661263, Accuracy: 0.9054, F1: 0.9465 Bal: 0.8903\n","Epoch 927:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24344583, Acc: 0.90730178, F1: 0.94761147 Bal: 0.8992 - Val Loss: 0.25659996, Accuracy: 0.9054, F1: 0.9465 Bal: 0.8901\n","Epoch 928:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24341808, Acc: 0.90730178, F1: 0.94761169 Bal: 0.8992 - Val Loss: 0.25658679, Accuracy: 0.9055, F1: 0.9465 Bal: 0.8902\n","Epoch 929:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24339081, Acc: 0.90730541, F1: 0.94761384 Bal: 0.8992 - Val Loss: 0.25657186, Accuracy: 0.9055, F1: 0.9465 Bal: 0.8902\n","Epoch 930:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24336316, Acc: 0.90732718, F1: 0.94762679 Bal: 0.8992 - Val Loss: 0.25655586, Accuracy: 0.9055, F1: 0.9465 Bal: 0.8902\n","Epoch 931:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24333572, Acc: 0.90731629, F1: 0.94762053 Bal: 0.8992 - Val Loss: 0.25653431, Accuracy: 0.9055, F1: 0.9465 Bal: 0.8902\n","Epoch 932:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24330854, Acc: 0.90734895, F1: 0.94763974 Bal: 0.8992 - Val Loss: 0.25652146, Accuracy: 0.9055, F1: 0.9466 Bal: 0.8902\n","Epoch 933:      TX: Train Loss: 0.0355, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24328154, Acc: 0.90735984, F1: 0.94764664 Bal: 0.8992 - Val Loss: 0.25651097, Accuracy: 0.9057, F1: 0.9467 Bal: 0.8903\n","Epoch 934:      TX: Train Loss: 0.0354, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24325398, Acc: 0.90734895, F1: 0.94764017 Bal: 0.8992 - Val Loss: 0.25649074, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8903\n","Epoch 935:      TX: Train Loss: 0.0354, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24322712, Acc: 0.90737072, F1: 0.94765311 Bal: 0.8992 - Val Loss: 0.25647295, Accuracy: 0.9057, F1: 0.9466 Bal: 0.8903\n","Epoch 936:      TX: Train Loss: 0.0354, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24319990, Acc: 0.90742152, F1: 0.94768311 Bal: 0.8992 - Val Loss: 0.25646093, Accuracy: 0.9057, F1: 0.9466 Bal: 0.8903\n","Epoch 937:      TX: Train Loss: 0.0354, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24317230, Acc: 0.90737798, F1: 0.94765679 Bal: 0.8992 - Val Loss: 0.25643736, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8902\n","Epoch 938:      TX: Train Loss: 0.0354, Acc: 0.9900, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1963, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24314471, Acc: 0.90738886, F1: 0.94766412 Bal: 0.8992 - Val Loss: 0.25642145, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8903\n","Epoch 939:      TX: Train Loss: 0.0354, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24311733, Acc: 0.90742152, F1: 0.94768332 Bal: 0.8992 - Val Loss: 0.25640488, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8902\n","Epoch 940:      TX: Train Loss: 0.0354, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24308994, Acc: 0.90740700, F1: 0.94767469 Bal: 0.8992 - Val Loss: 0.25639004, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8902\n","Epoch 941:      TX: Train Loss: 0.0354, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24306276, Acc: 0.90743240, F1: 0.94768980 Bal: 0.8992 - Val Loss: 0.25637272, Accuracy: 0.9057, F1: 0.9466 Bal: 0.8904\n","Epoch 942:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24303585, Acc: 0.90742515, F1: 0.94768570 Bal: 0.8992 - Val Loss: 0.25635135, Accuracy: 0.9057, F1: 0.9467 Bal: 0.8905\n","Epoch 943:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1964, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24300867, Acc: 0.90748320, F1: 0.94772022 Bal: 0.8992 - Val Loss: 0.25633785, Accuracy: 0.9058, F1: 0.9467 Bal: 0.8905\n","Epoch 944:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24298111, Acc: 0.90743966, F1: 0.94769411 Bal: 0.8992 - Val Loss: 0.25631633, Accuracy: 0.9057, F1: 0.9467 Bal: 0.8905\n","Epoch 945:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1966, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24295399, Acc: 0.90746869, F1: 0.94771159 Bal: 0.8992 - Val Loss: 0.25630245, Accuracy: 0.9058, F1: 0.9467 Bal: 0.8905\n","Epoch 946:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24292715, Acc: 0.90750134, F1: 0.94773101 Bal: 0.8992 - Val Loss: 0.25628749, Accuracy: 0.9057, F1: 0.9467 Bal: 0.8903\n","Epoch 947:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24289998, Acc: 0.90748683, F1: 0.94772216 Bal: 0.8992 - Val Loss: 0.25626415, Accuracy: 0.9058, F1: 0.9467 Bal: 0.8905\n","Epoch 948:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24287327, Acc: 0.90750497, F1: 0.94773359 Bal: 0.8992 - Val Loss: 0.25625205, Accuracy: 0.9058, F1: 0.9467 Bal: 0.8905\n","Epoch 949:      TX: Train Loss: 0.0353, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1966, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24284622, Acc: 0.90751223, F1: 0.94773791 Bal: 0.8992 - Val Loss: 0.25624081, Accuracy: 0.9059, F1: 0.9468 Bal: 0.8905\n","Epoch 950:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9944 Bal: 0.9943 - Val Loss: 0.1965, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24281861, Acc: 0.90751223, F1: 0.94773833 Bal: 0.8991 - Val Loss: 0.25622469, Accuracy: 0.9058, F1: 0.9467 Bal: 0.8905\n","Epoch 951:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1966, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24279237, Acc: 0.90757028, F1: 0.94777285 Bal: 0.8992 - Val Loss: 0.25621191, Accuracy: 0.9057, F1: 0.9467 Bal: 0.8903\n","Epoch 952:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24276526, Acc: 0.90754488, F1: 0.94775775 Bal: 0.8992 - Val Loss: 0.25618431, Accuracy: 0.9058, F1: 0.9467 Bal: 0.8907\n","Epoch 953:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1965, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24273866, Acc: 0.90755940, F1: 0.94776638 Bal: 0.8992 - Val Loss: 0.25616419, Accuracy: 0.9059, F1: 0.9468 Bal: 0.8907\n","Epoch 954:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24271168, Acc: 0.90765011, F1: 0.94781988 Bal: 0.8993 - Val Loss: 0.25615364, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8908\n","Epoch 955:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1966, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24268459, Acc: 0.90767913, F1: 0.94783671 Bal: 0.8993 - Val Loss: 0.25613269, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8907\n","Epoch 956:      TX: Train Loss: 0.0352, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1965, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24265790, Acc: 0.90764648, F1: 0.94781751 Bal: 0.8993 - Val Loss: 0.25610229, Accuracy: 0.9059, F1: 0.9468 Bal: 0.8907\n","Epoch 957:      TX: Train Loss: 0.0351, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24263155, Acc: 0.90766825, F1: 0.94783067 Bal: 0.8993 - Val Loss: 0.25608522, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8908\n","Epoch 958:      TX: Train Loss: 0.0351, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9324\n","           WALLETS: Train Loss: 0.24260505, Acc: 0.90767188, F1: 0.94783218 Bal: 0.8993 - Val Loss: 0.25606763, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8908\n","Epoch 959:      TX: Train Loss: 0.0351, Acc: 0.9901, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1966, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24257825, Acc: 0.90768639, F1: 0.94784017 Bal: 0.8994 - Val Loss: 0.25605369, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8907\n","Epoch 960:      TX: Train Loss: 0.0351, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24255174, Acc: 0.90773719, F1: 0.94787037 Bal: 0.8994 - Val Loss: 0.25604475, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8908\n","Epoch 961:      TX: Train Loss: 0.0351, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1966, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24252528, Acc: 0.90767913, F1: 0.94783586 Bal: 0.8994 - Val Loss: 0.25601834, Accuracy: 0.9060, F1: 0.9469 Bal: 0.8908\n","Epoch 962:      TX: Train Loss: 0.0351, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24249843, Acc: 0.90776259, F1: 0.94788525 Bal: 0.8995 - Val Loss: 0.25600120, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8908\n","Epoch 963:      TX: Train Loss: 0.0351, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24247156, Acc: 0.90779524, F1: 0.94790509 Bal: 0.8995 - Val Loss: 0.25599217, Accuracy: 0.9062, F1: 0.9469 Bal: 0.8909\n","Epoch 964:      TX: Train Loss: 0.0351, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24244511, Acc: 0.90771905, F1: 0.94785958 Bal: 0.8994 - Val Loss: 0.25596595, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8906\n","Epoch 965:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24241798, Acc: 0.90777710, F1: 0.94789388 Bal: 0.8995 - Val Loss: 0.25594759, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8906\n","Epoch 966:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24239105, Acc: 0.90783878, F1: 0.94793076 Bal: 0.8995 - Val Loss: 0.25592622, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8907\n","Epoch 967:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24236473, Acc: 0.90776259, F1: 0.94788525 Bal: 0.8995 - Val Loss: 0.25589687, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8906\n","Epoch 968:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24233782, Acc: 0.90781338, F1: 0.94791545 Bal: 0.8995 - Val Loss: 0.25589117, Accuracy: 0.9060, F1: 0.9469 Bal: 0.8906\n","Epoch 969:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1967, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24231097, Acc: 0.90787870, F1: 0.94795448 Bal: 0.8995 - Val Loss: 0.25588790, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8907\n","Epoch 970:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24228430, Acc: 0.90783515, F1: 0.94792796 Bal: 0.8996 - Val Loss: 0.25586388, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8909\n","Epoch 971:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24225715, Acc: 0.90790047, F1: 0.94796678 Bal: 0.8996 - Val Loss: 0.25585774, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8910\n","Epoch 972:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24223040, Acc: 0.90792224, F1: 0.94797994 Bal: 0.8996 - Val Loss: 0.25583982, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8910\n","Epoch 973:      TX: Train Loss: 0.0350, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24220361, Acc: 0.90788958, F1: 0.94795967 Bal: 0.8997 - Val Loss: 0.25581411, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8909\n","Epoch 974:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24217667, Acc: 0.90796941, F1: 0.94800840 Bal: 0.8996 - Val Loss: 0.25581011, Accuracy: 0.9062, F1: 0.9469 Bal: 0.8910\n","Epoch 975:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24214998, Acc: 0.90794038, F1: 0.94799029 Bal: 0.8996 - Val Loss: 0.25578535, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8911\n","Epoch 976:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24212299, Acc: 0.90797303, F1: 0.94800949 Bal: 0.8997 - Val Loss: 0.25576666, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8911\n","Epoch 977:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9325\n","           WALLETS: Train Loss: 0.24209593, Acc: 0.90804923, F1: 0.94805477 Bal: 0.8997 - Val Loss: 0.25576130, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8912\n","Epoch 978:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24206932, Acc: 0.90800206, F1: 0.94802652 Bal: 0.8997 - Val Loss: 0.25573578, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8912\n","Epoch 979:      TX: Train Loss: 0.0349, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24204229, Acc: 0.90804560, F1: 0.94805261 Bal: 0.8997 - Val Loss: 0.25572488, Accuracy: 0.9062, F1: 0.9470 Bal: 0.8912\n","Epoch 980:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24201569, Acc: 0.90807100, F1: 0.94806771 Bal: 0.8997 - Val Loss: 0.25571737, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8912\n","Epoch 981:      TX: Train Loss: 0.0349, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24198878, Acc: 0.90806737, F1: 0.94806491 Bal: 0.8998 - Val Loss: 0.25569957, Accuracy: 0.9062, F1: 0.9469 Bal: 0.8912\n","Epoch 982:      TX: Train Loss: 0.0348, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1968, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24196243, Acc: 0.90809640, F1: 0.94808195 Bal: 0.8998 - Val Loss: 0.25568578, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8912\n","Epoch 983:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24193531, Acc: 0.90807463, F1: 0.94806901 Bal: 0.8998 - Val Loss: 0.25566781, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8913\n","Epoch 984:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24190834, Acc: 0.90811454, F1: 0.94809273 Bal: 0.8998 - Val Loss: 0.25565654, Accuracy: 0.9064, F1: 0.9471 Bal: 0.8913\n","Epoch 985:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24188139, Acc: 0.90808551, F1: 0.94807548 Bal: 0.8998 - Val Loss: 0.25563487, Accuracy: 0.9064, F1: 0.9470 Bal: 0.8914\n","Epoch 986:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1968, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24185430, Acc: 0.90817622, F1: 0.94812917 Bal: 0.8999 - Val Loss: 0.25562492, Accuracy: 0.9064, F1: 0.9470 Bal: 0.8913\n","Epoch 987:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24182709, Acc: 0.90813631, F1: 0.94810418 Bal: 0.9000 - Val Loss: 0.25559869, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8914\n","Epoch 988:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1968, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24180007, Acc: 0.90815445, F1: 0.94811496 Bal: 0.9000 - Val Loss: 0.25558358, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8916\n","Epoch 989:      TX: Train Loss: 0.0348, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24177304, Acc: 0.90826331, F1: 0.94817964 Bal: 0.9001 - Val Loss: 0.25557792, Accuracy: 0.9064, F1: 0.9471 Bal: 0.8916\n","Epoch 990:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24174631, Acc: 0.90816534, F1: 0.94812143 Bal: 0.9000 - Val Loss: 0.25555512, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8916\n","Epoch 991:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1968, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24171944, Acc: 0.90825242, F1: 0.94817317 Bal: 0.9001 - Val Loss: 0.25554714, Accuracy: 0.9064, F1: 0.9471 Bal: 0.8916\n","Epoch 992:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24169303, Acc: 0.90824879, F1: 0.94817080 Bal: 0.9001 - Val Loss: 0.25553623, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8916\n","Epoch 993:      TX: Train Loss: 0.0347, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24166611, Acc: 0.90817985, F1: 0.94812984 Bal: 0.9000 - Val Loss: 0.25551686, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8915\n","Epoch 994:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9326\n","           WALLETS: Train Loss: 0.24163869, Acc: 0.90832862, F1: 0.94821865 Bal: 0.9001 - Val Loss: 0.25551596, Accuracy: 0.9065, F1: 0.9471 Bal: 0.8917\n","Epoch 995:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1970, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24161159, Acc: 0.90821614, F1: 0.94815118 Bal: 0.9001 - Val Loss: 0.25548255, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8916\n","Epoch 996:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1967, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24158394, Acc: 0.90827419, F1: 0.94818589 Bal: 0.9001 - Val Loss: 0.25547004, Accuracy: 0.9065, F1: 0.9471 Bal: 0.8917\n","Epoch 997:      TX: Train Loss: 0.0347, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1968, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24155688, Acc: 0.90833224, F1: 0.94822038 Bal: 0.9001 - Val Loss: 0.25545850, Accuracy: 0.9064, F1: 0.9471 Bal: 0.8916\n","Epoch 998:      TX: Train Loss: 0.0346, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1970, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24152975, Acc: 0.90826693, F1: 0.94818094 Bal: 0.9002 - Val Loss: 0.25543642, Accuracy: 0.9064, F1: 0.9471 Bal: 0.8916\n","Epoch 999:      TX: Train Loss: 0.0346, Acc: 0.9902, F1: 0.9945 Bal: 0.9944 - Val Loss: 0.1969, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24150255, Acc: 0.90831410, F1: 0.94820918 Bal: 0.9002 - Val Loss: 0.25542843, Accuracy: 0.9065, F1: 0.9471 Bal: 0.8917\n","Epoch 1000:      TX: Train Loss: 0.0346, Acc: 0.9903, F1: 0.9946 Bal: 0.9945 - Val Loss: 0.1969, Accuracy: 0.9691, F1: 0.9827 Bal: 0.9327\n","           WALLETS: Train Loss: 0.24147516, Acc: 0.90830322, F1: 0.94820250 Bal: 0.9002 - Val Loss: 0.25541538, Accuracy: 0.9064, F1: 0.9471 Bal: 0.8916\n","{'hidden_channels': 32, 'num_head': 3, 'num_layers': 2, 'num_epoch': 1000, 'patience': 50, 'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0, 'conv_type': 'Transformer', 'p': 5, 'factor': 0.5, 'eta_min': None, 'T_max': None, 'aggr': 'mean', 'lr_scheduler': 'ReduceLROnPlateau', 'optimizer': 'Adam', 'type_model': 'HeteroGNN', 'scaler': 'standard_l2', 'dim_reduction': 'pca', 'pca_threshold': 0.99, 'epoch': 1000, 'end': True}\n","Final_result for tx\n","{'hidden_channels': 32, 'num_head': 3, 'num_layers': 2, 'num_epoch': 1000, 'patience': 50, 'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0, 'conv_type': 'Transformer', 'p': 5, 'factor': 0.5, 'eta_min': None, 'T_max': None, 'aggr': 'mean', 'lr_scheduler': 'ReduceLROnPlateau', 'optimizer': 'Adam', 'type_model': 'HeteroGNN', 'scaler': 'standard_l2', 'dim_reduction': 'pca', 'pca_threshold': 0.99, 'epoch': 1000}\n","Epoch 343:\n","  TX:\n","   Train: Loss=0.0615, Acc=0.9820, F1=0.9899, Bal. Acc=0.9866\n","   Val:   Loss=0.1818, Acc=0.9638, F1=0.9797, Bal. Acc=0.9347\n","   Test:  Loss=0.1881, Acc=0.9593, F1=0.9773, Bal. Acc=0.9231\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.90      0.83       453\n","           1       0.99      0.97      0.98      4105\n","\n","    accuracy                           0.96      4558\n","   macro avg       0.88      0.93      0.91      4558\n","weighted avg       0.97      0.96      0.96      4558\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.88      0.81       665\n","           1       0.99      0.97      0.98      6172\n","\n","    accuracy                           0.96      6837\n","   macro avg       0.87      0.92      0.89      6837\n","weighted avg       0.96      0.96      0.96      6837\n","\n","  WALLETS:\n","   Train: Loss=0.28594661, Acc=0.88978752, F1=0.93719905, Bal. Acc=0.8808\n","   Val:   Loss=0.28987944, Acc=0.8888, F1=0.9365, Bal. Acc=0.8773\n","   Test:  Loss=0.29045761, Acc=0.8894, F1=0.9369, Bal. Acc=0.8733\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.86      0.55      2906\n","           1       0.99      0.89      0.94     33841\n","\n","    accuracy                           0.89     36747\n","   macro avg       0.70      0.88      0.74     36747\n","weighted avg       0.94      0.89      0.91     36747\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.85      0.55      4340\n","           1       0.99      0.89      0.94     50781\n","\n","    accuracy                           0.89     55121\n","   macro avg       0.70      0.87      0.74     55121\n","weighted avg       0.94      0.89      0.91     55121\n","\n","\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1wIoomnaeh74t1AKH1zYUzUr42JRiCeq-","timestamp":1739893838211}],"collapsed_sections":["P4xEz6Qv7asp"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}