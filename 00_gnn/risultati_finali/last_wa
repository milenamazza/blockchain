{"cells":[{"cell_type":"markdown","source":["# Addestramento\n","Migliore modello del TransformerConv addestrato su 1000 epoche per la classificazione dei wallet"],"metadata":{"id":"GR94DzLt62zk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iidXjXM7pXO"},"outputs":[],"source":["%%capture\n","from google.colab import drive\n","drive.mount('/content/drive')  # Autenticazione con Google Drive\n","\n","!pip install torch_geometric\n","#!pip install torch-sparse\n","import pandas as pd\n","import os\n","import random\n","import numpy as np\n","import os.path as osp\n","import torch\n","import warnings\n","from torch_geometric.data import Data, HeteroData\n","from torch_geometric.transforms import RandomNodeSplit\n","from torch_geometric.nn import GCNConv, GATConv, SAGEConv, ChebConv\n","import torch_geometric.nn as pyg_nn\n","import torch.nn as nn\n","import torch_geometric.utils as pyg_utils\n","from torch.nn import Module, Linear\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_recall_fscore_support, f1_score, classification_report\n","from torch_geometric.seed import seed_everything\n","import joblib\n","drive.mount('/content/drive')  # Autenticazione con Google Drive\n","\n","warnings.simplefilter(action='ignore')\n","SEED = 51\n","FILEPATH_TX = \"/content/drive/MyDrive/blockchain/00_gnn/risultati_finali/final_res/tx_last_1.csv\"\n","FILEPATH_WALLET = \"/content/drive/MyDrive/blockchain/00_gnn/risultati_finali/final_res/w_last_1.csv\"\n","\n","base_path = \"/content/drive/MyDrive/blockchain/E++/\"\n","path_comb = '/content/drive/MyDrive/blockchain/00_gnn/combination_do.csv'\n","\n","type_classification = 'w'"]},{"cell_type":"markdown","metadata":{"id":"XOk9zPoYDC5I"},"source":["##Crea db vuoto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCrI1kO2CYxi"},"outputs":[],"source":["def create_df():\n","  # Crea DataFrame vuoti\n","  df_tx = pd.DataFrame(columns=['epoch', 'hidden_channels', 'out_channels', 'num_layers', 'num_epoch', 'patience', 'lr', 'weight_decay', 'conv_type', 'eps', 'gamma','step_size', 'aggr', 'end'])\n","  df_wallet = pd.DataFrame(columns=['epoch', 'hidden_channels', 'out_channels', 'num_layers', 'num_epoch', 'patience', 'lr', 'weight_decay', 'conv_type', 'eps', 'gamma','step_size', 'aggr', 'end'])\n","\n","  # Salva i DataFrame come file CSV\n","  df_tx.to_csv(FILEPATH_TX, index=False)\n","  df_wallet.to_csv(FILEPATH_WALLET, index=False)\n","\n","#create_df()"]},{"cell_type":"markdown","metadata":{"id":"W1Syx8hzDPvM"},"source":["##Carica dati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qobTcbrVqpwG"},"outputs":[],"source":["def load_data():\n","    # Loading transactions\n","\n","    #Reading edges, features and classes from transaction files (as done with the original dataset)\n","    df_edges_tx = pd.read_csv(osp.join(base_path, \"txs_edgelist.csv\"))\n","    df_features_tx = pd.read_csv(osp.join(base_path, \"txs_features.csv\"), header=None)\n","    df_classes_tx = pd.read_csv(osp.join(base_path, \"txs_classes.csv\"))\n","\n","    #Columns naming based on index\n","    colNames1_tx = {'0': 'txId', 1: \"Time step\"}\n","    colNames2_tx = {str(ii+2): \"Local_feature_\" + str(ii+1) for ii in range(94)}\n","    colNames3_tx = {str(ii+96): \"Aggregate_feature_\" + str(ii+1) for ii in range(72)}\n","\n","    colNames_tx = dict(colNames1_tx, **colNames2_tx, **colNames3_tx)\n","    colNames_tx = {int(jj): item_kk for jj, item_kk in colNames_tx.items()}\n","\n","    # Rename feature columns\n","    df_features_tx = df_features_tx.rename(columns=colNames_tx)\n","\n","    # Map unknown class to '3'\n","    df_classes_tx.loc[df_classes_tx['class'] == 'unknown', 'class'] = '3'\n","\n","    # Merge classes and features in one Dataframe\n","    df_class_feature_tx = pd.merge(df_classes_tx, df_features_tx)\n","\n","    # Exclude records with unknown class transaction\n","    df_class_feature_tx = df_class_feature_tx[df_class_feature_tx['class'] != 3]\n","\n","    # Build Dataframe with head and tail of transactions (edges)\n","    known_txs = df_class_feature_tx[\"txId\"].values\n","    df_edges_tx = df_edges_tx[(df_edges_tx[\"txId1\"].isin(known_txs)) & (df_edges_tx[\"txId2\"].isin(known_txs))]\n","\n","    # Build indices for features and edge types\n","    features_idx_tx = {name: idx for idx, name in enumerate(sorted(df_class_feature_tx[\"txId\"].unique()))}\n","    class_idx_tx = {name: idx for idx, name in enumerate(sorted(df_class_feature_tx[\"class\"].unique()))}\n","\n","    # Apply index encoding to features\n","    df_class_feature_tx[\"txId\"] = df_class_feature_tx[\"txId\"].apply(lambda name: features_idx_tx[name])\n","    df_class_feature_tx[\"class\"] = df_class_feature_tx[\"class\"].apply(lambda name: class_idx_tx[name])\n","\n","    # Apply index encoding to edges\n","    df_edges_tx[\"txId1\"] = df_edges_tx[\"txId1\"].apply(lambda name: features_idx_tx[name])\n","    df_edges_tx[\"txId2\"] = df_edges_tx[\"txId2\"].apply(lambda name: features_idx_tx[name])\n","\n","    # Loading wallets\n","\n","    # From file\n","    df_edges_wallet = pd.read_csv(osp.join(base_path, \"AddrAddr_edgelist.csv\"))\n","    df_class_feature_wallet = pd.read_csv(osp.join(base_path, \"wallets_features_classes_combined.csv\"))\n","\n","    # Exclude records with unknown class transaction\n","    #print(df_class_feature_wallet.shape)\n","    df_class_feature_wallet = df_class_feature_wallet[df_class_feature_wallet[\"class\"] != 3]\n","    #print(df_class_feature_wallet.shape)\n","\n","    # Build Dataframe with head and tail of AddrToAddr (edges)\n","    known_wallets = df_class_feature_wallet[\"address\"].values\n","    df_edges_wallet = df_edges_wallet[(df_edges_wallet[\"input_address\"].isin(known_wallets)) & (df_edges_wallet[\"output_address\"].isin(known_wallets))]\n","\n","    # Building indices for features and edge types\n","    features_idx_wallet = {name: idx for idx, name in enumerate(sorted(df_class_feature_wallet[\"address\"].unique()))}\n","    class_idx_wallet = {name: idx for idx, name in enumerate(sorted(df_class_feature_wallet[\"class\"].unique()))}\n","\n","    # Apply index encoding to features\n","    df_class_feature_wallet[\"address\"] = df_class_feature_wallet[\"address\"].apply(lambda name: features_idx_wallet[name])\n","    df_class_feature_wallet[\"class\"] = df_class_feature_wallet[\"class\"].apply(lambda name: class_idx_wallet[name])\n","\n","    # Apply index encoding to edges\n","    df_edges_wallet[\"input_address\"] = df_edges_wallet[\"input_address\"].apply(lambda name: features_idx_wallet[name])\n","    df_edges_wallet[\"output_address\"] = df_edges_wallet[\"output_address\"].apply(lambda name: features_idx_wallet[name])\n","\n","    # Loading AddrTx and TxAddr\n","\n","    # From file\n","    df_edges_wallet_tx = pd.read_csv(osp.join(base_path, \"AddrTx_edgelist.csv\"))\n","    df_edges_tx_wallet = pd.read_csv(osp.join(base_path, \"TxAddr_edgelist.csv\"))\n","\n","    # Build Dataframe with head and tail of AddrTx (edges)\n","    df_edges_wallet_tx = df_edges_wallet_tx[(df_edges_wallet_tx[\"input_address\"].isin(known_wallets)) & df_edges_wallet_tx[\"txId\"].isin(known_txs)]\n","    df_edges_tx_wallet = df_edges_tx_wallet[(df_edges_tx_wallet[\"txId\"].isin(known_txs)) & df_edges_tx_wallet[\"output_address\"].isin(known_wallets)]\n","\n","    # Apply index encoding to edges\n","    df_edges_wallet_tx[\"input_address\"] = df_edges_wallet_tx[\"input_address\"].apply(lambda name: features_idx_wallet[name])\n","    df_edges_wallet_tx[\"txId\"] = df_edges_wallet_tx[\"txId\"].apply(lambda name: features_idx_tx[name])\n","    df_edges_tx_wallet[\"txId\"] = df_edges_tx_wallet[\"txId\"].apply(lambda name: features_idx_tx[name])\n","    df_edges_tx_wallet[\"output_address\"] = df_edges_tx_wallet[\"output_address\"].apply(lambda name: features_idx_wallet[name])\n","\n","    return df_class_feature_tx, df_edges_tx, df_class_feature_wallet, df_edges_wallet, df_edges_wallet_tx, df_edges_tx_wallet, features_idx_tx, features_idx_wallet\n","\n","def data_to_pyg(df_class_feature_tx, df_edges_tx, df_class_feature_wallet, df_edges_wallet, df_edges_wallet_tx, df_edges_tx_wallet, features_idx_tx, features_idx_wallet):\n","    data = HeteroData()\n","\n","    # Defining PyG objects for transactions\n","    df_class_feature_tx = df_class_feature_tx.fillna(0)\n","    data['tx'].x = torch.tensor(df_class_feature_tx.iloc[:, 3:].values, dtype=torch.float)\n","    data['tx'].y = torch.tensor(df_class_feature_tx[\"class\"].values, dtype=torch.long)\n","    data['tx','is_related_to','tx'].edge_index = torch.tensor([df_edges_tx[\"txId1\"].values,\n","                            df_edges_tx[\"txId2\"].values], dtype=torch.int64)\n","    #data['tx'] = random_node_split(num_val=0.15, num_test=0.2)(data['tx'])\n","    # Defining PyG objects for wallets\n","    data['wallet'].x = torch.tensor(df_class_feature_wallet.iloc[:, 3:].values, dtype=torch.float)\n","    data['wallet'].y = torch.tensor(df_class_feature_wallet[\"class\"].values, dtype=torch.long)\n","    data['wallet','interacts_with','wallet'].edge_index = torch.tensor([df_edges_wallet[\"input_address\"].values,\n","                            df_edges_wallet[\"output_address\"].values], dtype=torch.int64)\n","    #data['wallet'] = random_node_split(num_val=0.15, num_test=0.2)(data['wallet'])\n","    # Defining PyG objects for cross-edges\n","    data['wallet','performs','tx'].edge_index = torch.tensor([df_edges_wallet_tx[\"input_address\"].values,\n","                                         df_edges_wallet_tx[\"txId\"].values], dtype=torch.int64)\n","\n","    data['tx', 'flows_into', 'wallet'].edge_index = torch.tensor([df_edges_tx_wallet[\"txId\"].values,\n","                                         df_edges_tx_wallet[\"output_address\"].values], dtype=torch.int64)\n","\n","    # Impostare il seed per la divisione del dataset\n","    return RandomNodeSplit(num_val=0.10, num_test=0.15)(data)"]},{"cell_type":"markdown","metadata":{"id":"OhFPkCpExzOL"},"source":["##Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQfEkZ1nx44T"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Do2dQUF-x7hj"},"outputs":[],"source":["#NEW -> SU RANGE\n","# Utility per conversione a tensor\n","def to_tensor(arr):\n","    return torch.tensor(arr, dtype=torch.float).to(device)\n","\n","def scale_features(data, method=\"standard\"):\n","  if method == 'no':\n","    return data\n","\n","  # Scaling per training\n","  data['tx'].x[data['tx'].train_mask] = to_tensor(\n","      scale_train_data(data['tx'].x[data['tx'].train_mask].cpu().numpy(), method, 'tx')\n","  )\n","  data['wallet'].x[data['wallet'].train_mask] = to_tensor(\n","      scale_train_data(data['wallet'].x[data['wallet'].train_mask].cpu().numpy(), method, 'wallet')\n","  )\n","\n","  # Scaling per validation\n","  data['tx'].x[data['tx'].val_mask] = to_tensor(scale_validation_data(data['tx'].x[data['tx'].val_mask].cpu().numpy(), method, 'tx'))\n","  data['wallet'].x[data['wallet'].val_mask] = to_tensor(scale_validation_data(data['wallet'].x[data['wallet'].val_mask].cpu().numpy(), method, 'wallet'))\n","\n","  data['tx'].x[data['tx'].test_mask] = to_tensor(scale_validation_data(data['tx'].x[data['tx'].test_mask].cpu().numpy(), method, 'tx'))\n","  data['wallet'].x[data['wallet'].test_mask] = to_tensor(scale_validation_data(data['wallet'].x[data['wallet'].test_mask].cpu().numpy(), method, 'wallet'))\n","  return data\n","\n","def scale_train_data(train, scaling_method, df):\n","\n","    if 'standard' in scaling_method:\n","        scaler = StandardScaler()\n","        scaled_train = scaler.fit_transform(train)  # Scala tutte le colonne\n","        joblib.dump(scaler, f\"scaler_standard_{df}.pkl\")\n","\n","        if 'l2' in scaling_method:\n","            norm = Normalizer(norm='l2')\n","            scaled_train = norm.fit_transform(scaled_train)\n","            joblib.dump(norm, f\"scaler_l2_{df}.pkl\")\n","    else:\n","        raise ValueError(f\"Metodo di scaling '{scaling_method}' non supportato.\")\n","\n","    return scaled_train\n","\n","def scale_validation_data(val, scaling_method, df):\n","\n","    if 'standard' in scaling_method:\n","        scaler = joblib.load(f\"scaler_standard_{df}.pkl\")\n","        scaled_val = scaler.transform(val)  # Scala tutte le colonne\n","\n","        if 'l2' in scaling_method:\n","            norm = joblib.load(f\"scaler_l2_{df}.pkl\")\n","            scaled_val = norm.transform(scaled_val)\n","    else:\n","        raise ValueError(f\"Metodo di scaling '{scaling_method}' non supportato.\")\n","\n","    return scaled_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVRMmabn21eP"},"outputs":[],"source":["def dimentional_reduction(data, dim_reduction, pca_threshold):\n","    if dim_reduction == 'no':\n","        return data\n","    elif dim_reduction == 'pca':\n","        data1 = copy.deepcopy(data)\n","\n","        transformed_tx_data = apply_pca_train(data['tx'].x[data['tx'].train_mask].cpu().numpy(), 'tx', pca_threshold)\n","        transformed_wallet_data = apply_pca_train(data['wallet'].x[data['wallet'].train_mask].cpu().numpy(), 'wallet', pca_threshold)\n","\n","        data1['tx'].x = torch.zeros((data['tx'].x.shape[0], transformed_tx_data.shape[1]), dtype=torch.float, device=device)\n","        data1['wallet'].x = torch.zeros((data['wallet'].x.shape[0], transformed_wallet_data.shape[1]), dtype=torch.float, device=device)\n","\n","        data1['tx'].x[data['tx'].train_mask] = to_tensor(transformed_tx_data)\n","        data1['wallet'].x[data['wallet'].train_mask] = to_tensor(transformed_wallet_data)\n","\n","        transformed_tx_data = apply_pca_validation(data['tx'].x[data['tx'].val_mask].cpu().numpy(), 'tx')\n","        transformed_wallet_data = apply_pca_validation(data['wallet'].x[data['wallet'].val_mask].cpu().numpy(), 'wallet')\n","        data1['tx'].x[data['tx'].val_mask] = to_tensor(transformed_tx_data)\n","        data1['wallet'].x[data['wallet'].val_mask] = to_tensor(transformed_wallet_data)\n","\n","        transformed_tx_data = apply_pca_validation(data['tx'].x[data['tx'].test_mask].cpu().numpy(), 'tx')\n","        transformed_wallet_data = apply_pca_validation(data['wallet'].x[data['wallet'].test_mask].cpu().numpy(), 'wallet')\n","        data1['tx'].x[data['tx'].test_mask] = to_tensor(transformed_tx_data)\n","        data1['wallet'].x[data['wallet'].test_mask] = to_tensor(transformed_wallet_data)\n","\n","        return data1\n","\n","def apply_pca_train(train, df, pca_threshold=0.99):\n","    pca = PCA(random_state=SEED)\n","    pca.fit(train)\n","\n","    # Selezione componenti principali\n","    cumulative_variance = pca.explained_variance_ratio_.cumsum()\n","    n_components = (cumulative_variance >= pca_threshold).argmax() + 1\n","\n","    pca = PCA(n_components=n_components, random_state=SEED)\n","    transformed_data = pca.fit_transform(train).astype(np.float32)\n","\n","    joblib.dump(pca, f\"pca_model_{df}.pkl\")\n","    print(f\"  Numero di componenti principali per {df}: {pca.n_components_}\")\n","\n","    return transformed_data\n","\n","def apply_pca_validation(val, df):\n","    pca = joblib.load(f\"pca_model_{df}.pkl\")\n","    transformed_data = pca.transform(val).astype(np.float32)\n","    return transformed_data"]},{"cell_type":"markdown","metadata":{"id":"CaNNtrNLDSdI"},"source":["##Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbfXKtdynFBL"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear, Dropout\n","from torch_geometric.nn import HeteroConv, GATConv, SAGEConv, TransformerConv\n","import random\n","from itertools import product\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxfbqge_p64q"},"outputs":[],"source":["def set_seed(seed = 51):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # Per più GPU\n","\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    torch.use_deterministic_algorithms(True, warn_only=True)\n","\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    seed_everything(seed)\n","device = \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EiBF-BZYfq7b"},"outputs":[],"source":["class ResidualHeteroGNN(torch.nn.Module):\n","    def __init__(self, conv, hidden_channels=64, num_layers=2, aggr='sum', dropout_prob=0.5, out_channels=2, num_head=1):\n","        super().__init__()\n","        self.convs = torch.nn.ModuleList()\n","        self.skips = torch.nn.ModuleList()\n","        self.dropout = Dropout(p=dropout_prob)\n","        heads = num_head if conv == 'Transformer' else 1 # Define heads\n","\n","        for _ in range(num_layers):\n","            if conv == 'GAT':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads),\n","                    ('wallet', 'interacts_with', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads),\n","                    ('wallet', 'performs', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads),\n","                    ('tx', 'flows_into', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False, heads=heads)\n","                }, aggr=aggr)\n","            elif conv == 'SAGE':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'interacts_with', 'wallet'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'performs', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('tx', 'flows_into', 'wallet'): SAGEConv(-1, hidden_channels)\n","                }, aggr=aggr)\n","            elif conv == 'Transformer':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'interacts_with', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'performs', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('tx', 'flows_into', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads)\n","                }, aggr=aggr)\n","            else:\n","                raise ValueError(\"Invalid convolution type. Choose from ['GAT', 'SAGE', 'Transformer']\")\n","\n","            self.convs.append(conv_layer)\n","            self.skips.append(Linear(hidden_channels * heads, hidden_channels * heads)) # Fix: Linear layer expects the output of conv\n","\n","        # FIX: Modifica della dimensione di input dei layer lineari\n","        self.lin_tx = Linear(hidden_channels * heads, out_channels)\n","        self.lin_wallet = Linear(hidden_channels * heads, out_channels)\n","\n","    def forward(self, x_dict, edge_index_dict):\n","        for conv, skip in zip(self.convs, self.skips):\n","            x_dict_new = conv(x_dict, edge_index_dict)\n","            x_dict = {key: self.dropout(F.relu(x + skip(x_dict_new[key]))) for key, x in x_dict_new.items()}  # Residual + Dropout\n","        return self.lin_tx(x_dict['tx']), self.lin_wallet(x_dict['wallet'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdcebmslq5D0"},"outputs":[],"source":["class HeteroGNN(torch.nn.Module):\n","    def __init__(self, conv, hidden_channels=64, num_layers=2, aggr='sum', dropout_prob=0, out_channels=2, num_head=1):\n","        super().__init__()\n","        self.convs = torch.nn.ModuleList()\n","        self.dropout = Dropout(p=dropout_prob)\n","        heads = num_head if conv == 'Transformer' else 1  # Definiamo i heads solo se necessario\n","\n","        for _ in range(num_layers):\n","            if conv == 'GAT':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n","                    ('wallet', 'interacts_with', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n","                    ('wallet', 'performs', 'tx'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n","                    ('tx', 'flows_into', 'wallet'): GATConv((-1, -1), hidden_channels, add_self_loops=False)\n","                }, aggr=aggr)\n","            elif conv == 'SAGE':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'interacts_with', 'wallet'): SAGEConv(-1, hidden_channels),\n","                    ('wallet', 'performs', 'tx'): SAGEConv(-1, hidden_channels),\n","                    ('tx', 'flows_into', 'wallet'): SAGEConv(-1, hidden_channels)\n","                }, aggr=aggr)\n","            elif conv == 'Transformer':\n","                conv_layer = HeteroConv({\n","                    ('tx', 'is_related_to', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'interacts_with', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('wallet', 'performs', 'tx'): TransformerConv((-1, -1), hidden_channels, heads=heads),\n","                    ('tx', 'flows_into', 'wallet'): TransformerConv((-1, -1), hidden_channels, heads=heads)\n","                }, aggr=aggr)\n","            else:\n","                raise ValueError(\"Invalid convolution type. Choose from ['GAT', 'SAGE', 'Transformer']\")\n","\n","            self.convs.append(conv_layer)\n","\n","        # FIX: Modifica della dimensione di input dei layer lineari\n","        self.lin_tx = Linear(hidden_channels * heads, out_channels)\n","        self.lin_wallet = Linear(hidden_channels * heads, out_channels)\n","\n","    def forward(self, x_dict, edge_index_dict):\n","        for conv in self.convs:\n","            x_dict = conv(x_dict, edge_index_dict)\n","            x_dict = {key: self.dropout(x.relu()) for key, x in x_dict.items()}\n","        return self.lin_tx(x_dict['tx']), self.lin_wallet(x_dict['wallet'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJEJVt5l04Eb"},"outputs":[],"source":["def is_combination_tested(filepath, new_row):\n","    existing_results = pd.read_csv(filepath)\n","\n","    # Identifica le colonne comuni tra il dataset e new_row\n","    dataset_columns = set(existing_results.columns)\n","    comparison_columns = [col for col in new_row.keys() if col not in ['end', 'num_epoch', 'epoch']]\n","\n","    # Filtra le combinazioni\n","    filtered_results = existing_results.copy()\n","    #filtered_results = filtered_results[filtered_results['end'] == True]\n","    filtered_results = filtered_results[filtered_results['num_epoch'] >= new_row['num_epoch']]\n","\n","    for col in comparison_columns:\n","        if col in dataset_columns:\n","            # Mantieni solo le righe in cui i valori corrispondono (o sono entrambi NaN)\n","            filtered_results = filtered_results[\n","                (filtered_results[col] == new_row[col]) | (pd.isna(filtered_results[col]) & pd.isna(new_row[col]))\n","            ]\n","\n","    return not filtered_results.empty\n","\n","def append_and_save_results(FILEPATH_TX, FILEPATH_WALLET, params_tx, params_wallet, end=False):\n","  def append_and_save_result(filepath, new_row, end=False):\n","    new_row['end'] = end\n","    # Leggi i risultati esistenti\n","    results_df = pd.read_csv(filepath)\n","    results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n","    results_df.to_csv(filepath, index=False)\n","\n","  append_and_save_result(FILEPATH_TX, params_tx, end)\n","  append_and_save_result(FILEPATH_WALLET, params_wallet, end)\n","  if end:\n","    df_comb = pd.read_csv(path_comb)\n","    filtered_params = {key: params_tx[key] for key in params_tx if \"train\" not in key and \"val\" not in key}\n","    print(filtered_params)\n","    df_comb = pd.concat([df_comb, pd.DataFrame([filtered_params])], ignore_index=True)\n","    df_comb.to_csv(path_comb, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vo1zTF6zxQR"},"outputs":[],"source":["def compute_class_weights(data):\n","    class_counts = torch.bincount(data['tx'].y)\n","    weights = 1.0 / class_counts.float()\n","    weights /= weights.sum()\n","    return weights\n","\n","def eval(model, data, out_tx, out_wallet, params):\n","\n","  class_weights = compute_class_weights(data)\n","  criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n","\n","  model.eval()  # Imposta il modello in modalità di valutazione\n","\n","  tx_mask = data['tx'].train_mask\n","  wallet_mask = data['wallet'].train_mask\n","  tx_mask_val =  data['tx'].val_mask\n","  wallet_mask_val = data['wallet'].val_mask\n","\n","  params_tx = copy.copy(params)\n","  params_wallet = copy.copy(params)\n","\n","  # Calculate metrics for transactions\n","  params_tx['train_loss'] = criterion(out_tx[tx_mask], data['tx'].y[tx_mask].cpu())  # Convert to scalar\n","  params_tx['train_acc'] = accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_f1'] = f1_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  # Calculate metrics for wallets\n","  params_wallet['train_loss'] = criterion(out_wallet[wallet_mask], data['wallet'].y[wallet_mask].cpu())  # Convert to scalar\n","  params_wallet['train_acc'] = accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_f1'] = f1_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","\n","  loss = params_tx['train_loss'] + params_wallet['train_loss']\n","\n","  with torch.no_grad():\n","    params_tx['val_loss'] = criterion(out_tx[tx_mask_val], data['tx'].y[tx_mask_val].cpu())  # Convert to scalar\n","    params_tx['val_acc'] = accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_precision'] = precision_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_recall'] = recall_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_f1'] = f1_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","\n","    # Calculate metrics for wallets\n","    params_wallet['val_loss'] = criterion(out_wallet[wallet_mask_val], data['wallet'].y[wallet_mask_val].cpu())  # Convert to scalar\n","    params_wallet['val_acc'] = accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_precision'] = precision_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_recall'] = recall_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_f1'] = f1_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","\n","    print(f\"Epoch {str(params['epoch']).zfill(3)}:      TX: Train Loss: {params_tx['train_loss']:.4f}, Acc: {params_tx['train_acc']:.4f}, F1: {params_tx['train_f1']:.4f} Bal: {params_tx['train_balanced_acc']:.4f} - Val Loss: {params_tx['val_loss']:.4f}, Accuracy: {params_tx['val_acc']:.4f}, F1: {params_tx['val_f1']:.4f} Bal: {params_tx['val_balanced_acc']:.4f}\")\n","    print(f\"           WALLETS: Train Loss: {params_wallet['train_loss']:.8f}, Acc: {params_wallet['train_acc']:.8f}, F1: {params_wallet['train_f1']:.8f} Bal: {params_wallet['train_balanced_acc']:.4f} - Val Loss: {params_wallet['val_loss']:.8f}, Accuracy: {params_wallet['val_acc']:.4f}, F1: {params_wallet['val_f1']:.4f} Bal: {params_wallet['val_balanced_acc']:.4f}\")\n","\n","  return loss, params_tx, params_wallet\n","\n","\n","def eval_total(model, data, out_tx, out_wallet, params, best_epoch):\n","\n","  class_weights = compute_class_weights(data)\n","  criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n","\n","  model.eval()  # Imposta il modello in modalitÃ  di valutazione\n","\n","  tx_mask = data['tx'].train_mask\n","  wallet_mask = data['wallet'].train_mask\n","  tx_mask_val =  data['tx'].val_mask\n","  wallet_mask_val = data['wallet'].val_mask\n","  tx_mask_test = data['tx'].test_mask\n","  wallet_mask_test = data['wallet'].test_mask\n","\n","  params_tx = copy.copy(params)\n","  params_wallet = copy.copy(params)\n","\n","  # Calculate metrics for transactions\n","  params_tx['train_loss'] = criterion(out_tx[tx_mask], data['tx'].y[tx_mask].cpu())  # Convert to scalar\n","  params_tx['train_acc'] = accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_f1'] = f1_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  params_tx['train_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask].cpu(), out_tx[tx_mask].argmax(dim=1).cpu())\n","  # Calculate metrics for wallets\n","  params_wallet['train_loss'] = criterion(out_wallet[wallet_mask], data['wallet'].y[wallet_mask].cpu())  # Convert to scalar\n","  params_wallet['train_acc'] = accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_f1'] = f1_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","  params_wallet['train_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask].cpu(), out_wallet[wallet_mask].argmax(dim=1).cpu())\n","\n","  with torch.no_grad():\n","    # Calculate metrics for validation\n","    params_tx['val_loss'] = criterion(out_tx[tx_mask_val], data['tx'].y[tx_mask_val].cpu())  # Convert to scalar\n","    params_tx['val_acc'] = accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_precision'] = precision_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_recall'] = recall_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_f1'] = f1_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    params_tx['val_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","    report_tx_val = classification_report(data['tx'].y[tx_mask_val].cpu(), out_tx[tx_mask_val].argmax(dim=1).cpu())\n","\n","    params_wallet['val_loss'] = criterion(out_wallet[wallet_mask_val], data['wallet'].y[wallet_mask_val].cpu())  # Convert to scalar\n","    params_wallet['val_acc'] = accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_precision'] = precision_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_recall'] = recall_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_f1'] = f1_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    params_wallet['val_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","    report_wallet_val = classification_report(data['wallet'].y[wallet_mask_val].cpu(), out_wallet[wallet_mask_val].argmax(dim=1).cpu())\n","\n","    # Calculate metrics for test\n","    params_tx['test_loss'] = criterion(out_tx[tx_mask_test], data['tx'].y[tx_mask_test].cpu())  # Convert to scalar\n","    params_tx['test_acc'] = accuracy_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_precision'] = precision_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_recall'] = recall_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_f1'] = f1_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    params_tx['test_balanced_acc'] = balanced_accuracy_score(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","    report_tx_test = classification_report(data['tx'].y[tx_mask_test].cpu(), out_tx[tx_mask_test].argmax(dim=1).cpu())\n","\n","    params_wallet['test_loss'] = criterion(out_wallet[wallet_mask_test], data['wallet'].y[wallet_mask_test].cpu())  # Convert to scalar\n","    params_wallet['test_acc'] = accuracy_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_precision'] = precision_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_recall'] = recall_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_f1'] = f1_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    params_wallet['test_balanced_acc'] = balanced_accuracy_score(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","    report_wallet_test = classification_report(data['wallet'].y[wallet_mask_test].cpu(), out_wallet[wallet_mask_test].argmax(dim=1).cpu())\n","\n","    # Stampa delle metriche con formattazione migliorata\n","    print('Final_result for '+type_classification)\n","    print(params)\n","    print(f\"Epoch {best_epoch}:\")\n","    print(\"  TX:\")\n","    print(f\"   Train: Loss={params_tx['train_loss']:.4f}, Acc={params_tx['train_acc']:.4f}, F1={params_tx['train_f1']:.4f}, Bal. Acc={params_tx['train_balanced_acc']:.4f}\")\n","    print(f\"   Val:   Loss={params_tx['val_loss']:.4f}, Acc={params_tx['val_acc']:.4f}, F1={params_tx['val_f1']:.4f}, Bal. Acc={params_tx['val_balanced_acc']:.4f}\")\n","    print(f\"   Test:  Loss={params_tx['test_loss']:.4f}, Acc={params_tx['test_acc']:.4f}, F1={params_tx['test_f1']:.4f}, Bal. Acc={params_tx['test_balanced_acc']:.4f}\")\n","    print(report_tx_val)\n","    print(report_tx_test)\n","    print(\"  WALLETS:\")\n","    print(f\"   Train: Loss={params_wallet['train_loss']:.8f}, Acc={params_wallet['train_acc']:.8f}, F1={params_wallet['train_f1']:.8f}, Bal. Acc={params_wallet['train_balanced_acc']:.4f}\")\n","    print(f\"   Val:   Loss={params_wallet['val_loss']:.8f}, Acc={params_wallet['val_acc']:.4f}, F1={params_wallet['val_f1']:.4f}, Bal. Acc={params_wallet['val_balanced_acc']:.4f}\")\n","    print(f\"   Test:  Loss={params_wallet['test_loss']:.8f}, Acc={params_wallet['test_acc']:.4f}, F1={params_wallet['test_f1']:.4f}, Bal. Acc={params_wallet['test_balanced_acc']:.4f}\")\n","    print(report_wallet_val)\n","    print(report_wallet_test)\n","    print()\n","\n","def compute_class_weights(data):\n","    class_counts = torch.bincount(data['tx'].y)\n","    weights = 1.0 / class_counts.float()\n","    weights /= weights.sum()\n","    return weights\n","\n","def train(model, data, params):\n","    best_model = None\n","    best_epoch = None\n","\n","    if params['optimizer'] == 'Adam':\n","      optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n","    elif params['optimizer'] == 'AdamW':\n","      optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n","    else:\n","      optimizer = None\n","\n","    if params['lr_scheduler'] == 'ReduceLROnPlateau':\n","      scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=params['factor'], patience=params['p'])\n","    elif params['lr_scheduler'] == 'CosineAnnealingLR':\n","      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=params['T_max'], eta_min=params['eta_min'])\n","    elif params['lr_scheduler'] == 'StepLR':\n","      scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=params['step_size'], gamma=params['gamma'])\n","    else:\n","      scheduler = None\n","\n","    print(f'Combinazione: {params}')\n","    model.train()\n","    tx_mask = data['tx'].train_mask\n","    wallet_mask = data['wallet'].train_mask\n","    tx_mask_val =  data['tx'].val_mask\n","    wallet_mask_val = data['wallet'].val_mask\n","\n","    best_val_tx_acc = 0\n","    best_val_wallet_acc = 0\n","\n","    best_val_tx_loss = float('inf')\n","    best_val_wallet_loss = float('inf')\n","    patience = params['patience']\n","    epochs_since_best = 0\n","\n","    for epoch in range(params['num_epoch']):\n","        params['epoch'] = epoch+1\n","        optimizer.zero_grad()\n","        out_tx, out_wallet = model(data.x_dict, data.edge_index_dict)\n","        loss, params_tx, params_wallet = eval(model, data, out_tx, out_wallet, params)\n","\n","        val_tx_loss = params_tx['val_loss']\n","        val_wallet_loss = params_wallet['val_loss']\n","        val_tx_acc = params_tx['val_balanced_acc']\n","        val_wallet_acc = params_wallet['val_balanced_acc']\n","\n","        # Check if validation loss has improved\n","        if val_tx_loss < best_val_tx_loss or val_wallet_loss < best_val_wallet_loss:\n","            best_val_tx_loss = val_tx_loss\n","            best_val_wallet_loss = val_wallet_loss\n","            epochs_since_best = 0\n","        else:\n","            epochs_since_best += 1\n","\n","        # Check if early stopping criteria is met\n","        if epochs_since_best >= patience:\n","            print(f'Early stopping at epoch {epoch}')\n","            #append_and_save_results(FILEPATH_TX, FILEPATH_WALLET, params_tx, params_wallet, True)\n","            out_tx, out_wallet = best_model(data.x_dict, data.edge_index_dict)\n","            eval_total(best_model, data, out_tx, out_wallet, params, best_epoch)\n","            return best_model\n","\n","        if type_classification == 'w':\n","          if best_val_wallet_acc < val_wallet_acc:\n","            best_val_wallet_acc = val_wallet_acc\n","            best_model = copy.deepcopy(model)\n","            best_epoch = epoch+1\n","\n","        elif type_classification == 'tx':\n","          if best_val_tx_acc < val_tx_acc:\n","            best_val_tx_acc = val_tx_acc\n","            best_model = copy.deepcopy(model)\n","            best_epoch = epoch+1\n","\n","        else:\n","          print('Definisci modello da considerare')\n","          raise ValueError\n","\n","        loss.backward()\n","        optimizer.step()\n","        #scheduler.step()\n","        scheduler.step(loss)\n","\n","        #append_and_save_results(FILEPATH_TX, FILEPATH_WALLET, params_tx, params_wallet, params['epoch']==params['num_epoch'])\n","\n","    out_tx, out_wallet = best_model(data.x_dict, data.edge_index_dict)\n","    eval_total(best_model, data, out_tx, out_wallet, params, best_epoch)\n","    return model\n","\n","\n","def train_grid(data_full, param_grid, scalers, dim_reductions, pca_thresholds):\n","    best_model = None\n","    best_f1 = 0\n","\n","    keys, values = zip(*param_grid.items())\n","    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n","    combination_counter = 0\n","    total_combinations = len(param_combinations) * len(scalers) * len(dim_reductions) * len(pca_thresholds)\n","\n","    for scaler in scalers:\n","      data = scale_features(data_full.clone(), scaler)\n","      for dim_reduction in dim_reductions:\n","        for pca_threshold in pca_thresholds:\n","          data = dimentional_reduction(data, dim_reduction, pca_threshold)\n","\n","          for params in param_combinations:\n","            combination_counter += 1\n","\n","            set_seed(SEED)\n","            params['scaler'] = scaler\n","            params['dim_reduction'] = dim_reduction # Fixed the typo here: 'dim_reduction' instead of 'dim_reducition'\n","\n","            if params['lr_scheduler'] != 'ReduceLROnPlateau':\n","              params['p'] = None\n","              params['factor'] = None\n","            elif params['lr_scheduler'] != 'CosineAnnealingLR':\n","              params['T_max'] = None\n","              params['eta_min'] = None\n","\n","            if params['conv_type'] != 'Transformer':\n","              params['num_head'] = None\n","\n","            if dim_reduction == 'no':\n","              params['pca_threshold'] = None\n","            else:\n","              params['pca_threshold'] = pca_threshold\n","\n","            if True: #not is_combination_tested(path_comb, params):\n","              print(f\"  Combinazione {combination_counter}/{total_combinations}\")  # Print the counter\n","              model = None\n","              if params[ 'type_model'] == 'HeteroGNN':\n","                model = HeteroGNN(params['conv_type'], hidden_channels = params['hidden_channels'], num_layers = params['num_layers'],\n","                                  aggr=params['aggr'], dropout_prob=params['dropout'], num_head=params['num_head'])\n","              elif params[ 'type_model'] == 'ResidualHeteroGNN':\n","                model = ResidualHeteroGNN(params['conv_type'], hidden_channels = params['hidden_channels'], num_layers = params['num_layers'],\n","                                  aggr=params['aggr'], dropout_prob=params['dropout'], num_head=params['num_head'])\n","              model = train(model, data, params)\n","            else:\n","              print(f\"  Configurazione {combination_counter}/{total_combinations} già testata, salto...\")\n","    return best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOYfyiGS4aMO"},"outputs":[],"source":["set_seed(SEED)\n","data = data_to_pyg(*load_data())"]},{"cell_type":"markdown","source":["# Risultato"],"metadata":{"id":"aQOXKldv7NPm"}},{"cell_type":"code","source":["hyperparams = {\n","    \"hidden_channels\": [64],#\n","    'num_head': [2],#\n","    \"num_layers\": [2],\n","    \"num_epoch\": [829],\n","    #\"num_epoch\": [3],\n","    \"patience\": [50],\n","    \"lr\": [0.001],\n","    \"weight_decay\": [0.0005],\n","    \"dropout\": [0],\n","    \"conv_type\": ['Transformer'],\n","    \"p\": [10],#\n","    \"factor\": [0.5],#\n","    \"eta_min\": ['/'],\n","    \"T_max\": ['/'],\n","    \"aggr\": ['sum'],\n","    'lr_scheduler':['ReduceLROnPlateau'],\n","    'optimizer': ['Adam'],\n","    'type_model':['HeteroGNN'],\n","}\n","\n","scaler = ['standard_l2']\n","dim_reduction=['pca']\n","pca_threshold=[0.99]\n","best_model = train_grid(data, hyperparams, scaler, dim_reduction, pca_threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ga_C9F6UwLTV","executionInfo":{"status":"ok","timestamp":1743226438027,"user_tz":-60,"elapsed":32418534,"user":{"displayName":"Benedetta Bottari","userId":"12990631195970134636"}},"outputId":"fb027752-70eb-454f-f03f-9c29e1af8064"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Numero di componenti principali per tx: 73\n","  Numero di componenti principali per wallet: 22\n","  Combinazione 1/1\n","Combinazione: {'hidden_channels': 64, 'num_head': 2, 'num_layers': 2, 'num_epoch': 829, 'patience': 50, 'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0, 'conv_type': 'Transformer', 'p': 10, 'factor': 0.5, 'eta_min': None, 'T_max': None, 'aggr': 'sum', 'lr_scheduler': 'ReduceLROnPlateau', 'optimizer': 'Adam', 'type_model': 'HeteroGNN', 'scaler': 'standard_l2', 'dim_reduction': 'pca', 'pca_threshold': 0.99}\n","Epoch 001:      TX: Train Loss: 0.6885, Acc: 0.7995, F1: 0.8846 Bal: 0.5802 - Val Loss: 0.6886, Accuracy: 0.7984, F1: 0.8840 Bal: 0.5778\n","           WALLETS: Train Loss: 0.70094252, Acc: 0.08751687, F1: 0.02269512 Bal: 0.5021 - Val Loss: 0.70045346, Accuracy: 0.0889, F1: 0.0225 Bal: 0.5016\n","Epoch 002:      TX: Train Loss: 0.6806, Acc: 0.7455, F1: 0.8427 Bal: 0.6978 - Val Loss: 0.6809, Accuracy: 0.7473, F1: 0.8441 Bal: 0.6977\n","           WALLETS: Train Loss: 0.68554467, Acc: 0.57658089, F1: 0.71393131 Bal: 0.5976 - Val Loss: 0.68566179, Accuracy: 0.5806, F1: 0.7168 Bal: 0.6034\n","Epoch 003:      TX: Train Loss: 0.6721, Acc: 0.7481, F1: 0.8429 Bal: 0.7373 - Val Loss: 0.6727, Accuracy: 0.7427, F1: 0.8392 Bal: 0.7295\n","           WALLETS: Train Loss: 0.67386585, Acc: 0.83966125, F1: 0.91044685 Bal: 0.6006 - Val Loss: 0.67441541, Accuracy: 0.8393, F1: 0.9102 Bal: 0.5993\n","Epoch 004:      TX: Train Loss: 0.6625, Acc: 0.7760, F1: 0.8625 Bal: 0.7594 - Val Loss: 0.6633, Accuracy: 0.7753, F1: 0.8621 Bal: 0.7565\n","           WALLETS: Train Loss: 0.66405755, Acc: 0.90410879, F1: 0.94868110 Bal: 0.5952 - Val Loss: 0.66485804, Accuracy: 0.9029, F1: 0.9480 Bal: 0.5933\n","Epoch 005:      TX: Train Loss: 0.6518, Acc: 0.8032, F1: 0.8812 Bal: 0.7744 - Val Loss: 0.6529, Accuracy: 0.8028, F1: 0.8810 Bal: 0.7717\n","           WALLETS: Train Loss: 0.65453327, Acc: 0.91626391, F1: 0.95555102 Bal: 0.5924 - Val Loss: 0.65540767, Accuracy: 0.9154, F1: 0.9551 Bal: 0.5907\n","Epoch 006:      TX: Train Loss: 0.6399, Acc: 0.8222, F1: 0.8938 Bal: 0.7852 - Val Loss: 0.6412, Accuracy: 0.8260, F1: 0.8966 Bal: 0.7807\n","           WALLETS: Train Loss: 0.64463842, Acc: 0.91706579, F1: 0.95590814 Bal: 0.6038 - Val Loss: 0.64544988, Accuracy: 0.9160, F1: 0.9553 Bal: 0.6041\n","Epoch 007:      TX: Train Loss: 0.6267, Acc: 0.8330, F1: 0.9009 Bal: 0.7921 - Val Loss: 0.6283, Accuracy: 0.8333, F1: 0.9013 Bal: 0.7847\n","           WALLETS: Train Loss: 0.63428682, Acc: 0.91424653, F1: 0.95396141 Bal: 0.6480 - Val Loss: 0.63494188, Accuracy: 0.9147, F1: 0.9542 Bal: 0.6519\n","Epoch 008:      TX: Train Loss: 0.6122, Acc: 0.8374, F1: 0.9036 Bal: 0.7985 - Val Loss: 0.6142, Accuracy: 0.8366, F1: 0.9034 Bal: 0.7895\n","           WALLETS: Train Loss: 0.62362963, Acc: 0.90466394, F1: 0.94804221 Bal: 0.6966 - Val Loss: 0.62406921, Accuracy: 0.9049, F1: 0.9481 Bal: 0.6992\n","Epoch 009:      TX: Train Loss: 0.5965, Acc: 0.8358, F1: 0.9024 Bal: 0.8027 - Val Loss: 0.5990, Accuracy: 0.8357, F1: 0.9026 Bal: 0.7978\n","           WALLETS: Train Loss: 0.61279702, Acc: 0.88997620, F1: 0.93905329 Bal: 0.7328 - Val Loss: 0.61299628, Accuracy: 0.8910, F1: 0.9396 Bal: 0.7360\n","Epoch 010:      TX: Train Loss: 0.5796, Acc: 0.8301, F1: 0.8986 Bal: 0.8061 - Val Loss: 0.5828, Accuracy: 0.8322, F1: 0.9001 Bal: 0.8037\n","           WALLETS: Train Loss: 0.60185421, Acc: 0.87185600, F1: 0.92793875 Bal: 0.7491 - Val Loss: 0.60180598, Accuracy: 0.8738, F1: 0.9290 Bal: 0.7535\n","Epoch 011:      TX: Train Loss: 0.5618, Acc: 0.8250, F1: 0.8951 Bal: 0.8087 - Val Loss: 0.5655, Accuracy: 0.8276, F1: 0.8968 Bal: 0.8090\n","           WALLETS: Train Loss: 0.59070861, Acc: 0.85656957, F1: 0.91835276 Bal: 0.7594 - Val Loss: 0.59044707, Accuracy: 0.8587, F1: 0.9196 Bal: 0.7608\n","Epoch 012:      TX: Train Loss: 0.5429, Acc: 0.8217, F1: 0.8928 Bal: 0.8096 - Val Loss: 0.5472, Accuracy: 0.8225, F1: 0.8935 Bal: 0.8062\n","           WALLETS: Train Loss: 0.57925099, Acc: 0.84753124, F1: 0.91258100 Bal: 0.7650 - Val Loss: 0.57883728, Accuracy: 0.8505, F1: 0.9143 Bal: 0.7678\n","Epoch 013:      TX: Train Loss: 0.5233, Acc: 0.8215, F1: 0.8926 Bal: 0.8104 - Val Loss: 0.5281, Accuracy: 0.8234, F1: 0.8940 Bal: 0.8087\n","           WALLETS: Train Loss: 0.56745625, Acc: 0.84556465, F1: 0.91126404 Bal: 0.7691 - Val Loss: 0.56695080, Accuracy: 0.8486, F1: 0.9130 Bal: 0.7712\n","Epoch 014:      TX: Train Loss: 0.5030, Acc: 0.8246, F1: 0.8947 Bal: 0.8121 - Val Loss: 0.5084, Accuracy: 0.8265, F1: 0.8960 Bal: 0.8123\n","           WALLETS: Train Loss: 0.55544055, Acc: 0.84771992, F1: 0.91259609 Bal: 0.7712 - Val Loss: 0.55487680, Accuracy: 0.8511, F1: 0.9146 Bal: 0.7741\n","Epoch 015:      TX: Train Loss: 0.4823, Acc: 0.8294, F1: 0.8978 Bal: 0.8148 - Val Loss: 0.4883, Accuracy: 0.8326, F1: 0.9001 Bal: 0.8148\n","           WALLETS: Train Loss: 0.54344332, Acc: 0.85229169, F1: 0.91544273 Bal: 0.7736 - Val Loss: 0.54284704, Accuracy: 0.8548, F1: 0.9169 Bal: 0.7749\n","Epoch 016:      TX: Train Loss: 0.4618, Acc: 0.8347, F1: 0.9013 Bal: 0.8181 - Val Loss: 0.4683, Accuracy: 0.8390, F1: 0.9042 Bal: 0.8193\n","           WALLETS: Train Loss: 0.53174508, Acc: 0.85684533, F1: 0.91829203 Bal: 0.7742 - Val Loss: 0.53112358, Accuracy: 0.8590, F1: 0.9195 Bal: 0.7747\n","Epoch 017:      TX: Train Loss: 0.4416, Acc: 0.8386, F1: 0.9039 Bal: 0.8203 - Val Loss: 0.4486, Accuracy: 0.8451, F1: 0.9081 Bal: 0.8246\n","           WALLETS: Train Loss: 0.52050471, Acc: 0.86036850, F1: 0.92045105 Bal: 0.7769 - Val Loss: 0.51983827, Accuracy: 0.8619, F1: 0.9213 Bal: 0.7776\n","Epoch 018:      TX: Train Loss: 0.4222, Acc: 0.8405, F1: 0.9051 Bal: 0.8226 - Val Loss: 0.4296, Accuracy: 0.8469, F1: 0.9092 Bal: 0.8276\n","           WALLETS: Train Loss: 0.50979137, Acc: 0.86164207, F1: 0.92118394 Bal: 0.7808 - Val Loss: 0.50902480, Accuracy: 0.8632, F1: 0.9221 Bal: 0.7821\n","Epoch 019:      TX: Train Loss: 0.4040, Acc: 0.8405, F1: 0.9050 Bal: 0.8251 - Val Loss: 0.4115, Accuracy: 0.8469, F1: 0.9091 Bal: 0.8325\n","           WALLETS: Train Loss: 0.49972361, Acc: 0.86099984, F1: 0.92074191 Bal: 0.7836 - Val Loss: 0.49878100, Accuracy: 0.8619, F1: 0.9212 Bal: 0.7845\n","Epoch 020:      TX: Train Loss: 0.3871, Acc: 0.8422, F1: 0.9061 Bal: 0.8290 - Val Loss: 0.3946, Accuracy: 0.8471, F1: 0.9092 Bal: 0.8356\n","           WALLETS: Train Loss: 0.49054322, Acc: 0.85907679, F1: 0.91947245 Bal: 0.7880 - Val Loss: 0.48938221, Accuracy: 0.8600, F1: 0.9199 Bal: 0.7895\n","Epoch 021:      TX: Train Loss: 0.3717, Acc: 0.8445, F1: 0.9075 Bal: 0.8322 - Val Loss: 0.3792, Accuracy: 0.8488, F1: 0.9103 Bal: 0.8375\n","           WALLETS: Train Loss: 0.48244342, Acc: 0.85762906, F1: 0.91852507 Bal: 0.7905 - Val Loss: 0.48106429, Accuracy: 0.8592, F1: 0.9194 Bal: 0.7924\n","Epoch 022:      TX: Train Loss: 0.3579, Acc: 0.8479, F1: 0.9096 Bal: 0.8369 - Val Loss: 0.3652, Accuracy: 0.8526, F1: 0.9127 Bal: 0.8396\n","           WALLETS: Train Loss: 0.47542700, Acc: 0.85777783, F1: 0.91857960 Bal: 0.7930 - Val Loss: 0.47387215, Accuracy: 0.8590, F1: 0.9192 Bal: 0.7951\n","Epoch 023:      TX: Train Loss: 0.3456, Acc: 0.8523, F1: 0.9125 Bal: 0.8412 - Val Loss: 0.3527, Accuracy: 0.8554, F1: 0.9145 Bal: 0.8431\n","           WALLETS: Train Loss: 0.46940020, Acc: 0.86110869, F1: 0.92060819 Bal: 0.7967 - Val Loss: 0.46773061, Accuracy: 0.8620, F1: 0.9211 Bal: 0.7982\n","Epoch 024:      TX: Train Loss: 0.3349, Acc: 0.8565, F1: 0.9151 Bal: 0.8458 - Val Loss: 0.3415, Accuracy: 0.8591, F1: 0.9168 Bal: 0.8491\n","           WALLETS: Train Loss: 0.46434522, Acc: 0.86385176, F1: 0.92231022 Bal: 0.7974 - Val Loss: 0.46261728, Accuracy: 0.8643, F1: 0.9225 Bal: 0.7981\n","Epoch 025:      TX: Train Loss: 0.3255, Acc: 0.8599, F1: 0.9172 Bal: 0.8502 - Val Loss: 0.3316, Accuracy: 0.8633, F1: 0.9194 Bal: 0.8544\n","           WALLETS: Train Loss: 0.46026763, Acc: 0.86609411, F1: 0.92369750 Bal: 0.7979 - Val Loss: 0.45850405, Accuracy: 0.8665, F1: 0.9239 Bal: 0.7981\n","Epoch 026:      TX: Train Loss: 0.3174, Acc: 0.8623, F1: 0.9187 Bal: 0.8543 - Val Loss: 0.3227, Accuracy: 0.8651, F1: 0.9204 Bal: 0.8603\n","           WALLETS: Train Loss: 0.45704260, Acc: 0.86601065, F1: 0.92363084 Bal: 0.7990 - Val Loss: 0.45521721, Accuracy: 0.8664, F1: 0.9238 Bal: 0.7983\n","Epoch 027:      TX: Train Loss: 0.3104, Acc: 0.8649, F1: 0.9203 Bal: 0.8590 - Val Loss: 0.3148, Accuracy: 0.8686, F1: 0.9226 Bal: 0.8652\n","           WALLETS: Train Loss: 0.45439711, Acc: 0.86465363, F1: 0.92277626 Bal: 0.7997 - Val Loss: 0.45246586, Accuracy: 0.8652, F1: 0.9230 Bal: 0.7994\n","Epoch 028:      TX: Train Loss: 0.3043, Acc: 0.8670, F1: 0.9216 Bal: 0.8625 - Val Loss: 0.3080, Accuracy: 0.8714, F1: 0.9244 Bal: 0.8677\n","           WALLETS: Train Loss: 0.45219955, Acc: 0.86159490, F1: 0.92088119 Bal: 0.7988 - Val Loss: 0.45012477, Accuracy: 0.8621, F1: 0.9211 Bal: 0.7976\n","Epoch 029:      TX: Train Loss: 0.2991, Acc: 0.8712, F1: 0.9242 Bal: 0.8670 - Val Loss: 0.3019, Accuracy: 0.8745, F1: 0.9263 Bal: 0.8694\n","           WALLETS: Train Loss: 0.45036194, Acc: 0.85679816, F1: 0.91790314 Bal: 0.7969 - Val Loss: 0.44815862, Accuracy: 0.8570, F1: 0.9179 Bal: 0.7953\n","Epoch 030:      TX: Train Loss: 0.2947, Acc: 0.8741, F1: 0.9260 Bal: 0.8702 - Val Loss: 0.2966, Accuracy: 0.8771, F1: 0.9280 Bal: 0.8709\n","           WALLETS: Train Loss: 0.44865352, Acc: 0.85380473, F1: 0.91603104 Bal: 0.7960 - Val Loss: 0.44638282, Accuracy: 0.8537, F1: 0.9159 Bal: 0.7938\n","Epoch 031:      TX: Train Loss: 0.2909, Acc: 0.8768, F1: 0.9277 Bal: 0.8739 - Val Loss: 0.2920, Accuracy: 0.8800, F1: 0.9297 Bal: 0.8745\n","           WALLETS: Train Loss: 0.44686157, Acc: 0.85337296, F1: 0.91564012 Bal: 0.8032 - Val Loss: 0.44459733, Accuracy: 0.8534, F1: 0.9156 Bal: 0.8004\n","Epoch 032:      TX: Train Loss: 0.2875, Acc: 0.8790, F1: 0.9290 Bal: 0.8763 - Val Loss: 0.2878, Accuracy: 0.8817, F1: 0.9308 Bal: 0.8774\n","           WALLETS: Train Loss: 0.44491693, Acc: 0.85316251, F1: 0.91550704 Bal: 0.8032 - Val Loss: 0.44271672, Accuracy: 0.8536, F1: 0.9157 Bal: 0.8005\n","Epoch 033:      TX: Train Loss: 0.2844, Acc: 0.8809, F1: 0.9302 Bal: 0.8785 - Val Loss: 0.2842, Accuracy: 0.8813, F1: 0.9305 Bal: 0.8781\n","           WALLETS: Train Loss: 0.44279054, Acc: 0.85295932, F1: 0.91537917 Bal: 0.8031 - Val Loss: 0.44066906, Accuracy: 0.8532, F1: 0.9155 Bal: 0.8006\n","Epoch 034:      TX: Train Loss: 0.2815, Acc: 0.8825, F1: 0.9311 Bal: 0.8806 - Val Loss: 0.2809, Accuracy: 0.8835, F1: 0.9318 Bal: 0.8803\n","           WALLETS: Train Loss: 0.44042414, Acc: 0.85213567, F1: 0.91486197 Bal: 0.8028 - Val Loss: 0.43836641, Accuracy: 0.8523, F1: 0.9149 Bal: 0.8004\n","Epoch 035:      TX: Train Loss: 0.2786, Acc: 0.8843, F1: 0.9323 Bal: 0.8821 - Val Loss: 0.2779, Accuracy: 0.8864, F1: 0.9336 Bal: 0.8829\n","           WALLETS: Train Loss: 0.43785542, Acc: 0.85182363, F1: 0.91466340 Bal: 0.8029 - Val Loss: 0.43583938, Accuracy: 0.8521, F1: 0.9148 Bal: 0.8005\n","Epoch 036:      TX: Train Loss: 0.2757, Acc: 0.8856, F1: 0.9331 Bal: 0.8830 - Val Loss: 0.2752, Accuracy: 0.8866, F1: 0.9338 Bal: 0.8811\n","           WALLETS: Train Loss: 0.43520775, Acc: 0.85192523, F1: 0.91472690 Bal: 0.8029 - Val Loss: 0.43323594, Accuracy: 0.8521, F1: 0.9148 Bal: 0.8005\n","Epoch 037:      TX: Train Loss: 0.2727, Acc: 0.8865, F1: 0.9336 Bal: 0.8839 - Val Loss: 0.2725, Accuracy: 0.8864, F1: 0.9337 Bal: 0.8800\n","           WALLETS: Train Loss: 0.43255728, Acc: 0.85264728, F1: 0.91518046 Bal: 0.8032 - Val Loss: 0.43066463, Accuracy: 0.8529, F1: 0.9153 Bal: 0.8005\n","Epoch 038:      TX: Train Loss: 0.2696, Acc: 0.8878, F1: 0.9345 Bal: 0.8855 - Val Loss: 0.2700, Accuracy: 0.8866, F1: 0.9338 Bal: 0.8811\n","           WALLETS: Train Loss: 0.42996630, Acc: 0.85491865, F1: 0.91660114 Bal: 0.8042 - Val Loss: 0.42819992, Accuracy: 0.8551, F1: 0.9167 Bal: 0.8013\n","Epoch 039:      TX: Train Loss: 0.2665, Acc: 0.8888, F1: 0.9350 Bal: 0.8875 - Val Loss: 0.2676, Accuracy: 0.8857, F1: 0.9332 Bal: 0.8806\n","           WALLETS: Train Loss: 0.42754406, Acc: 0.85844908, F1: 0.91879673 Bal: 0.8060 - Val Loss: 0.42592102, Accuracy: 0.8585, F1: 0.9187 Bal: 0.8031\n","Epoch 040:      TX: Train Loss: 0.2633, Acc: 0.8900, F1: 0.9357 Bal: 0.8888 - Val Loss: 0.2653, Accuracy: 0.8866, F1: 0.9338 Bal: 0.8820\n","           WALLETS: Train Loss: 0.42533836, Acc: 0.86087647, F1: 0.92030421 Bal: 0.8070 - Val Loss: 0.42382702, Accuracy: 0.8609, F1: 0.9203 Bal: 0.8046\n","Epoch 041:      TX: Train Loss: 0.2601, Acc: 0.8915, F1: 0.9367 Bal: 0.8903 - Val Loss: 0.2631, Accuracy: 0.8888, F1: 0.9351 Bal: 0.8833\n","           WALLETS: Train Loss: 0.42333001, Acc: 0.86228066, F1: 0.92117330 Bal: 0.8077 - Val Loss: 0.42187053, Accuracy: 0.8622, F1: 0.9210 Bal: 0.8056\n","Epoch 042:      TX: Train Loss: 0.2570, Acc: 0.8921, F1: 0.9371 Bal: 0.8907 - Val Loss: 0.2611, Accuracy: 0.8903, F1: 0.9361 Bal: 0.8841\n","           WALLETS: Train Loss: 0.42152825, Acc: 0.86356149, F1: 0.92196621 Bal: 0.8082 - Val Loss: 0.42006528, Accuracy: 0.8635, F1: 0.9218 Bal: 0.8067\n","Epoch 043:      TX: Train Loss: 0.2539, Acc: 0.8921, F1: 0.9370 Bal: 0.8911 - Val Loss: 0.2592, Accuracy: 0.8914, F1: 0.9367 Bal: 0.8857\n","           WALLETS: Train Loss: 0.41991186, Acc: 0.86558250, F1: 0.92321722 Bal: 0.8089 - Val Loss: 0.41841871, Accuracy: 0.8653, F1: 0.9230 Bal: 0.8067\n","Epoch 044:      TX: Train Loss: 0.2510, Acc: 0.8928, F1: 0.9375 Bal: 0.8919 - Val Loss: 0.2574, Accuracy: 0.8916, F1: 0.9369 Bal: 0.8858\n","           WALLETS: Train Loss: 0.41840720, Acc: 0.86666376, F1: 0.92388693 Bal: 0.8092 - Val Loss: 0.41688210, Accuracy: 0.8662, F1: 0.9235 Bal: 0.8070\n","Epoch 045:      TX: Train Loss: 0.2482, Acc: 0.8941, F1: 0.9383 Bal: 0.8931 - Val Loss: 0.2557, Accuracy: 0.8925, F1: 0.9374 Bal: 0.8863\n","           WALLETS: Train Loss: 0.41698772, Acc: 0.86722254, F1: 0.92423163 Bal: 0.8093 - Val Loss: 0.41542450, Accuracy: 0.8670, F1: 0.9240 Bal: 0.8071\n","Epoch 046:      TX: Train Loss: 0.2455, Acc: 0.8953, F1: 0.9390 Bal: 0.8951 - Val Loss: 0.2542, Accuracy: 0.8945, F1: 0.9386 Bal: 0.8894\n","           WALLETS: Train Loss: 0.41561893, Acc: 0.86744387, F1: 0.92436342 Bal: 0.8097 - Val Loss: 0.41397941, Accuracy: 0.8673, F1: 0.9242 Bal: 0.8080\n","Epoch 047:      TX: Train Loss: 0.2429, Acc: 0.8962, F1: 0.9396 Bal: 0.8955 - Val Loss: 0.2527, Accuracy: 0.8960, F1: 0.9396 Bal: 0.8902\n","           WALLETS: Train Loss: 0.41425085, Acc: 0.86660208, F1: 0.92383642 Bal: 0.8100 - Val Loss: 0.41246590, Accuracy: 0.8670, F1: 0.9240 Bal: 0.8089\n","Epoch 048:      TX: Train Loss: 0.2404, Acc: 0.8969, F1: 0.9400 Bal: 0.8964 - Val Loss: 0.2512, Accuracy: 0.8971, F1: 0.9402 Bal: 0.8908\n","           WALLETS: Train Loss: 0.41287774, Acc: 0.86490036, F1: 0.92278020 Bal: 0.8097 - Val Loss: 0.41090003, Accuracy: 0.8650, F1: 0.9227 Bal: 0.8092\n","Epoch 049:      TX: Train Loss: 0.2380, Acc: 0.8979, F1: 0.9406 Bal: 0.8979 - Val Loss: 0.2496, Accuracy: 0.8969, F1: 0.9401 Bal: 0.8897\n","           WALLETS: Train Loss: 0.41150117, Acc: 0.86316236, F1: 0.92169862 Bal: 0.8094 - Val Loss: 0.40932229, Accuracy: 0.8641, F1: 0.9222 Bal: 0.8094\n","Epoch 050:      TX: Train Loss: 0.2355, Acc: 0.8994, F1: 0.9415 Bal: 0.8992 - Val Loss: 0.2480, Accuracy: 0.8984, F1: 0.9410 Bal: 0.8925\n","           WALLETS: Train Loss: 0.41011569, Acc: 0.86213190, F1: 0.92106865 Bal: 0.8085 - Val Loss: 0.40775508, Accuracy: 0.8629, F1: 0.9214 Bal: 0.8082\n","Epoch 051:      TX: Train Loss: 0.2331, Acc: 0.9010, F1: 0.9425 Bal: 0.9011 - Val Loss: 0.2464, Accuracy: 0.9004, F1: 0.9422 Bal: 0.8936\n","           WALLETS: Train Loss: 0.40874463, Acc: 0.86202668, F1: 0.92100759 Bal: 0.8082 - Val Loss: 0.40621617, Accuracy: 0.8630, F1: 0.9215 Bal: 0.8079\n","Epoch 052:      TX: Train Loss: 0.2306, Acc: 0.9028, F1: 0.9436 Bal: 0.9029 - Val Loss: 0.2446, Accuracy: 0.9019, F1: 0.9432 Bal: 0.8945\n","           WALLETS: Train Loss: 0.40738937, Acc: 0.86166746, F1: 0.92078334 Bal: 0.8081 - Val Loss: 0.40468606, Accuracy: 0.8624, F1: 0.9211 Bal: 0.8075\n","Epoch 053:      TX: Train Loss: 0.2282, Acc: 0.9041, F1: 0.9444 Bal: 0.9048 - Val Loss: 0.2427, Accuracy: 0.9032, F1: 0.9440 Bal: 0.8942\n","           WALLETS: Train Loss: 0.40604296, Acc: 0.86096718, F1: 0.92034375 Bal: 0.8082 - Val Loss: 0.40315041, Accuracy: 0.8613, F1: 0.9205 Bal: 0.8075\n","Epoch 054:      TX: Train Loss: 0.2257, Acc: 0.9056, F1: 0.9452 Bal: 0.9059 - Val Loss: 0.2407, Accuracy: 0.9050, F1: 0.9451 Bal: 0.8952\n","           WALLETS: Train Loss: 0.40472886, Acc: 0.86070594, F1: 0.92017682 Bal: 0.8084 - Val Loss: 0.40166393, Accuracy: 0.8611, F1: 0.9203 Bal: 0.8077\n","Epoch 055:      TX: Train Loss: 0.2231, Acc: 0.9070, F1: 0.9461 Bal: 0.9070 - Val Loss: 0.2386, Accuracy: 0.9074, F1: 0.9465 Bal: 0.8975\n","           WALLETS: Train Loss: 0.40344036, Acc: 0.86144613, F1: 0.92063433 Bal: 0.8088 - Val Loss: 0.40024945, Accuracy: 0.8619, F1: 0.9208 Bal: 0.8083\n","Epoch 056:      TX: Train Loss: 0.2206, Acc: 0.9090, F1: 0.9473 Bal: 0.9074 - Val Loss: 0.2366, Accuracy: 0.9087, F1: 0.9473 Bal: 0.8983\n","           WALLETS: Train Loss: 0.40218377, Acc: 0.86340184, F1: 0.92185512 Bal: 0.8090 - Val Loss: 0.39891663, Accuracy: 0.8638, F1: 0.9220 Bal: 0.8087\n","Epoch 057:      TX: Train Loss: 0.2181, Acc: 0.9112, F1: 0.9487 Bal: 0.9088 - Val Loss: 0.2345, Accuracy: 0.9105, F1: 0.9484 Bal: 0.8992\n","           WALLETS: Train Loss: 0.40096539, Acc: 0.86483868, F1: 0.92274638 Bal: 0.8094 - Val Loss: 0.39763963, Accuracy: 0.8652, F1: 0.9228 Bal: 0.8093\n","Epoch 058:      TX: Train Loss: 0.2155, Acc: 0.9130, F1: 0.9497 Bal: 0.9103 - Val Loss: 0.2324, Accuracy: 0.9136, F1: 0.9502 Bal: 0.9019\n","           WALLETS: Train Loss: 0.39977881, Acc: 0.86561153, F1: 0.92321948 Bal: 0.8100 - Val Loss: 0.39639911, Accuracy: 0.8654, F1: 0.9230 Bal: 0.8090\n","Epoch 059:      TX: Train Loss: 0.2130, Acc: 0.9153, F1: 0.9512 Bal: 0.9118 - Val Loss: 0.2304, Accuracy: 0.9147, F1: 0.9509 Bal: 0.9025\n","           WALLETS: Train Loss: 0.39862877, Acc: 0.86631907, F1: 0.92365079 Bal: 0.8106 - Val Loss: 0.39521569, Accuracy: 0.8659, F1: 0.9233 Bal: 0.8091\n","Epoch 060:      TX: Train Loss: 0.2104, Acc: 0.9167, F1: 0.9520 Bal: 0.9129 - Val Loss: 0.2284, Accuracy: 0.9179, F1: 0.9529 Bal: 0.9024\n","           WALLETS: Train Loss: 0.39750588, Acc: 0.86730599, F1: 0.92425777 Bal: 0.8111 - Val Loss: 0.39409870, Accuracy: 0.8671, F1: 0.9240 Bal: 0.8097\n","Epoch 061:      TX: Train Loss: 0.2079, Acc: 0.9188, F1: 0.9533 Bal: 0.9144 - Val Loss: 0.2265, Accuracy: 0.9190, F1: 0.9536 Bal: 0.9030\n","           WALLETS: Train Loss: 0.39640144, Acc: 0.86884080, F1: 0.92520650 Bal: 0.8114 - Val Loss: 0.39303762, Accuracy: 0.8689, F1: 0.9251 Bal: 0.8105\n","Epoch 062:      TX: Train Loss: 0.2054, Acc: 0.9201, F1: 0.9541 Bal: 0.9154 - Val Loss: 0.2247, Accuracy: 0.9206, F1: 0.9545 Bal: 0.9019\n","           WALLETS: Train Loss: 0.39530382, Acc: 0.86991118, F1: 0.92586826 Bal: 0.8116 - Val Loss: 0.39198428, Accuracy: 0.8698, F1: 0.9257 Bal: 0.8110\n","Epoch 063:      TX: Train Loss: 0.2028, Acc: 0.9222, F1: 0.9553 Bal: 0.9171 - Val Loss: 0.2229, Accuracy: 0.9212, F1: 0.9549 Bal: 0.9032\n","           WALLETS: Train Loss: 0.39419392, Acc: 0.87027402, F1: 0.92608970 Bal: 0.8118 - Val Loss: 0.39090362, Accuracy: 0.8699, F1: 0.9258 Bal: 0.8110\n","Epoch 064:      TX: Train Loss: 0.2003, Acc: 0.9237, F1: 0.9562 Bal: 0.9178 - Val Loss: 0.2211, Accuracy: 0.9223, F1: 0.9555 Bal: 0.9039\n","           WALLETS: Train Loss: 0.39306858, Acc: 0.87061871, F1: 0.92629721 Bal: 0.8123 - Val Loss: 0.38980454, Accuracy: 0.8699, F1: 0.9258 Bal: 0.8110\n","Epoch 065:      TX: Train Loss: 0.1977, Acc: 0.9251, F1: 0.9570 Bal: 0.9191 - Val Loss: 0.2195, Accuracy: 0.9232, F1: 0.9561 Bal: 0.9043\n","           WALLETS: Train Loss: 0.39193130, Acc: 0.87117749, F1: 0.92663978 Bal: 0.8125 - Val Loss: 0.38871065, Accuracy: 0.8707, F1: 0.9263 Bal: 0.8118\n","Epoch 066:      TX: Train Loss: 0.1951, Acc: 0.9261, F1: 0.9576 Bal: 0.9203 - Val Loss: 0.2178, Accuracy: 0.9241, F1: 0.9566 Bal: 0.9048\n","           WALLETS: Train Loss: 0.39077824, Acc: 0.87188502, F1: 0.92707329 Bal: 0.8128 - Val Loss: 0.38760558, Accuracy: 0.8712, F1: 0.9265 Bal: 0.8118\n","Epoch 067:      TX: Train Loss: 0.1925, Acc: 0.9272, F1: 0.9583 Bal: 0.9209 - Val Loss: 0.2161, Accuracy: 0.9250, F1: 0.9571 Bal: 0.9063\n","           WALLETS: Train Loss: 0.38960943, Acc: 0.87203742, F1: 0.92716485 Bal: 0.8130 - Val Loss: 0.38647148, Accuracy: 0.8711, F1: 0.9265 Bal: 0.8117\n","Epoch 068:      TX: Train Loss: 0.1899, Acc: 0.9287, F1: 0.9592 Bal: 0.9224 - Val Loss: 0.2146, Accuracy: 0.9256, F1: 0.9575 Bal: 0.9067\n","           WALLETS: Train Loss: 0.38843560, Acc: 0.87142422, F1: 0.92678573 Bal: 0.8130 - Val Loss: 0.38532510, Accuracy: 0.8703, F1: 0.9260 Bal: 0.8118\n","Epoch 069:      TX: Train Loss: 0.1873, Acc: 0.9299, F1: 0.9599 Bal: 0.9237 - Val Loss: 0.2131, Accuracy: 0.9263, F1: 0.9579 Bal: 0.9070\n","           WALLETS: Train Loss: 0.38726941, Acc: 0.87118111, F1: 0.92662502 Bal: 0.8137 - Val Loss: 0.38419458, Accuracy: 0.8700, F1: 0.9258 Bal: 0.8111\n","Epoch 070:      TX: Train Loss: 0.1847, Acc: 0.9310, F1: 0.9605 Bal: 0.9254 - Val Loss: 0.2115, Accuracy: 0.9272, F1: 0.9584 Bal: 0.9075\n","           WALLETS: Train Loss: 0.38611165, Acc: 0.87116660, F1: 0.92661007 Bal: 0.8141 - Val Loss: 0.38308334, Accuracy: 0.8702, F1: 0.9260 Bal: 0.8122\n","Epoch 071:      TX: Train Loss: 0.1821, Acc: 0.9322, F1: 0.9612 Bal: 0.9275 - Val Loss: 0.2100, Accuracy: 0.9287, F1: 0.9593 Bal: 0.9094\n","           WALLETS: Train Loss: 0.38496512, Acc: 0.87105412, F1: 0.92653583 Bal: 0.8144 - Val Loss: 0.38197118, Accuracy: 0.8700, F1: 0.9258 Bal: 0.8126\n","Epoch 072:      TX: Train Loss: 0.1794, Acc: 0.9329, F1: 0.9616 Bal: 0.9281 - Val Loss: 0.2086, Accuracy: 0.9291, F1: 0.9596 Bal: 0.9096\n","           WALLETS: Train Loss: 0.38381746, Acc: 0.87071668, F1: 0.92631784 Bal: 0.8151 - Val Loss: 0.38083819, Accuracy: 0.8701, F1: 0.9258 Bal: 0.8137\n","Epoch 073:      TX: Train Loss: 0.1768, Acc: 0.9340, F1: 0.9623 Bal: 0.9287 - Val Loss: 0.2071, Accuracy: 0.9307, F1: 0.9605 Bal: 0.9114\n","           WALLETS: Train Loss: 0.38265544, Acc: 0.87058969, F1: 0.92622852 Bal: 0.8158 - Val Loss: 0.37968194, Accuracy: 0.8699, F1: 0.9257 Bal: 0.8147\n","Epoch 074:      TX: Train Loss: 0.1742, Acc: 0.9348, F1: 0.9627 Bal: 0.9294 - Val Loss: 0.2057, Accuracy: 0.9318, F1: 0.9611 Bal: 0.9120\n","           WALLETS: Train Loss: 0.38147357, Acc: 0.87103961, F1: 0.92649899 Bal: 0.8164 - Val Loss: 0.37851739, Accuracy: 0.8704, F1: 0.9260 Bal: 0.8150\n","Epoch 075:      TX: Train Loss: 0.1716, Acc: 0.9365, F1: 0.9637 Bal: 0.9317 - Val Loss: 0.2043, Accuracy: 0.9337, F1: 0.9623 Bal: 0.9131\n","           WALLETS: Train Loss: 0.38027585, Acc: 0.87151856, F1: 0.92679014 Bal: 0.8168 - Val Loss: 0.37733862, Accuracy: 0.8708, F1: 0.9263 Bal: 0.8152\n","Epoch 076:      TX: Train Loss: 0.1690, Acc: 0.9376, F1: 0.9644 Bal: 0.9323 - Val Loss: 0.2030, Accuracy: 0.9344, F1: 0.9627 Bal: 0.9155\n","           WALLETS: Train Loss: 0.37906402, Acc: 0.87187414, F1: 0.92699698 Bal: 0.8177 - Val Loss: 0.37613797, Accuracy: 0.8711, F1: 0.9265 Bal: 0.8160\n","Epoch 077:      TX: Train Loss: 0.1665, Acc: 0.9390, F1: 0.9652 Bal: 0.9337 - Val Loss: 0.2017, Accuracy: 0.9348, F1: 0.9629 Bal: 0.9147\n","           WALLETS: Train Loss: 0.37784222, Acc: 0.87211361, F1: 0.92713583 Bal: 0.8184 - Val Loss: 0.37493220, Accuracy: 0.8714, F1: 0.9266 Bal: 0.8164\n","Epoch 078:      TX: Train Loss: 0.1639, Acc: 0.9401, F1: 0.9659 Bal: 0.9352 - Val Loss: 0.2005, Accuracy: 0.9355, F1: 0.9633 Bal: 0.9141\n","           WALLETS: Train Loss: 0.37662816, Acc: 0.87280664, F1: 0.92755899 Bal: 0.8188 - Val Loss: 0.37375087, Accuracy: 0.8719, F1: 0.9269 Bal: 0.8169\n","Epoch 079:      TX: Train Loss: 0.1614, Acc: 0.9408, F1: 0.9663 Bal: 0.9363 - Val Loss: 0.1994, Accuracy: 0.9373, F1: 0.9644 Bal: 0.9151\n","           WALLETS: Train Loss: 0.37541729, Acc: 0.87344160, F1: 0.92794788 Bal: 0.8191 - Val Loss: 0.37257931, Accuracy: 0.8725, F1: 0.9273 Bal: 0.8180\n","Epoch 080:      TX: Train Loss: 0.1589, Acc: 0.9419, F1: 0.9669 Bal: 0.9375 - Val Loss: 0.1983, Accuracy: 0.9386, F1: 0.9651 Bal: 0.9158\n","           WALLETS: Train Loss: 0.37420380, Acc: 0.87365568, F1: 0.92807258 Bal: 0.8196 - Val Loss: 0.37138921, Accuracy: 0.8727, F1: 0.9274 Bal: 0.8183\n","Epoch 081:      TX: Train Loss: 0.1564, Acc: 0.9427, F1: 0.9674 Bal: 0.9390 - Val Loss: 0.1973, Accuracy: 0.9397, F1: 0.9658 Bal: 0.9164\n","           WALLETS: Train Loss: 0.37297931, Acc: 0.87372099, F1: 0.92810352 Bal: 0.8203 - Val Loss: 0.37018901, Accuracy: 0.8728, F1: 0.9275 Bal: 0.8191\n","Epoch 082:      TX: Train Loss: 0.1539, Acc: 0.9437, F1: 0.9680 Bal: 0.9408 - Val Loss: 0.1963, Accuracy: 0.9414, F1: 0.9668 Bal: 0.9194\n","           WALLETS: Train Loss: 0.37174106, Acc: 0.87401852, F1: 0.92828122 Bal: 0.8207 - Val Loss: 0.36899063, Accuracy: 0.8731, F1: 0.9276 Bal: 0.8194\n","Epoch 083:      TX: Train Loss: 0.1514, Acc: 0.9446, F1: 0.9685 Bal: 0.9414 - Val Loss: 0.1953, Accuracy: 0.9423, F1: 0.9673 Bal: 0.9208\n","           WALLETS: Train Loss: 0.37049434, Acc: 0.87408020, F1: 0.92831056 Bal: 0.8214 - Val Loss: 0.36777908, Accuracy: 0.8731, F1: 0.9276 Bal: 0.8197\n","Epoch 084:      TX: Train Loss: 0.1489, Acc: 0.9454, F1: 0.9689 Bal: 0.9422 - Val Loss: 0.1944, Accuracy: 0.9430, F1: 0.9677 Bal: 0.9212\n","           WALLETS: Train Loss: 0.36924168, Acc: 0.87357586, F1: 0.92798905 Bal: 0.8221 - Val Loss: 0.36655399, Accuracy: 0.8727, F1: 0.9274 Bal: 0.8203\n","Epoch 085:      TX: Train Loss: 0.1465, Acc: 0.9465, F1: 0.9696 Bal: 0.9440 - Val Loss: 0.1935, Accuracy: 0.9432, F1: 0.9678 Bal: 0.9213\n","           WALLETS: Train Loss: 0.36798215, Acc: 0.87341258, F1: 0.92787861 Bal: 0.8228 - Val Loss: 0.36533177, Accuracy: 0.8725, F1: 0.9272 Bal: 0.8210\n","Epoch 086:      TX: Train Loss: 0.1441, Acc: 0.9476, F1: 0.9702 Bal: 0.9455 - Val Loss: 0.1926, Accuracy: 0.9434, F1: 0.9679 Bal: 0.9214\n","           WALLETS: Train Loss: 0.36672491, Acc: 0.87341621, F1: 0.92786890 Bal: 0.8236 - Val Loss: 0.36411640, Accuracy: 0.8723, F1: 0.9271 Bal: 0.8213\n","Epoch 087:      TX: Train Loss: 0.1417, Acc: 0.9491, F1: 0.9711 Bal: 0.9466 - Val Loss: 0.1918, Accuracy: 0.9438, F1: 0.9682 Bal: 0.9217\n","           WALLETS: Train Loss: 0.36547244, Acc: 0.87276672, F1: 0.92745246 Bal: 0.8247 - Val Loss: 0.36289397, Accuracy: 0.8717, F1: 0.9267 Bal: 0.8234\n","Epoch 088:      TX: Train Loss: 0.1394, Acc: 0.9500, F1: 0.9716 Bal: 0.9477 - Val Loss: 0.1910, Accuracy: 0.9438, F1: 0.9682 Bal: 0.9207\n","           WALLETS: Train Loss: 0.36422372, Acc: 0.87270141, F1: 0.92739509 Bal: 0.8259 - Val Loss: 0.36167857, Accuracy: 0.8718, F1: 0.9267 Bal: 0.8244\n","Epoch 089:      TX: Train Loss: 0.1370, Acc: 0.9511, F1: 0.9722 Bal: 0.9485 - Val Loss: 0.1902, Accuracy: 0.9449, F1: 0.9688 Bal: 0.9213\n","           WALLETS: Train Loss: 0.36297378, Acc: 0.87294451, F1: 0.92752879 Bal: 0.8271 - Val Loss: 0.36047757, Accuracy: 0.8722, F1: 0.9270 Bal: 0.8262\n","Epoch 090:      TX: Train Loss: 0.1347, Acc: 0.9521, F1: 0.9728 Bal: 0.9501 - Val Loss: 0.1896, Accuracy: 0.9456, F1: 0.9692 Bal: 0.9197\n","           WALLETS: Train Loss: 0.36172199, Acc: 0.87310054, F1: 0.92761074 Bal: 0.8281 - Val Loss: 0.35926145, Accuracy: 0.8725, F1: 0.9271 Bal: 0.8279\n","Epoch 091:      TX: Train Loss: 0.1325, Acc: 0.9530, F1: 0.9733 Bal: 0.9525 - Val Loss: 0.1889, Accuracy: 0.9458, F1: 0.9694 Bal: 0.9198\n","           WALLETS: Train Loss: 0.36047649, Acc: 0.87315496, F1: 0.92763415 Bal: 0.8289 - Val Loss: 0.35805383, Accuracy: 0.8726, F1: 0.9272 Bal: 0.8289\n","Epoch 092:      TX: Train Loss: 0.1303, Acc: 0.9535, F1: 0.9736 Bal: 0.9530 - Val Loss: 0.1884, Accuracy: 0.9462, F1: 0.9696 Bal: 0.9201\n","           WALLETS: Train Loss: 0.35923055, Acc: 0.87358311, F1: 0.92789155 Bal: 0.8294 - Val Loss: 0.35685602, Accuracy: 0.8727, F1: 0.9272 Bal: 0.8289\n","Epoch 093:      TX: Train Loss: 0.1281, Acc: 0.9543, F1: 0.9741 Bal: 0.9541 - Val Loss: 0.1880, Accuracy: 0.9462, F1: 0.9696 Bal: 0.9201\n","           WALLETS: Train Loss: 0.35798186, Acc: 0.87374639, F1: 0.92798126 Bal: 0.8302 - Val Loss: 0.35563856, Accuracy: 0.8730, F1: 0.9274 Bal: 0.8295\n","Epoch 094:      TX: Train Loss: 0.1259, Acc: 0.9555, F1: 0.9748 Bal: 0.9560 - Val Loss: 0.1876, Accuracy: 0.9465, F1: 0.9698 Bal: 0.9202\n","           WALLETS: Train Loss: 0.35673657, Acc: 0.87398224, F1: 0.92812010 Bal: 0.8307 - Val Loss: 0.35442704, Accuracy: 0.8735, F1: 0.9277 Bal: 0.8298\n","Epoch 095:      TX: Train Loss: 0.1238, Acc: 0.9563, F1: 0.9752 Bal: 0.9567 - Val Loss: 0.1874, Accuracy: 0.9469, F1: 0.9700 Bal: 0.9204\n","           WALLETS: Train Loss: 0.35549891, Acc: 0.87423622, F1: 0.92827062 Bal: 0.8312 - Val Loss: 0.35322073, Accuracy: 0.8739, F1: 0.9280 Bal: 0.8312\n","Epoch 096:      TX: Train Loss: 0.1217, Acc: 0.9571, F1: 0.9757 Bal: 0.9578 - Val Loss: 0.1871, Accuracy: 0.9476, F1: 0.9704 Bal: 0.9208\n","           WALLETS: Train Loss: 0.35427311, Acc: 0.87416003, F1: 0.92821216 Bal: 0.8320 - Val Loss: 0.35201389, Accuracy: 0.8739, F1: 0.9279 Bal: 0.8324\n","Epoch 097:      TX: Train Loss: 0.1197, Acc: 0.9580, F1: 0.9762 Bal: 0.9596 - Val Loss: 0.1868, Accuracy: 0.9478, F1: 0.9705 Bal: 0.9209\n","           WALLETS: Train Loss: 0.35305864, Acc: 0.87464260, F1: 0.92849914 Bal: 0.8329 - Val Loss: 0.35084969, Accuracy: 0.8742, F1: 0.9281 Bal: 0.8334\n","Epoch 098:      TX: Train Loss: 0.1177, Acc: 0.9586, F1: 0.9766 Bal: 0.9604 - Val Loss: 0.1867, Accuracy: 0.9482, F1: 0.9708 Bal: 0.9212\n","           WALLETS: Train Loss: 0.35185349, Acc: 0.87450472, F1: 0.92840509 Bal: 0.8335 - Val Loss: 0.34969050, Accuracy: 0.8742, F1: 0.9281 Bal: 0.8340\n","Epoch 099:      TX: Train Loss: 0.1157, Acc: 0.9594, F1: 0.9770 Bal: 0.9618 - Val Loss: 0.1864, Accuracy: 0.9484, F1: 0.9709 Bal: 0.9223\n","           WALLETS: Train Loss: 0.35065940, Acc: 0.87453738, F1: 0.92841527 Bal: 0.8342 - Val Loss: 0.34854904, Accuracy: 0.8740, F1: 0.9280 Bal: 0.8347\n","Epoch 100:      TX: Train Loss: 0.1138, Acc: 0.9602, F1: 0.9775 Bal: 0.9628 - Val Loss: 0.1865, Accuracy: 0.9487, F1: 0.9710 Bal: 0.9214\n","           WALLETS: Train Loss: 0.34947318, Acc: 0.87491110, F1: 0.92863397 Bal: 0.8352 - Val Loss: 0.34744450, Accuracy: 0.8743, F1: 0.9281 Bal: 0.8353\n","Epoch 101:      TX: Train Loss: 0.1119, Acc: 0.9604, F1: 0.9776 Bal: 0.9631 - Val Loss: 0.1863, Accuracy: 0.9480, F1: 0.9707 Bal: 0.9211\n","           WALLETS: Train Loss: 0.34829438, Acc: 0.87469340, F1: 0.92848075 Bal: 0.8365 - Val Loss: 0.34631851, Accuracy: 0.8740, F1: 0.9280 Bal: 0.8363\n","Epoch 102:      TX: Train Loss: 0.1100, Acc: 0.9614, F1: 0.9782 Bal: 0.9640 - Val Loss: 0.1866, Accuracy: 0.9484, F1: 0.9709 Bal: 0.9213\n","           WALLETS: Train Loss: 0.34712088, Acc: 0.87544811, F1: 0.92893623 Bal: 0.8373 - Val Loss: 0.34524372, Accuracy: 0.8746, F1: 0.9283 Bal: 0.8364\n","Epoch 103:      TX: Train Loss: 0.1082, Acc: 0.9617, F1: 0.9783 Bal: 0.9644 - Val Loss: 0.1864, Accuracy: 0.9484, F1: 0.9709 Bal: 0.9203\n","           WALLETS: Train Loss: 0.34595233, Acc: 0.87512881, F1: 0.92871686 Bal: 0.8389 - Val Loss: 0.34412491, Accuracy: 0.8744, F1: 0.9282 Bal: 0.8378\n","Epoch 104:      TX: Train Loss: 0.1065, Acc: 0.9629, F1: 0.9790 Bal: 0.9652 - Val Loss: 0.1870, Accuracy: 0.9487, F1: 0.9710 Bal: 0.9204\n","           WALLETS: Train Loss: 0.34478560, Acc: 0.87551342, F1: 0.92894849 Bal: 0.8394 - Val Loss: 0.34305638, Accuracy: 0.8749, F1: 0.9285 Bal: 0.8396\n","Epoch 105:      TX: Train Loss: 0.1047, Acc: 0.9630, F1: 0.9791 Bal: 0.9658 - Val Loss: 0.1867, Accuracy: 0.9491, F1: 0.9713 Bal: 0.9217\n","           WALLETS: Train Loss: 0.34361896, Acc: 0.87471154, F1: 0.92843227 Bal: 0.8408 - Val Loss: 0.34194767, Accuracy: 0.8742, F1: 0.9280 Bal: 0.8408\n","Epoch 106:      TX: Train Loss: 0.1030, Acc: 0.9645, F1: 0.9799 Bal: 0.9669 - Val Loss: 0.1878, Accuracy: 0.9502, F1: 0.9719 Bal: 0.9213\n","           WALLETS: Train Loss: 0.34245282, Acc: 0.87557147, F1: 0.92895661 Bal: 0.8414 - Val Loss: 0.34090889, Accuracy: 0.8750, F1: 0.9285 Bal: 0.8417\n","Epoch 107:      TX: Train Loss: 0.1014, Acc: 0.9642, F1: 0.9798 Bal: 0.9675 - Val Loss: 0.1871, Accuracy: 0.9502, F1: 0.9719 Bal: 0.9223\n","           WALLETS: Train Loss: 0.34130457, Acc: 0.87421082, F1: 0.92809170 Bal: 0.8430 - Val Loss: 0.33978781, Accuracy: 0.8738, F1: 0.9277 Bal: 0.8426\n","Epoch 108:      TX: Train Loss: 0.0998, Acc: 0.9666, F1: 0.9811 Bal: 0.9688 - Val Loss: 0.1895, Accuracy: 0.9517, F1: 0.9728 Bal: 0.9221\n","           WALLETS: Train Loss: 0.34017959, Acc: 0.87640963, F1: 0.92945548 Bal: 0.8429 - Val Loss: 0.33887762, Accuracy: 0.8757, F1: 0.9289 Bal: 0.8426\n","Epoch 109:      TX: Train Loss: 0.0982, Acc: 0.9647, F1: 0.9801 Bal: 0.9691 - Val Loss: 0.1870, Accuracy: 0.9500, F1: 0.9718 Bal: 0.9231\n","           WALLETS: Train Loss: 0.33911571, Acc: 0.87194671, F1: 0.92664860 Bal: 0.8456 - Val Loss: 0.33767977, Accuracy: 0.8721, F1: 0.9267 Bal: 0.8456\n","Epoch 110:      TX: Train Loss: 0.0967, Acc: 0.9688, F1: 0.9824 Bal: 0.9704 - Val Loss: 0.1918, Accuracy: 0.9544, F1: 0.9743 Bal: 0.9236\n","           WALLETS: Train Loss: 0.33821264, Acc: 0.87960625, F1: 0.93143784 Bal: 0.8421 - Val Loss: 0.33731088, Accuracy: 0.8792, F1: 0.9311 Bal: 0.8424\n","Epoch 111:      TX: Train Loss: 0.0952, Acc: 0.9653, F1: 0.9804 Bal: 0.9699 - Val Loss: 0.1870, Accuracy: 0.9504, F1: 0.9720 Bal: 0.9234\n","           WALLETS: Train Loss: 0.33743751, Acc: 0.86740396, F1: 0.92375707 Bal: 0.8493 - Val Loss: 0.33598268, Accuracy: 0.8680, F1: 0.9240 Bal: 0.8503\n","Epoch 112:      TX: Train Loss: 0.0937, Acc: 0.9695, F1: 0.9828 Bal: 0.9715 - Val Loss: 0.1918, Accuracy: 0.9552, F1: 0.9748 Bal: 0.9241\n","           WALLETS: Train Loss: 0.33625698, Acc: 0.88121000, F1: 0.93241483 Bal: 0.8428 - Val Loss: 0.33565289, Accuracy: 0.8805, F1: 0.9319 Bal: 0.8422\n","Epoch 113:      TX: Train Loss: 0.0921, Acc: 0.9685, F1: 0.9822 Bal: 0.9718 - Val Loss: 0.1903, Accuracy: 0.9541, F1: 0.9742 Bal: 0.9235\n","           WALLETS: Train Loss: 0.33471796, Acc: 0.87284655, F1: 0.92716768 Bal: 0.8484 - Val Loss: 0.33375895, Accuracy: 0.8730, F1: 0.9272 Bal: 0.8483\n","Epoch 114:      TX: Train Loss: 0.0908, Acc: 0.9680, F1: 0.9819 Bal: 0.9727 - Val Loss: 0.1895, Accuracy: 0.9524, F1: 0.9732 Bal: 0.9225\n","           WALLETS: Train Loss: 0.33378997, Acc: 0.87126820, F1: 0.92616402 Bal: 0.8499 - Val Loss: 0.33285367, Accuracy: 0.8719, F1: 0.9264 Bal: 0.8510\n","Epoch 115:      TX: Train Loss: 0.0894, Acc: 0.9710, F1: 0.9837 Bal: 0.9739 - Val Loss: 0.1941, Accuracy: 0.9577, F1: 0.9762 Bal: 0.9254\n","           WALLETS: Train Loss: 0.33308253, Acc: 0.88091247, F1: 0.93220188 Bal: 0.8451 - Val Loss: 0.33279020, Accuracy: 0.8807, F1: 0.9320 Bal: 0.8453\n","Epoch 116:      TX: Train Loss: 0.0881, Acc: 0.9688, F1: 0.9824 Bal: 0.9738 - Val Loss: 0.1904, Accuracy: 0.9537, F1: 0.9740 Bal: 0.9232\n","           WALLETS: Train Loss: 0.33179873, Acc: 0.87102147, F1: 0.92598708 Bal: 0.8515 - Val Loss: 0.33104274, Accuracy: 0.8711, F1: 0.9259 Bal: 0.8517\n","Epoch 117:      TX: Train Loss: 0.0867, Acc: 0.9706, F1: 0.9835 Bal: 0.9746 - Val Loss: 0.1935, Accuracy: 0.9572, F1: 0.9760 Bal: 0.9252\n","           WALLETS: Train Loss: 0.33061504, Acc: 0.87390967, F1: 0.92779448 Bal: 0.8509 - Val Loss: 0.33011988, Accuracy: 0.8742, F1: 0.9279 Bal: 0.8510\n","Epoch 118:      TX: Train Loss: 0.0854, Acc: 0.9715, F1: 0.9840 Bal: 0.9752 - Val Loss: 0.1947, Accuracy: 0.9579, F1: 0.9764 Bal: 0.9256\n","           WALLETS: Train Loss: 0.32991529, Acc: 0.88005980, F1: 0.93163581 Bal: 0.8483 - Val Loss: 0.32987064, Accuracy: 0.8802, F1: 0.9316 Bal: 0.8494\n","Epoch 119:      TX: Train Loss: 0.0842, Acc: 0.9702, F1: 0.9832 Bal: 0.9751 - Val Loss: 0.1924, Accuracy: 0.9546, F1: 0.9745 Bal: 0.9237\n","           WALLETS: Train Loss: 0.32891199, Acc: 0.87075659, F1: 0.92578981 Bal: 0.8537 - Val Loss: 0.32843161, Accuracy: 0.8707, F1: 0.9257 Bal: 0.8532\n","Epoch 120:      TX: Train Loss: 0.0830, Acc: 0.9726, F1: 0.9846 Bal: 0.9759 - Val Loss: 0.1968, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9237\n","           WALLETS: Train Loss: 0.32768682, Acc: 0.87614476, F1: 0.92916624 Bal: 0.8520 - Val Loss: 0.32762769, Accuracy: 0.8762, F1: 0.9291 Bal: 0.8519\n","Epoch 121:      TX: Train Loss: 0.0817, Acc: 0.9716, F1: 0.9840 Bal: 0.9757 - Val Loss: 0.1949, Accuracy: 0.9566, F1: 0.9756 Bal: 0.9248\n","           WALLETS: Train Loss: 0.32687497, Acc: 0.87894225, F1: 0.93090480 Bal: 0.8514 - Val Loss: 0.32709670, Accuracy: 0.8788, F1: 0.9307 Bal: 0.8519\n","Epoch 122:      TX: Train Loss: 0.0805, Acc: 0.9721, F1: 0.9843 Bal: 0.9766 - Val Loss: 0.1958, Accuracy: 0.9570, F1: 0.9759 Bal: 0.9251\n","           WALLETS: Train Loss: 0.32607815, Acc: 0.87094890, F1: 0.92588742 Bal: 0.8553 - Val Loss: 0.32595938, Accuracy: 0.8707, F1: 0.9256 Bal: 0.8538\n","Epoch 123:      TX: Train Loss: 0.0794, Acc: 0.9738, F1: 0.9852 Bal: 0.9774 - Val Loss: 0.1984, Accuracy: 0.9583, F1: 0.9766 Bal: 0.9238\n","           WALLETS: Train Loss: 0.32494044, Acc: 0.87927969, F1: 0.93108441 Bal: 0.8536 - Val Loss: 0.32539234, Accuracy: 0.8790, F1: 0.9308 Bal: 0.8532\n","Epoch 124:      TX: Train Loss: 0.0783, Acc: 0.9726, F1: 0.9845 Bal: 0.9777 - Val Loss: 0.1960, Accuracy: 0.9566, F1: 0.9756 Bal: 0.9238\n","           WALLETS: Train Loss: 0.32396075, Acc: 0.87809683, F1: 0.93034885 Bal: 0.8539 - Val Loss: 0.32449061, Accuracy: 0.8778, F1: 0.9301 Bal: 0.8531\n","Epoch 125:      TX: Train Loss: 0.0772, Acc: 0.9745, F1: 0.9857 Bal: 0.9782 - Val Loss: 0.1992, Accuracy: 0.9581, F1: 0.9765 Bal: 0.9237\n","           WALLETS: Train Loss: 0.32322812, Acc: 0.87314770, F1: 0.92723174 Bal: 0.8572 - Val Loss: 0.32358778, Accuracy: 0.8730, F1: 0.9271 Bal: 0.8552\n","Epoch 126:      TX: Train Loss: 0.0761, Acc: 0.9742, F1: 0.9855 Bal: 0.9789 - Val Loss: 0.1984, Accuracy: 0.9570, F1: 0.9759 Bal: 0.9231\n","           WALLETS: Train Loss: 0.32230213, Acc: 0.88130434, F1: 0.93231900 Bal: 0.8546 - Val Loss: 0.32328454, Accuracy: 0.8808, F1: 0.9319 Bal: 0.8535\n","Epoch 127:      TX: Train Loss: 0.0751, Acc: 0.9746, F1: 0.9857 Bal: 0.9796 - Val Loss: 0.1985, Accuracy: 0.9561, F1: 0.9754 Bal: 0.9216\n","           WALLETS: Train Loss: 0.32124135, Acc: 0.87628264, F1: 0.92917838 Bal: 0.8574 - Val Loss: 0.32205671, Accuracy: 0.8759, F1: 0.9289 Bal: 0.8556\n","Epoch 128:      TX: Train Loss: 0.0740, Acc: 0.9763, F1: 0.9867 Bal: 0.9806 - Val Loss: 0.2009, Accuracy: 0.9577, F1: 0.9763 Bal: 0.9225\n","           WALLETS: Train Loss: 0.32036114, Acc: 0.87586537, F1: 0.92890540 Bal: 0.8584 - Val Loss: 0.32128951, Accuracy: 0.8751, F1: 0.9284 Bal: 0.8561\n","Epoch 129:      TX: Train Loss: 0.0730, Acc: 0.9753, F1: 0.9861 Bal: 0.9805 - Val Loss: 0.1989, Accuracy: 0.9555, F1: 0.9750 Bal: 0.9213\n","           WALLETS: Train Loss: 0.31958836, Acc: 0.88175063, F1: 0.93256497 Bal: 0.8569 - Val Loss: 0.32101074, Accuracy: 0.8812, F1: 0.9322 Bal: 0.8555\n","Epoch 130:      TX: Train Loss: 0.0721, Acc: 0.9771, F1: 0.9871 Bal: 0.9815 - Val Loss: 0.2016, Accuracy: 0.9568, F1: 0.9757 Bal: 0.9220\n","           WALLETS: Train Loss: 0.31868917, Acc: 0.87472606, F1: 0.92815615 Bal: 0.8613 - Val Loss: 0.31980541, Accuracy: 0.8741, F1: 0.9277 Bal: 0.8576\n","Epoch 131:      TX: Train Loss: 0.0711, Acc: 0.9767, F1: 0.9869 Bal: 0.9821 - Val Loss: 0.2005, Accuracy: 0.9559, F1: 0.9752 Bal: 0.9215\n","           WALLETS: Train Loss: 0.31769049, Acc: 0.87985298, F1: 0.93136903 Bal: 0.8588 - Val Loss: 0.31928825, Accuracy: 0.8793, F1: 0.9309 Bal: 0.8569\n","Epoch 132:      TX: Train Loss: 0.0702, Acc: 0.9773, F1: 0.9872 Bal: 0.9824 - Val Loss: 0.2014, Accuracy: 0.9561, F1: 0.9754 Bal: 0.9216\n","           WALLETS: Train Loss: 0.31680620, Acc: 0.87965704, F1: 0.93123003 Bal: 0.8602 - Val Loss: 0.31851736, Accuracy: 0.8787, F1: 0.9305 Bal: 0.8574\n","Epoch 133:      TX: Train Loss: 0.0693, Acc: 0.9781, F1: 0.9877 Bal: 0.9830 - Val Loss: 0.2027, Accuracy: 0.9563, F1: 0.9755 Bal: 0.9218\n","           WALLETS: Train Loss: 0.31603640, Acc: 0.87621733, F1: 0.92905641 Bal: 0.8633 - Val Loss: 0.31764418, Accuracy: 0.8758, F1: 0.9287 Bal: 0.8596\n","Epoch 134:      TX: Train Loss: 0.0684, Acc: 0.9773, F1: 0.9872 Bal: 0.9829 - Val Loss: 0.2016, Accuracy: 0.9561, F1: 0.9754 Bal: 0.9216\n","           WALLETS: Train Loss: 0.31523433, Acc: 0.88303508, F1: 0.93329774 Bal: 0.8613 - Val Loss: 0.31741720, Accuracy: 0.8820, F1: 0.9326 Bal: 0.8592\n","Epoch 135:      TX: Train Loss: 0.0675, Acc: 0.9787, F1: 0.9881 Bal: 0.9836 - Val Loss: 0.2047, Accuracy: 0.9574, F1: 0.9761 Bal: 0.9224\n","           WALLETS: Train Loss: 0.31434783, Acc: 0.87680513, F1: 0.92939183 Bal: 0.8655 - Val Loss: 0.31623551, Accuracy: 0.8764, F1: 0.9290 Bal: 0.8629\n","Epoch 136:      TX: Train Loss: 0.0667, Acc: 0.9781, F1: 0.9877 Bal: 0.9842 - Val Loss: 0.2025, Accuracy: 0.9561, F1: 0.9754 Bal: 0.9216\n","           WALLETS: Train Loss: 0.31342813, Acc: 0.88154744, F1: 0.93233793 Bal: 0.8647 - Val Loss: 0.31576645, Accuracy: 0.8809, F1: 0.9319 Bal: 0.8622\n","Epoch 137:      TX: Train Loss: 0.0659, Acc: 0.9793, F1: 0.9884 Bal: 0.9843 - Val Loss: 0.2056, Accuracy: 0.9572, F1: 0.9760 Bal: 0.9213\n","           WALLETS: Train Loss: 0.31257042, Acc: 0.88058228, F1: 0.93173087 Bal: 0.8655 - Val Loss: 0.31497481, Accuracy: 0.8800, F1: 0.9313 Bal: 0.8632\n","Epoch 138:      TX: Train Loss: 0.0651, Acc: 0.9786, F1: 0.9880 Bal: 0.9848 - Val Loss: 0.2040, Accuracy: 0.9570, F1: 0.9759 Bal: 0.9221\n","           WALLETS: Train Loss: 0.31177559, Acc: 0.87836534, F1: 0.93034573 Bal: 0.8665 - Val Loss: 0.31418052, Accuracy: 0.8773, F1: 0.9296 Bal: 0.8634\n","Epoch 139:      TX: Train Loss: 0.0643, Acc: 0.9796, F1: 0.9885 Bal: 0.9850 - Val Loss: 0.2059, Accuracy: 0.9572, F1: 0.9760 Bal: 0.9222\n","           WALLETS: Train Loss: 0.31100237, Acc: 0.88348500, F1: 0.93352021 Bal: 0.8656 - Val Loss: 0.31389436, Accuracy: 0.8828, F1: 0.9330 Bal: 0.8634\n","Epoch 140:      TX: Train Loss: 0.0635, Acc: 0.9796, F1: 0.9885 Bal: 0.9853 - Val Loss: 0.2059, Accuracy: 0.9574, F1: 0.9761 Bal: 0.9224\n","           WALLETS: Train Loss: 0.31023347, Acc: 0.87703372, F1: 0.92949953 Bal: 0.8680 - Val Loss: 0.31283420, Accuracy: 0.8759, F1: 0.9287 Bal: 0.8647\n","Epoch 141:      TX: Train Loss: 0.0628, Acc: 0.9796, F1: 0.9886 Bal: 0.9853 - Val Loss: 0.2061, Accuracy: 0.9577, F1: 0.9763 Bal: 0.9225\n","           WALLETS: Train Loss: 0.30943066, Acc: 0.88449007, F1: 0.93413335 Bal: 0.8660 - Val Loss: 0.31274167, Accuracy: 0.8836, F1: 0.9335 Bal: 0.8635\n","Epoch 142:      TX: Train Loss: 0.0620, Acc: 0.9803, F1: 0.9889 Bal: 0.9855 - Val Loss: 0.2078, Accuracy: 0.9579, F1: 0.9764 Bal: 0.9216\n","           WALLETS: Train Loss: 0.30861267, Acc: 0.87747638, F1: 0.92975624 Bal: 0.8693 - Val Loss: 0.31156495, Accuracy: 0.8763, F1: 0.9289 Bal: 0.8665\n","Epoch 143:      TX: Train Loss: 0.0613, Acc: 0.9799, F1: 0.9887 Bal: 0.9856 - Val Loss: 0.2063, Accuracy: 0.9577, F1: 0.9763 Bal: 0.9225\n","           WALLETS: Train Loss: 0.30776605, Acc: 0.88418165, F1: 0.93392919 Bal: 0.8671 - Val Loss: 0.31140763, Accuracy: 0.8834, F1: 0.9334 Bal: 0.8644\n","Epoch 144:      TX: Train Loss: 0.0606, Acc: 0.9811, F1: 0.9894 Bal: 0.9860 - Val Loss: 0.2095, Accuracy: 0.9579, F1: 0.9764 Bal: 0.9216\n","           WALLETS: Train Loss: 0.30692306, Acc: 0.87896039, F1: 0.93066459 Bal: 0.8702 - Val Loss: 0.31029433, Accuracy: 0.8777, F1: 0.9298 Bal: 0.8669\n","Epoch 145:      TX: Train Loss: 0.0600, Acc: 0.9803, F1: 0.9889 Bal: 0.9862 - Val Loss: 0.2066, Accuracy: 0.9572, F1: 0.9760 Bal: 0.9222\n","           WALLETS: Train Loss: 0.30608156, Acc: 0.88366279, F1: 0.93358962 Bal: 0.8687 - Val Loss: 0.30998302, Accuracy: 0.8830, F1: 0.9331 Bal: 0.8655\n","Epoch 146:      TX: Train Loss: 0.0593, Acc: 0.9817, F1: 0.9898 Bal: 0.9865 - Val Loss: 0.2115, Accuracy: 0.9585, F1: 0.9768 Bal: 0.9220\n","           WALLETS: Train Loss: 0.30525777, Acc: 0.88039361, F1: 0.93154804 Bal: 0.8705 - Val Loss: 0.30904827, Accuracy: 0.8795, F1: 0.9309 Bal: 0.8668\n","Epoch 147:      TX: Train Loss: 0.0587, Acc: 0.9803, F1: 0.9889 Bal: 0.9867 - Val Loss: 0.2069, Accuracy: 0.9574, F1: 0.9761 Bal: 0.9224\n","           WALLETS: Train Loss: 0.30444002, Acc: 0.88402200, F1: 0.93378795 Bal: 0.8705 - Val Loss: 0.30862093, Accuracy: 0.8831, F1: 0.9332 Bal: 0.8666\n","Epoch 148:      TX: Train Loss: 0.0581, Acc: 0.9826, F1: 0.9902 Bal: 0.9876 - Val Loss: 0.2135, Accuracy: 0.9596, F1: 0.9774 Bal: 0.9226\n","           WALLETS: Train Loss: 0.30363408, Acc: 0.88205541, F1: 0.93255961 Bal: 0.8717 - Val Loss: 0.30780303, Accuracy: 0.8811, F1: 0.9319 Bal: 0.8681\n","Epoch 149:      TX: Train Loss: 0.0575, Acc: 0.9807, F1: 0.9891 Bal: 0.9870 - Val Loss: 0.2073, Accuracy: 0.9579, F1: 0.9764 Bal: 0.9226\n","           WALLETS: Train Loss: 0.30283377, Acc: 0.88446467, F1: 0.93404914 Bal: 0.8713 - Val Loss: 0.30735755, Accuracy: 0.8834, F1: 0.9334 Bal: 0.8664\n","Epoch 150:      TX: Train Loss: 0.0569, Acc: 0.9829, F1: 0.9904 Bal: 0.9880 - Val Loss: 0.2147, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9233\n","           WALLETS: Train Loss: 0.30205062, Acc: 0.88201913, F1: 0.93252458 Bal: 0.8727 - Val Loss: 0.30651689, Accuracy: 0.8810, F1: 0.9319 Bal: 0.8687\n","Epoch 151:      TX: Train Loss: 0.0563, Acc: 0.9812, F1: 0.9895 Bal: 0.9876 - Val Loss: 0.2089, Accuracy: 0.9583, F1: 0.9766 Bal: 0.9229\n","           WALLETS: Train Loss: 0.30129972, Acc: 0.88657276, F1: 0.93533487 Bal: 0.8721 - Val Loss: 0.30627477, Accuracy: 0.8854, F1: 0.9346 Bal: 0.8670\n","Epoch 152:      TX: Train Loss: 0.0556, Acc: 0.9829, F1: 0.9904 Bal: 0.9882 - Val Loss: 0.2144, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9233\n","           WALLETS: Train Loss: 0.30067077, Acc: 0.87951554, F1: 0.93095920 Bal: 0.8739 - Val Loss: 0.30523044, Accuracy: 0.8783, F1: 0.9302 Bal: 0.8696\n","Epoch 153:      TX: Train Loss: 0.0551, Acc: 0.9824, F1: 0.9901 Bal: 0.9881 - Val Loss: 0.2119, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9237\n","           WALLETS: Train Loss: 0.30038205, Acc: 0.89210244, F1: 0.93872589 Bal: 0.8713 - Val Loss: 0.30608878, Accuracy: 0.8913, F1: 0.9382 Bal: 0.8671\n","Epoch 154:      TX: Train Loss: 0.0545, Acc: 0.9827, F1: 0.9903 Bal: 0.9883 - Val Loss: 0.2131, Accuracy: 0.9603, F1: 0.9778 Bal: 0.9239\n","           WALLETS: Train Loss: 0.30089983, Acc: 0.87133351, F1: 0.92583258 Bal: 0.8757 - Val Loss: 0.30507094, Accuracy: 0.8699, F1: 0.9249 Bal: 0.8709\n","Epoch 155:      TX: Train Loss: 0.0540, Acc: 0.9833, F1: 0.9906 Bal: 0.9886 - Val Loss: 0.2149, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9232\n","           WALLETS: Train Loss: 0.30121064, Acc: 0.89964950, F1: 0.94333174 Bal: 0.8683 - Val Loss: 0.30786914, Accuracy: 0.8983, F1: 0.9425 Bal: 0.8635\n","Epoch 156:      TX: Train Loss: 0.0535, Acc: 0.9827, F1: 0.9903 Bal: 0.9885 - Val Loss: 0.2124, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9237\n","           WALLETS: Train Loss: 0.29901809, Acc: 0.87326744, F1: 0.92703816 Bal: 0.8761 - Val Loss: 0.30358887, Accuracy: 0.8718, F1: 0.9261 Bal: 0.8710\n","Epoch 157:      TX: Train Loss: 0.0530, Acc: 0.9841, F1: 0.9911 Bal: 0.9891 - Val Loss: 0.2172, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9233\n","           WALLETS: Train Loss: 0.29675585, Acc: 0.88420342, F1: 0.93383725 Bal: 0.8753 - Val Loss: 0.30230513, Accuracy: 0.8833, F1: 0.9332 Bal: 0.8704\n","Epoch 158:      TX: Train Loss: 0.0525, Acc: 0.9828, F1: 0.9904 Bal: 0.9886 - Val Loss: 0.2128, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9237\n","           WALLETS: Train Loss: 0.29769701, Acc: 0.89689555, F1: 0.94163223 Bal: 0.8716 - Val Loss: 0.30443287, Accuracy: 0.8960, F1: 0.9411 Bal: 0.8660\n","Epoch 159:      TX: Train Loss: 0.0520, Acc: 0.9845, F1: 0.9913 Bal: 0.9894 - Val Loss: 0.2184, Accuracy: 0.9614, F1: 0.9784 Bal: 0.9236\n","           WALLETS: Train Loss: 0.29699004, Acc: 0.87393869, F1: 0.92744113 Bal: 0.8773 - Val Loss: 0.30193225, Accuracy: 0.8725, F1: 0.9265 Bal: 0.8724\n","Epoch 160:      TX: Train Loss: 0.0515, Acc: 0.9833, F1: 0.9907 Bal: 0.9889 - Val Loss: 0.2144, Accuracy: 0.9599, F1: 0.9775 Bal: 0.9237\n","           WALLETS: Train Loss: 0.29471177, Acc: 0.88667436, F1: 0.93535133 Bal: 0.8758 - Val Loss: 0.30078030, Accuracy: 0.8856, F1: 0.9346 Bal: 0.8704\n","Epoch 161:      TX: Train Loss: 0.0510, Acc: 0.9847, F1: 0.9914 Bal: 0.9897 - Val Loss: 0.2185, Accuracy: 0.9607, F1: 0.9780 Bal: 0.9232\n","           WALLETS: Train Loss: 0.29524228, Acc: 0.89578889, F1: 0.94094400 Bal: 0.8732 - Val Loss: 0.30221391, Accuracy: 0.8949, F1: 0.9404 Bal: 0.8682\n","Epoch 162:      TX: Train Loss: 0.0505, Acc: 0.9841, F1: 0.9911 Bal: 0.9894 - Val Loss: 0.2166, Accuracy: 0.9601, F1: 0.9776 Bal: 0.9238\n","           WALLETS: Train Loss: 0.29459655, Acc: 0.87603591, F1: 0.92873874 Bal: 0.8781 - Val Loss: 0.30001557, Accuracy: 0.8751, F1: 0.9281 Bal: 0.8735\n","Epoch 163:      TX: Train Loss: 0.0501, Acc: 0.9847, F1: 0.9914 Bal: 0.9897 - Val Loss: 0.2182, Accuracy: 0.9603, F1: 0.9778 Bal: 0.9230\n","           WALLETS: Train Loss: 0.29275012, Acc: 0.88631152, F1: 0.93511238 Bal: 0.8771 - Val Loss: 0.29910314, Accuracy: 0.8848, F1: 0.9341 Bal: 0.8717\n","Epoch 164:      TX: Train Loss: 0.0496, Acc: 0.9848, F1: 0.9915 Bal: 0.9897 - Val Loss: 0.2188, Accuracy: 0.9605, F1: 0.9779 Bal: 0.9231\n","           WALLETS: Train Loss: 0.29315689, Acc: 0.89587960, F1: 0.94098266 Bal: 0.8746 - Val Loss: 0.30042568, Accuracy: 0.8953, F1: 0.9406 Bal: 0.8698\n","Epoch 165:      TX: Train Loss: 0.0492, Acc: 0.9847, F1: 0.9914 Bal: 0.9898 - Val Loss: 0.2181, Accuracy: 0.9603, F1: 0.9778 Bal: 0.9239\n","           WALLETS: Train Loss: 0.29231873, Acc: 0.87878623, F1: 0.93044107 Bal: 0.8788 - Val Loss: 0.29820594, Accuracy: 0.8779, F1: 0.9299 Bal: 0.8735\n","Epoch 166:      TX: Train Loss: 0.0488, Acc: 0.9856, F1: 0.9919 Bal: 0.9902 - Val Loss: 0.2208, Accuracy: 0.9625, F1: 0.9790 Bal: 0.9232\n","           WALLETS: Train Loss: 0.29091021, Acc: 0.88601762, F1: 0.93491593 Bal: 0.8783 - Val Loss: 0.29748672, Accuracy: 0.8844, F1: 0.9339 Bal: 0.8724\n","Epoch 167:      TX: Train Loss: 0.0484, Acc: 0.9848, F1: 0.9915 Bal: 0.9902 - Val Loss: 0.2180, Accuracy: 0.9603, F1: 0.9778 Bal: 0.9239\n","           WALLETS: Train Loss: 0.29117835, Acc: 0.89589048, F1: 0.94097633 Bal: 0.8758 - Val Loss: 0.29870343, Accuracy: 0.8950, F1: 0.9404 Bal: 0.8708\n","Epoch 168:      TX: Train Loss: 0.0480, Acc: 0.9860, F1: 0.9922 Bal: 0.9904 - Val Loss: 0.2224, Accuracy: 0.9627, F1: 0.9792 Bal: 0.9233\n","           WALLETS: Train Loss: 0.29020166, Acc: 0.88114106, F1: 0.93188812 Bal: 0.8798 - Val Loss: 0.29649392, Accuracy: 0.8800, F1: 0.9312 Bal: 0.8738\n","Epoch 169:      TX: Train Loss: 0.0476, Acc: 0.9849, F1: 0.9915 Bal: 0.9903 - Val Loss: 0.2177, Accuracy: 0.9605, F1: 0.9779 Bal: 0.9251\n","           WALLETS: Train Loss: 0.28914782, Acc: 0.88564752, F1: 0.93467591 Bal: 0.8793 - Val Loss: 0.29589161, Accuracy: 0.8843, F1: 0.9338 Bal: 0.8738\n","Epoch 170:      TX: Train Loss: 0.0472, Acc: 0.9865, F1: 0.9925 Bal: 0.9908 - Val Loss: 0.2244, Accuracy: 0.9645, F1: 0.9802 Bal: 0.9243\n","           WALLETS: Train Loss: 0.28924814, Acc: 0.89584694, F1: 0.94093439 Bal: 0.8771 - Val Loss: 0.29695547, Accuracy: 0.8950, F1: 0.9404 Bal: 0.8719\n","Epoch 171:      TX: Train Loss: 0.0469, Acc: 0.9846, F1: 0.9914 Bal: 0.9902 - Val Loss: 0.2172, Accuracy: 0.9609, F1: 0.9781 Bal: 0.9253\n","           WALLETS: Train Loss: 0.28825277, Acc: 0.88288994, F1: 0.93296280 Bal: 0.8803 - Val Loss: 0.29490033, Accuracy: 0.8815, F1: 0.9321 Bal: 0.8743\n","Epoch 172:      TX: Train Loss: 0.0465, Acc: 0.9870, F1: 0.9927 Bal: 0.9912 - Val Loss: 0.2266, Accuracy: 0.9653, F1: 0.9807 Bal: 0.9248\n","           WALLETS: Train Loss: 0.28739610, Acc: 0.88611921, F1: 0.93495022 Bal: 0.8806 - Val Loss: 0.29438812, Accuracy: 0.8846, F1: 0.9340 Bal: 0.8746\n","Epoch 173:      TX: Train Loss: 0.0462, Acc: 0.9848, F1: 0.9915 Bal: 0.9905 - Val Loss: 0.2174, Accuracy: 0.9612, F1: 0.9783 Bal: 0.9254\n","           WALLETS: Train Loss: 0.28733307, Acc: 0.89560747, F1: 0.94077445 Bal: 0.8784 - Val Loss: 0.29524732, Accuracy: 0.8946, F1: 0.9402 Bal: 0.8731\n","Epoch 174:      TX: Train Loss: 0.0458, Acc: 0.9872, F1: 0.9929 Bal: 0.9914 - Val Loss: 0.2267, Accuracy: 0.9653, F1: 0.9807 Bal: 0.9248\n","           WALLETS: Train Loss: 0.28641298, Acc: 0.88442113, F1: 0.93389476 Bal: 0.8813 - Val Loss: 0.29338205, Accuracy: 0.8828, F1: 0.9329 Bal: 0.8752\n","Epoch 175:      TX: Train Loss: 0.0454, Acc: 0.9857, F1: 0.9920 Bal: 0.9910 - Val Loss: 0.2196, Accuracy: 0.9623, F1: 0.9789 Bal: 0.9260\n","           WALLETS: Train Loss: 0.28564197, Acc: 0.88715694, F1: 0.93557449 Bal: 0.8817 - Val Loss: 0.29290694, Accuracy: 0.8859, F1: 0.9348 Bal: 0.8761\n","Epoch 176:      TX: Train Loss: 0.0450, Acc: 0.9868, F1: 0.9926 Bal: 0.9913 - Val Loss: 0.2246, Accuracy: 0.9649, F1: 0.9804 Bal: 0.9255\n","           WALLETS: Train Loss: 0.28546897, Acc: 0.89558570, F1: 0.94074161 Bal: 0.8802 - Val Loss: 0.29356903, Accuracy: 0.8944, F1: 0.9400 Bal: 0.8746\n","Epoch 177:      TX: Train Loss: 0.0446, Acc: 0.9866, F1: 0.9925 Bal: 0.9913 - Val Loss: 0.2235, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9263\n","           WALLETS: Train Loss: 0.28467080, Acc: 0.88499078, F1: 0.93423818 Bal: 0.8819 - Val Loss: 0.29193103, Accuracy: 0.8837, F1: 0.9334 Bal: 0.8760\n","Epoch 178:      TX: Train Loss: 0.0443, Acc: 0.9864, F1: 0.9924 Bal: 0.9914 - Val Loss: 0.2221, Accuracy: 0.9636, F1: 0.9796 Bal: 0.9258\n","           WALLETS: Train Loss: 0.28389093, Acc: 0.88874980, F1: 0.93654397 Bal: 0.8824 - Val Loss: 0.29153794, Accuracy: 0.8875, F1: 0.9357 Bal: 0.8771\n","Epoch 179:      TX: Train Loss: 0.0440, Acc: 0.9875, F1: 0.9930 Bal: 0.9919 - Val Loss: 0.2266, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9247\n","           WALLETS: Train Loss: 0.28363281, Acc: 0.89501604, F1: 0.94037915 Bal: 0.8816 - Val Loss: 0.29196945, Accuracy: 0.8940, F1: 0.9397 Bal: 0.8763\n","Epoch 180:      TX: Train Loss: 0.0437, Acc: 0.9863, F1: 0.9923 Bal: 0.9916 - Val Loss: 0.2208, Accuracy: 0.9627, F1: 0.9791 Bal: 0.9253\n","           WALLETS: Train Loss: 0.28299373, Acc: 0.88562938, F1: 0.93462205 Bal: 0.8827 - Val Loss: 0.29054153, Accuracy: 0.8845, F1: 0.9339 Bal: 0.8770\n","Epoch 181:      TX: Train Loss: 0.0434, Acc: 0.9877, F1: 0.9931 Bal: 0.9920 - Val Loss: 0.2281, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9247\n","           WALLETS: Train Loss: 0.28217843, Acc: 0.89082161, F1: 0.93780642 Bal: 0.8829 - Val Loss: 0.29026034, Accuracy: 0.8896, F1: 0.9370 Bal: 0.8775\n","Epoch 182:      TX: Train Loss: 0.0430, Acc: 0.9866, F1: 0.9925 Bal: 0.9919 - Val Loss: 0.2216, Accuracy: 0.9629, F1: 0.9793 Bal: 0.9254\n","           WALLETS: Train Loss: 0.28180432, Acc: 0.89464231, F1: 0.94013891 Bal: 0.8827 - Val Loss: 0.29035160, Accuracy: 0.8935, F1: 0.9394 Bal: 0.8779\n","Epoch 183:      TX: Train Loss: 0.0427, Acc: 0.9877, F1: 0.9931 Bal: 0.9921 - Val Loss: 0.2278, Accuracy: 0.9653, F1: 0.9807 Bal: 0.9248\n","           WALLETS: Train Loss: 0.28133070, Acc: 0.88641674, F1: 0.93509622 Bal: 0.8835 - Val Loss: 0.28919739, Accuracy: 0.8851, F1: 0.9342 Bal: 0.8782\n","Epoch 184:      TX: Train Loss: 0.0424, Acc: 0.9870, F1: 0.9928 Bal: 0.9920 - Val Loss: 0.2240, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9253\n","           WALLETS: Train Loss: 0.28054366, Acc: 0.89300228, F1: 0.93913306 Bal: 0.8833 - Val Loss: 0.28914836, Accuracy: 0.8919, F1: 0.9384 Bal: 0.8781\n","Epoch 185:      TX: Train Loss: 0.0421, Acc: 0.9876, F1: 0.9930 Bal: 0.9923 - Val Loss: 0.2261, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9256\n","           WALLETS: Train Loss: 0.27999967, Acc: 0.89339777, F1: 0.93937193 Bal: 0.8835 - Val Loss: 0.28875676, Accuracy: 0.8923, F1: 0.9387 Bal: 0.8782\n","Epoch 186:      TX: Train Loss: 0.0418, Acc: 0.9877, F1: 0.9931 Bal: 0.9924 - Val Loss: 0.2265, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9256\n","           WALLETS: Train Loss: 0.27961913, Acc: 0.88762500, F1: 0.93583095 Bal: 0.8842 - Val Loss: 0.28790495, Accuracy: 0.8862, F1: 0.9350 Bal: 0.8783\n","Epoch 187:      TX: Train Loss: 0.0415, Acc: 0.9874, F1: 0.9929 Bal: 0.9922 - Val Loss: 0.2248, Accuracy: 0.9647, F1: 0.9803 Bal: 0.9254\n","           WALLETS: Train Loss: 0.27899098, Acc: 0.89526640, F1: 0.94050331 Bal: 0.8840 - Val Loss: 0.28812796, Accuracy: 0.8945, F1: 0.9400 Bal: 0.8787\n","Epoch 188:      TX: Train Loss: 0.0412, Acc: 0.9883, F1: 0.9934 Bal: 0.9927 - Val Loss: 0.2287, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9258\n","           WALLETS: Train Loss: 0.27830938, Acc: 0.89140579, F1: 0.93814597 Bal: 0.8844 - Val Loss: 0.28718096, Accuracy: 0.8899, F1: 0.9372 Bal: 0.8784\n","Epoch 189:      TX: Train Loss: 0.0409, Acc: 0.9873, F1: 0.9929 Bal: 0.9924 - Val Loss: 0.2239, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9253\n","           WALLETS: Train Loss: 0.27782732, Acc: 0.88993266, F1: 0.93724282 Bal: 0.8845 - Val Loss: 0.28667223, Accuracy: 0.8884, F1: 0.9363 Bal: 0.8782\n","Epoch 190:      TX: Train Loss: 0.0407, Acc: 0.9887, F1: 0.9937 Bal: 0.9929 - Val Loss: 0.2306, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9261\n","           WALLETS: Train Loss: 0.27738798, Acc: 0.89615535, F1: 0.94103735 Bal: 0.8846 - Val Loss: 0.28693971, Accuracy: 0.8952, F1: 0.9404 Bal: 0.8788\n","Epoch 191:      TX: Train Loss: 0.0404, Acc: 0.9872, F1: 0.9928 Bal: 0.9923 - Val Loss: 0.2235, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9263\n","           WALLETS: Train Loss: 0.27681249, Acc: 0.88960610, F1: 0.93703709 Bal: 0.8850 - Val Loss: 0.28583622, Accuracy: 0.8882, F1: 0.9362 Bal: 0.8788\n","Epoch 192:      TX: Train Loss: 0.0401, Acc: 0.9889, F1: 0.9938 Bal: 0.9932 - Val Loss: 0.2319, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9254\n","           WALLETS: Train Loss: 0.27617511, Acc: 0.89385132, F1: 0.93963150 Bal: 0.8849 - Val Loss: 0.28574792, Accuracy: 0.8928, F1: 0.9390 Bal: 0.8795\n","Epoch 193:      TX: Train Loss: 0.0399, Acc: 0.9873, F1: 0.9929 Bal: 0.9924 - Val Loss: 0.2237, Accuracy: 0.9647, F1: 0.9803 Bal: 0.9264\n","           WALLETS: Train Loss: 0.27565280, Acc: 0.89420328, F1: 0.93984221 Bal: 0.8853 - Val Loss: 0.28537545, Accuracy: 0.8931, F1: 0.9392 Bal: 0.8795\n","Epoch 194:      TX: Train Loss: 0.0396, Acc: 0.9889, F1: 0.9938 Bal: 0.9932 - Val Loss: 0.2324, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9258\n","           WALLETS: Train Loss: 0.27521464, Acc: 0.89047329, F1: 0.93755766 Bal: 0.8858 - Val Loss: 0.28467321, Accuracy: 0.8892, F1: 0.9367 Bal: 0.8794\n","Epoch 195:      TX: Train Loss: 0.0393, Acc: 0.9877, F1: 0.9931 Bal: 0.9927 - Val Loss: 0.2251, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9256\n","           WALLETS: Train Loss: 0.27472302, Acc: 0.89658350, F1: 0.94128384 Bal: 0.8858 - Val Loss: 0.28491884, Accuracy: 0.8954, F1: 0.9406 Bal: 0.8794\n","Epoch 196:      TX: Train Loss: 0.0391, Acc: 0.9889, F1: 0.9938 Bal: 0.9932 - Val Loss: 0.2319, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9254\n","           WALLETS: Train Loss: 0.27416694, Acc: 0.89119171, F1: 0.93799136 Bal: 0.8863 - Val Loss: 0.28391865, Accuracy: 0.8901, F1: 0.9373 Bal: 0.8801\n","Epoch 197:      TX: Train Loss: 0.0388, Acc: 0.9882, F1: 0.9934 Bal: 0.9929 - Val Loss: 0.2274, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9258\n","           WALLETS: Train Loss: 0.27359545, Acc: 0.89499064, F1: 0.94031122 Bal: 0.8862 - Val Loss: 0.28383225, Accuracy: 0.8937, F1: 0.9395 Bal: 0.8803\n","Epoch 198:      TX: Train Loss: 0.0385, Acc: 0.9889, F1: 0.9938 Bal: 0.9932 - Val Loss: 0.2305, Accuracy: 0.9656, F1: 0.9808 Bal: 0.9249\n","           WALLETS: Train Loss: 0.27308467, Acc: 0.89463143, F1: 0.94008888 Bal: 0.8865 - Val Loss: 0.28339341, Accuracy: 0.8934, F1: 0.9393 Bal: 0.8805\n","Epoch 199:      TX: Train Loss: 0.0383, Acc: 0.9888, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.2297, Accuracy: 0.9658, F1: 0.9809 Bal: 0.9260\n","           WALLETS: Train Loss: 0.27262387, Acc: 0.89240359, F1: 0.93872685 Bal: 0.8868 - Val Loss: 0.28283623, Accuracy: 0.8912, F1: 0.9380 Bal: 0.8807\n","Epoch 200:      TX: Train Loss: 0.0380, Acc: 0.9888, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.2293, Accuracy: 0.9656, F1: 0.9808 Bal: 0.9259\n","           WALLETS: Train Loss: 0.27216783, Acc: 0.89713865, F1: 0.94160613 Bal: 0.8871 - Val Loss: 0.28296915, Accuracy: 0.8956, F1: 0.9407 Bal: 0.8799\n","Epoch 201:      TX: Train Loss: 0.0378, Acc: 0.9890, F1: 0.9939 Bal: 0.9934 - Val Loss: 0.2316, Accuracy: 0.9662, F1: 0.9812 Bal: 0.9253\n","           WALLETS: Train Loss: 0.27170917, Acc: 0.89154366, F1: 0.93819487 Bal: 0.8873 - Val Loss: 0.28205955, Accuracy: 0.8902, F1: 0.9373 Bal: 0.8814\n","Epoch 202:      TX: Train Loss: 0.0376, Acc: 0.9887, F1: 0.9937 Bal: 0.9932 - Val Loss: 0.2283, Accuracy: 0.9653, F1: 0.9806 Bal: 0.9258\n","           WALLETS: Train Loss: 0.27121809, Acc: 0.89791875, F1: 0.94207726 Bal: 0.8873 - Val Loss: 0.28234366, Accuracy: 0.8966, F1: 0.9413 Bal: 0.8803\n","Epoch 203:      TX: Train Loss: 0.0374, Acc: 0.9895, F1: 0.9941 Bal: 0.9936 - Val Loss: 0.2338, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9261\n","           WALLETS: Train Loss: 0.27072036, Acc: 0.89227297, F1: 0.93863370 Bal: 0.8879 - Val Loss: 0.28136405, Accuracy: 0.8909, F1: 0.9378 Bal: 0.8816\n","Epoch 204:      TX: Train Loss: 0.0372, Acc: 0.9883, F1: 0.9935 Bal: 0.9930 - Val Loss: 0.2272, Accuracy: 0.9647, F1: 0.9803 Bal: 0.9254\n","           WALLETS: Train Loss: 0.27020770, Acc: 0.89794415, F1: 0.94208822 Bal: 0.8877 - Val Loss: 0.28156886, Accuracy: 0.8967, F1: 0.9413 Bal: 0.8811\n","Epoch 205:      TX: Train Loss: 0.0370, Acc: 0.9900, F1: 0.9944 Bal: 0.9938 - Val Loss: 0.2366, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9264\n","           WALLETS: Train Loss: 0.26970994, Acc: 0.89339052, F1: 0.93931320 Bal: 0.8881 - Val Loss: 0.28070420, Accuracy: 0.8922, F1: 0.9386 Bal: 0.8819\n","Epoch 206:      TX: Train Loss: 0.0368, Acc: 0.9878, F1: 0.9932 Bal: 0.9927 - Val Loss: 0.2254, Accuracy: 0.9640, F1: 0.9799 Bal: 0.9260\n","           WALLETS: Train Loss: 0.26921391, Acc: 0.89771193, F1: 0.94194449 Bal: 0.8879 - Val Loss: 0.28079659, Accuracy: 0.8965, F1: 0.9412 Bal: 0.8814\n","Epoch 207:      TX: Train Loss: 0.0366, Acc: 0.9906, F1: 0.9948 Bal: 0.9941 - Val Loss: 0.2395, Accuracy: 0.9688, F1: 0.9827 Bal: 0.9248\n","           WALLETS: Train Loss: 0.26873806, Acc: 0.89408354, F1: 0.93973347 Bal: 0.8884 - Val Loss: 0.28005156, Accuracy: 0.8929, F1: 0.9390 Bal: 0.8822\n","Epoch 208:      TX: Train Loss: 0.0365, Acc: 0.9877, F1: 0.9931 Bal: 0.9926 - Val Loss: 0.2245, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9271\n","           WALLETS: Train Loss: 0.26826471, Acc: 0.89819088, F1: 0.94222941 Bal: 0.8884 - Val Loss: 0.28014132, Accuracy: 0.8968, F1: 0.9414 Bal: 0.8814\n","Epoch 209:      TX: Train Loss: 0.0362, Acc: 0.9906, F1: 0.9947 Bal: 0.9941 - Val Loss: 0.2396, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9270\n","           WALLETS: Train Loss: 0.26782048, Acc: 0.89429399, F1: 0.93985569 Bal: 0.8889 - Val Loss: 0.27938229, Accuracy: 0.8926, F1: 0.9388 Bal: 0.8824\n","Epoch 210:      TX: Train Loss: 0.0359, Acc: 0.9886, F1: 0.9936 Bal: 0.9931 - Val Loss: 0.2281, Accuracy: 0.9645, F1: 0.9801 Bal: 0.9253\n","           WALLETS: Train Loss: 0.26740494, Acc: 0.89985994, F1: 0.94323658 Bal: 0.8888 - Val Loss: 0.27971527, Accuracy: 0.8986, F1: 0.9425 Bal: 0.8811\n","Epoch 211:      TX: Train Loss: 0.0356, Acc: 0.9900, F1: 0.9944 Bal: 0.9939 - Val Loss: 0.2347, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9261\n","           WALLETS: Train Loss: 0.26708531, Acc: 0.89230926, F1: 0.93863838 Bal: 0.8894 - Val Loss: 0.27868190, Accuracy: 0.8906, F1: 0.9376 Bal: 0.8826\n","Epoch 212:      TX: Train Loss: 0.0354, Acc: 0.9900, F1: 0.9944 Bal: 0.9939 - Val Loss: 0.2347, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9261\n","           WALLETS: Train Loss: 0.26695174, Acc: 0.90370967, F1: 0.94556017 Bal: 0.8887 - Val Loss: 0.27992526, Accuracy: 0.9020, F1: 0.9446 Bal: 0.8797\n","Epoch 213:      TX: Train Loss: 0.0352, Acc: 0.9892, F1: 0.9940 Bal: 0.9935 - Val Loss: 0.2295, Accuracy: 0.9651, F1: 0.9805 Bal: 0.9256\n","           WALLETS: Train Loss: 0.26732653, Acc: 0.88642763, F1: 0.93503011 Bal: 0.8893 - Val Loss: 0.27848864, Accuracy: 0.8845, F1: 0.9338 Bal: 0.8819\n","Epoch 214:      TX: Train Loss: 0.0351, Acc: 0.9906, F1: 0.9948 Bal: 0.9941 - Val Loss: 0.2397, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9270\n","           WALLETS: Train Loss: 0.26836848, Acc: 0.91166311, F1: 0.95033334 Bal: 0.8874 - Val Loss: 0.28251293, Accuracy: 0.9103, F1: 0.9495 Bal: 0.8785\n","Epoch 215:      TX: Train Loss: 0.0349, Acc: 0.9889, F1: 0.9938 Bal: 0.9933 - Val Loss: 0.2281, Accuracy: 0.9642, F1: 0.9800 Bal: 0.9261\n","           WALLETS: Train Loss: 0.26974621, Acc: 0.87725868, F1: 0.92934424 Bal: 0.8895 - Val Loss: 0.28015432, Accuracy: 0.8761, F1: 0.9286 Bal: 0.8821\n","Epoch 216:      TX: Train Loss: 0.0347, Acc: 0.9908, F1: 0.9949 Bal: 0.9944 - Val Loss: 0.2399, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9269\n","           WALLETS: Train Loss: 0.26805678, Acc: 0.91316889, F1: 0.95123119 Bal: 0.8871 - Val Loss: 0.28257394, Accuracy: 0.9119, F1: 0.9505 Bal: 0.8778\n","Epoch 217:      TX: Train Loss: 0.0344, Acc: 0.9896, F1: 0.9942 Bal: 0.9937 - Val Loss: 0.2318, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9251\n","           WALLETS: Train Loss: 0.26481754, Acc: 0.89156906, F1: 0.93817777 Bal: 0.8901 - Val Loss: 0.27688679, Accuracy: 0.8897, F1: 0.9370 Bal: 0.8827\n","Epoch 218:      TX: Train Loss: 0.0342, Acc: 0.9902, F1: 0.9945 Bal: 0.9940 - Val Loss: 0.2352, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9258\n","           WALLETS: Train Loss: 0.26448628, Acc: 0.89140941, F1: 0.93807880 Bal: 0.8902 - Val Loss: 0.27659452, Accuracy: 0.8894, F1: 0.9368 Bal: 0.8828\n","Epoch 219:      TX: Train Loss: 0.0340, Acc: 0.9906, F1: 0.9947 Bal: 0.9942 - Val Loss: 0.2375, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9261\n","           WALLETS: Train Loss: 0.26613984, Acc: 0.91190621, F1: 0.95047053 Bal: 0.8882 - Val Loss: 0.28074583, Accuracy: 0.9103, F1: 0.9495 Bal: 0.8796\n","Epoch 220:      TX: Train Loss: 0.0338, Acc: 0.9898, F1: 0.9943 Bal: 0.9939 - Val Loss: 0.2315, Accuracy: 0.9660, F1: 0.9810 Bal: 0.9251\n","           WALLETS: Train Loss: 0.26527807, Acc: 0.88486016, F1: 0.93403896 Bal: 0.8912 - Val Loss: 0.27685690, Accuracy: 0.8826, F1: 0.9326 Bal: 0.8831\n","Epoch 221:      TX: Train Loss: 0.0337, Acc: 0.9910, F1: 0.9950 Bal: 0.9945 - Val Loss: 0.2407, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9269\n","           WALLETS: Train Loss: 0.26289299, Acc: 0.90041872, F1: 0.94355819 Bal: 0.8903 - Val Loss: 0.27631932, Accuracy: 0.8987, F1: 0.9425 Bal: 0.8816\n","Epoch 222:      TX: Train Loss: 0.0335, Acc: 0.9899, F1: 0.9943 Bal: 0.9940 - Val Loss: 0.2318, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9274\n","           WALLETS: Train Loss: 0.26346564, Acc: 0.90704779, F1: 0.94755268 Bal: 0.8899 - Val Loss: 0.27774057, Accuracy: 0.9053, F1: 0.9465 Bal: 0.8806\n","Epoch 223:      TX: Train Loss: 0.0333, Acc: 0.9909, F1: 0.9949 Bal: 0.9944 - Val Loss: 0.2397, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9266\n","           WALLETS: Train Loss: 0.26421052, Acc: 0.88540805, F1: 0.93437370 Bal: 0.8915 - Val Loss: 0.27603784, Accuracy: 0.8833, F1: 0.9331 Bal: 0.8828\n","Epoch 224:      TX: Train Loss: 0.0330, Acc: 0.9904, F1: 0.9946 Bal: 0.9943 - Val Loss: 0.2353, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9256\n","           WALLETS: Train Loss: 0.26227826, Acc: 0.90523360, F1: 0.94645976 Bal: 0.8903 - Val Loss: 0.27651441, Accuracy: 0.9034, F1: 0.9454 Bal: 0.8814\n","Epoch 225:      TX: Train Loss: 0.0329, Acc: 0.9906, F1: 0.9947 Bal: 0.9944 - Val Loss: 0.2367, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9256\n","           WALLETS: Train Loss: 0.26164258, Acc: 0.90324886, F1: 0.94526203 Bal: 0.8907 - Val Loss: 0.27574202, Accuracy: 0.9015, F1: 0.9442 Bal: 0.8819\n","Epoch 226:      TX: Train Loss: 0.0327, Acc: 0.9910, F1: 0.9950 Bal: 0.9946 - Val Loss: 0.2390, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9266\n","           WALLETS: Train Loss: 0.26251987, Acc: 0.88818014, F1: 0.93607444 Bal: 0.8921 - Val Loss: 0.27490252, Accuracy: 0.8860, F1: 0.9347 Bal: 0.8840\n","Epoch 227:      TX: Train Loss: 0.0325, Acc: 0.9902, F1: 0.9945 Bal: 0.9942 - Val Loss: 0.2342, Accuracy: 0.9667, F1: 0.9814 Bal: 0.9265\n","           WALLETS: Train Loss: 0.26153940, Acc: 0.90711310, F1: 0.94758373 Bal: 0.8907 - Val Loss: 0.27621272, Accuracy: 0.9053, F1: 0.9465 Bal: 0.8814\n","Epoch 228:      TX: Train Loss: 0.0324, Acc: 0.9913, F1: 0.9952 Bal: 0.9948 - Val Loss: 0.2413, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9267\n","           WALLETS: Train Loss: 0.26039156, Acc: 0.89981640, F1: 0.94317590 Bal: 0.8919 - Val Loss: 0.27423635, Accuracy: 0.8976, F1: 0.9418 Bal: 0.8829\n","Epoch 229:      TX: Train Loss: 0.0322, Acc: 0.9902, F1: 0.9945 Bal: 0.9943 - Val Loss: 0.2337, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9274\n","           WALLETS: Train Loss: 0.26080191, Acc: 0.89182305, F1: 0.93830471 Bal: 0.8924 - Val Loss: 0.27379996, Accuracy: 0.8896, F1: 0.9369 Bal: 0.8842\n","Epoch 230:      TX: Train Loss: 0.0320, Acc: 0.9915, F1: 0.9952 Bal: 0.9949 - Val Loss: 0.2415, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9270\n","           WALLETS: Train Loss: 0.26061112, Acc: 0.90771179, F1: 0.94794065 Bal: 0.8909 - Val Loss: 0.27567080, Accuracy: 0.9061, F1: 0.9470 Bal: 0.8812\n","Epoch 231:      TX: Train Loss: 0.0319, Acc: 0.9905, F1: 0.9947 Bal: 0.9945 - Val Loss: 0.2354, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9266\n","           WALLETS: Train Loss: 0.25950512, Acc: 0.89713865, F1: 0.94154062 Bal: 0.8929 - Val Loss: 0.27326700, Accuracy: 0.8951, F1: 0.9403 Bal: 0.8842\n","Epoch 232:      TX: Train Loss: 0.0317, Acc: 0.9912, F1: 0.9951 Bal: 0.9947 - Val Loss: 0.2402, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9265\n","           WALLETS: Train Loss: 0.25928888, Acc: 0.89616624, F1: 0.94094900 Bal: 0.8930 - Val Loss: 0.27297813, Accuracy: 0.8942, F1: 0.9398 Bal: 0.8842\n","Epoch 233:      TX: Train Loss: 0.0315, Acc: 0.9910, F1: 0.9950 Bal: 0.9948 - Val Loss: 0.2380, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9273\n","           WALLETS: Train Loss: 0.25946850, Acc: 0.90754488, F1: 0.94783476 Bal: 0.8914 - Val Loss: 0.27471054, Accuracy: 0.9060, F1: 0.9469 Bal: 0.8821\n","Epoch 234:      TX: Train Loss: 0.0313, Acc: 0.9911, F1: 0.9950 Bal: 0.9948 - Val Loss: 0.2385, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9273\n","           WALLETS: Train Loss: 0.25880346, Acc: 0.89502329, F1: 0.94025055 Bal: 0.8932 - Val Loss: 0.27257487, Accuracy: 0.8931, F1: 0.9391 Bal: 0.8849\n","Epoch 235:      TX: Train Loss: 0.0312, Acc: 0.9913, F1: 0.9952 Bal: 0.9949 - Val Loss: 0.2401, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9265\n","           WALLETS: Train Loss: 0.25810853, Acc: 0.90034615, F1: 0.94347823 Bal: 0.8936 - Val Loss: 0.27262723, Accuracy: 0.8979, F1: 0.9420 Bal: 0.8840\n","Epoch 236:      TX: Train Loss: 0.0310, Acc: 0.9910, F1: 0.9950 Bal: 0.9947 - Val Loss: 0.2372, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9272\n","           WALLETS: Train Loss: 0.25816473, Acc: 0.90577786, F1: 0.94676747 Bal: 0.8922 - Val Loss: 0.27349478, Accuracy: 0.9038, F1: 0.9456 Bal: 0.8830\n","Epoch 237:      TX: Train Loss: 0.0309, Acc: 0.9918, F1: 0.9954 Bal: 0.9952 - Val Loss: 0.2418, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9267\n","           WALLETS: Train Loss: 0.25802979, Acc: 0.89428673, F1: 0.93979489 Bal: 0.8937 - Val Loss: 0.27194288, Accuracy: 0.8923, F1: 0.9386 Bal: 0.8851\n","Epoch 238:      TX: Train Loss: 0.0307, Acc: 0.9908, F1: 0.9949 Bal: 0.9947 - Val Loss: 0.2361, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9281\n","           WALLETS: Train Loss: 0.25729814, Acc: 0.90411605, F1: 0.94575766 Bal: 0.8932 - Val Loss: 0.27254954, Accuracy: 0.9020, F1: 0.9445 Bal: 0.8837\n","Epoch 239:      TX: Train Loss: 0.0306, Acc: 0.9920, F1: 0.9955 Bal: 0.9953 - Val Loss: 0.2433, Accuracy: 0.9688, F1: 0.9827 Bal: 0.9248\n","           WALLETS: Train Loss: 0.25691620, Acc: 0.90324161, F1: 0.94522644 Bal: 0.8936 - Val Loss: 0.27213615, Accuracy: 0.9008, F1: 0.9438 Bal: 0.8834\n","Epoch 240:      TX: Train Loss: 0.0305, Acc: 0.9908, F1: 0.9949 Bal: 0.9947 - Val Loss: 0.2351, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9277\n","           WALLETS: Train Loss: 0.25693259, Acc: 0.89609367, F1: 0.94089285 Bal: 0.8940 - Val Loss: 0.27132910, Accuracy: 0.8941, F1: 0.9397 Bal: 0.8848\n","Epoch 241:      TX: Train Loss: 0.0303, Acc: 0.9921, F1: 0.9956 Bal: 0.9954 - Val Loss: 0.2449, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9253\n","           WALLETS: Train Loss: 0.25659329, Acc: 0.90647088, F1: 0.94717297 Bal: 0.8932 - Val Loss: 0.27240044, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8834\n","Epoch 242:      TX: Train Loss: 0.0302, Acc: 0.9908, F1: 0.9949 Bal: 0.9948 - Val Loss: 0.2342, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9276\n","           WALLETS: Train Loss: 0.25601557, Acc: 0.89974384, F1: 0.94310500 Bal: 0.8944 - Val Loss: 0.27100211, Accuracy: 0.8974, F1: 0.9417 Bal: 0.8845\n","Epoch 243:      TX: Train Loss: 0.0301, Acc: 0.9923, F1: 0.9957 Bal: 0.9955 - Val Loss: 0.2463, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9243\n","           WALLETS: Train Loss: 0.25570908, Acc: 0.89982729, F1: 0.94315458 Bal: 0.8945 - Val Loss: 0.27079856, Accuracy: 0.8974, F1: 0.9417 Bal: 0.8845\n","Epoch 244:      TX: Train Loss: 0.0299, Acc: 0.9908, F1: 0.9949 Bal: 0.9948 - Val Loss: 0.2339, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9276\n","           WALLETS: Train Loss: 0.25561264, Acc: 0.90618424, F1: 0.94699597 Bal: 0.8937 - Val Loss: 0.27162990, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8841\n","Epoch 245:      TX: Train Loss: 0.0298, Acc: 0.9924, F1: 0.9958 Bal: 0.9955 - Val Loss: 0.2464, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9243\n","           WALLETS: Train Loss: 0.25531828, Acc: 0.89747972, F1: 0.94172749 Bal: 0.8947 - Val Loss: 0.27024657, Accuracy: 0.8950, F1: 0.9402 Bal: 0.8848\n","Epoch 246:      TX: Train Loss: 0.0296, Acc: 0.9910, F1: 0.9950 Bal: 0.9949 - Val Loss: 0.2351, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9277\n","           WALLETS: Train Loss: 0.25481361, Acc: 0.90430836, F1: 0.94586256 Bal: 0.8943 - Val Loss: 0.27069625, Accuracy: 0.9020, F1: 0.9445 Bal: 0.8843\n","Epoch 247:      TX: Train Loss: 0.0294, Acc: 0.9922, F1: 0.9957 Bal: 0.9954 - Val Loss: 0.2447, Accuracy: 0.9688, F1: 0.9827 Bal: 0.9238\n","           WALLETS: Train Loss: 0.25447035, Acc: 0.90336860, F1: 0.94529485 Bal: 0.8944 - Val Loss: 0.27029222, Accuracy: 0.9006, F1: 0.9436 Bal: 0.8845\n","Epoch 248:      TX: Train Loss: 0.0293, Acc: 0.9915, F1: 0.9953 Bal: 0.9952 - Val Loss: 0.2380, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9275\n","           WALLETS: Train Loss: 0.25431761, Acc: 0.89908710, F1: 0.94269797 Bal: 0.8952 - Val Loss: 0.26966649, Accuracy: 0.8967, F1: 0.9413 Bal: 0.8849\n","Epoch 249:      TX: Train Loss: 0.0291, Acc: 0.9920, F1: 0.9955 Bal: 0.9953 - Val Loss: 0.2419, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9280\n","           WALLETS: Train Loss: 0.25408608, Acc: 0.90661239, F1: 0.94724458 Bal: 0.8945 - Val Loss: 0.27049795, Accuracy: 0.9042, F1: 0.9458 Bal: 0.8839\n","Epoch 250:      TX: Train Loss: 0.0290, Acc: 0.9919, F1: 0.9955 Bal: 0.9953 - Val Loss: 0.2411, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9280\n","           WALLETS: Train Loss: 0.25371036, Acc: 0.89969304, F1: 0.94306304 Bal: 0.8954 - Val Loss: 0.26926443, Accuracy: 0.8970, F1: 0.9415 Bal: 0.8845\n","Epoch 251:      TX: Train Loss: 0.0288, Acc: 0.9918, F1: 0.9954 Bal: 0.9953 - Val Loss: 0.2396, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9280\n","           WALLETS: Train Loss: 0.25331050, Acc: 0.90348471, F1: 0.94535856 Bal: 0.8950 - Val Loss: 0.26946366, Accuracy: 0.9007, F1: 0.9437 Bal: 0.8849\n","Epoch 252:      TX: Train Loss: 0.0287, Acc: 0.9923, F1: 0.9957 Bal: 0.9954 - Val Loss: 0.2437, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9249\n","           WALLETS: Train Loss: 0.25303826, Acc: 0.90414508, F1: 0.94575649 Bal: 0.8950 - Val Loss: 0.26935604, Accuracy: 0.9014, F1: 0.9441 Bal: 0.8846\n","Epoch 253:      TX: Train Loss: 0.0286, Acc: 0.9916, F1: 0.9953 Bal: 0.9952 - Val Loss: 0.2375, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9273\n","           WALLETS: Train Loss: 0.25284761, Acc: 0.89995428, F1: 0.94321811 Bal: 0.8957 - Val Loss: 0.26866800, Accuracy: 0.8972, F1: 0.9416 Bal: 0.8844\n","Epoch 254:      TX: Train Loss: 0.0285, Acc: 0.9925, F1: 0.9958 Bal: 0.9956 - Val Loss: 0.2459, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9230\n","           WALLETS: Train Loss: 0.25260007, Acc: 0.90673212, F1: 0.94730779 Bal: 0.8954 - Val Loss: 0.26936933, Accuracy: 0.9041, F1: 0.9458 Bal: 0.8841\n","Epoch 255:      TX: Train Loss: 0.0284, Acc: 0.9914, F1: 0.9952 Bal: 0.9951 - Val Loss: 0.2357, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9277\n","           WALLETS: Train Loss: 0.25228149, Acc: 0.90021190, F1: 0.94337237 Bal: 0.8959 - Val Loss: 0.26828200, Accuracy: 0.8972, F1: 0.9416 Bal: 0.8843\n","Epoch 256:      TX: Train Loss: 0.0283, Acc: 0.9930, F1: 0.9961 Bal: 0.9958 - Val Loss: 0.2482, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9232\n","           WALLETS: Train Loss: 0.25192741, Acc: 0.90497598, F1: 0.94625086 Bal: 0.8956 - Val Loss: 0.26861888, Accuracy: 0.9022, F1: 0.9446 Bal: 0.8845\n","Epoch 257:      TX: Train Loss: 0.0282, Acc: 0.9913, F1: 0.9951 Bal: 0.9950 - Val Loss: 0.2344, Accuracy: 0.9664, F1: 0.9813 Bal: 0.9274\n","           WALLETS: Train Loss: 0.25162211, Acc: 0.90348471, F1: 0.94535205 Bal: 0.8956 - Val Loss: 0.26818874, Accuracy: 0.9007, F1: 0.9437 Bal: 0.8847\n","Epoch 258:      TX: Train Loss: 0.0281, Acc: 0.9931, F1: 0.9962 Bal: 0.9961 - Val Loss: 0.2492, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9237\n","           WALLETS: Train Loss: 0.25137469, Acc: 0.90232725, F1: 0.94464790 Bal: 0.8962 - Val Loss: 0.26784325, Accuracy: 0.8993, F1: 0.9429 Bal: 0.8846\n","Epoch 259:      TX: Train Loss: 0.0280, Acc: 0.9914, F1: 0.9952 Bal: 0.9951 - Val Loss: 0.2348, Accuracy: 0.9669, F1: 0.9815 Bal: 0.9276\n","           WALLETS: Train Loss: 0.25115049, Acc: 0.90635840, F1: 0.94707680 Bal: 0.8961 - Val Loss: 0.26823121, Accuracy: 0.9038, F1: 0.9456 Bal: 0.8848\n","Epoch 260:      TX: Train Loss: 0.0278, Acc: 0.9930, F1: 0.9961 Bal: 0.9960 - Val Loss: 0.2478, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9235\n","           WALLETS: Train Loss: 0.25092399, Acc: 0.90134396, F1: 0.94403507 Bal: 0.8979 - Val Loss: 0.26735693, Accuracy: 0.8980, F1: 0.9421 Bal: 0.8860\n","Epoch 261:      TX: Train Loss: 0.0276, Acc: 0.9919, F1: 0.9955 Bal: 0.9954 - Val Loss: 0.2382, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9285\n","           WALLETS: Train Loss: 0.25065535, Acc: 0.90721470, F1: 0.94759106 Bal: 0.8960 - Val Loss: 0.26800132, Accuracy: 0.9047, F1: 0.9461 Bal: 0.8849\n","Epoch 262:      TX: Train Loss: 0.0274, Acc: 0.9927, F1: 0.9959 Bal: 0.9958 - Val Loss: 0.2442, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9250\n","           WALLETS: Train Loss: 0.25037110, Acc: 0.90171768, F1: 0.94425844 Bal: 0.8982 - Val Loss: 0.26700464, Accuracy: 0.8985, F1: 0.9423 Bal: 0.8862\n","Epoch 263:      TX: Train Loss: 0.0273, Acc: 0.9925, F1: 0.9958 Bal: 0.9957 - Val Loss: 0.2425, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9259\n","           WALLETS: Train Loss: 0.25006670, Acc: 0.90654707, F1: 0.94718690 Bal: 0.8964 - Val Loss: 0.26746678, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8850\n","Epoch 264:      TX: Train Loss: 0.0272, Acc: 0.9923, F1: 0.9957 Bal: 0.9956 - Val Loss: 0.2404, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9278\n","           WALLETS: Train Loss: 0.24977535, Acc: 0.90307470, F1: 0.94507736 Bal: 0.8982 - Val Loss: 0.26675159, Accuracy: 0.9002, F1: 0.9434 Bal: 0.8859\n","Epoch 265:      TX: Train Loss: 0.0271, Acc: 0.9928, F1: 0.9960 Bal: 0.9959 - Val Loss: 0.2459, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9245\n","           WALLETS: Train Loss: 0.24949098, Acc: 0.90552387, F1: 0.94656811 Bal: 0.8968 - Val Loss: 0.26690105, Accuracy: 0.9027, F1: 0.9449 Bal: 0.8851\n","Epoch 266:      TX: Train Loss: 0.0270, Acc: 0.9920, F1: 0.9955 Bal: 0.9954 - Val Loss: 0.2376, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9285\n","           WALLETS: Train Loss: 0.24922298, Acc: 0.90454057, F1: 0.94596021 Bal: 0.8983 - Val Loss: 0.26655513, Accuracy: 0.9016, F1: 0.9442 Bal: 0.8860\n","Epoch 267:      TX: Train Loss: 0.0270, Acc: 0.9931, F1: 0.9962 Bal: 0.9960 - Val Loss: 0.2486, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9240\n","           WALLETS: Train Loss: 0.24896063, Acc: 0.90485261, F1: 0.94614637 Bal: 0.8985 - Val Loss: 0.26640978, Accuracy: 0.9019, F1: 0.9444 Bal: 0.8862\n","Epoch 268:      TX: Train Loss: 0.0269, Acc: 0.9918, F1: 0.9954 Bal: 0.9953 - Val Loss: 0.2363, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9283\n","           WALLETS: Train Loss: 0.24870512, Acc: 0.90569440, F1: 0.94666270 Bal: 0.8975 - Val Loss: 0.26637292, Accuracy: 0.9027, F1: 0.9449 Bal: 0.8857\n","Epoch 269:      TX: Train Loss: 0.0268, Acc: 0.9932, F1: 0.9962 Bal: 0.9961 - Val Loss: 0.2494, Accuracy: 0.9715, F1: 0.9842 Bal: 0.9243\n","           WALLETS: Train Loss: 0.24845868, Acc: 0.90410154, F1: 0.94568947 Bal: 0.8989 - Val Loss: 0.26597276, Accuracy: 0.9012, F1: 0.9440 Bal: 0.8868\n","Epoch 270:      TX: Train Loss: 0.0266, Acc: 0.9920, F1: 0.9955 Bal: 0.9954 - Val Loss: 0.2368, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9293\n","           WALLETS: Train Loss: 0.24821694, Acc: 0.90701514, F1: 0.94744527 Bal: 0.8986 - Val Loss: 0.26620698, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8866\n","Epoch 271:      TX: Train Loss: 0.0265, Acc: 0.9931, F1: 0.9962 Bal: 0.9961 - Val Loss: 0.2481, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9251\n","           WALLETS: Train Loss: 0.24799810, Acc: 0.90321621, F1: 0.94514954 Bal: 0.8995 - Val Loss: 0.26551154, Accuracy: 0.9002, F1: 0.9434 Bal: 0.8870\n","Epoch 272:      TX: Train Loss: 0.0263, Acc: 0.9924, F1: 0.9958 Bal: 0.9956 - Val Loss: 0.2395, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9265\n","           WALLETS: Train Loss: 0.24780610, Acc: 0.90849189, F1: 0.94834402 Bal: 0.8973 - Val Loss: 0.26621720, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8857\n","Epoch 273:      TX: Train Loss: 0.0262, Acc: 0.9929, F1: 0.9960 Bal: 0.9959 - Val Loss: 0.2451, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9246\n","           WALLETS: Train Loss: 0.24770345, Acc: 0.90116979, F1: 0.94390649 Bal: 0.9001 - Val Loss: 0.26507375, Accuracy: 0.8983, F1: 0.9422 Bal: 0.8883\n","Epoch 274:      TX: Train Loss: 0.0261, Acc: 0.9927, F1: 0.9959 Bal: 0.9958 - Val Loss: 0.2431, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9262\n","           WALLETS: Train Loss: 0.24774206, Acc: 0.91186993, F1: 0.95036548 Bal: 0.8970 - Val Loss: 0.26683143, Accuracy: 0.9094, F1: 0.9489 Bal: 0.8858\n","Epoch 275:      TX: Train Loss: 0.0260, Acc: 0.9927, F1: 0.9959 Bal: 0.9958 - Val Loss: 0.2421, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9261\n","           WALLETS: Train Loss: 0.24817494, Acc: 0.89629323, F1: 0.94093261 Bal: 0.9012 - Val Loss: 0.26495707, Accuracy: 0.8934, F1: 0.9392 Bal: 0.8899\n","Epoch 276:      TX: Train Loss: 0.0259, Acc: 0.9931, F1: 0.9962 Bal: 0.9960 - Val Loss: 0.2463, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.24910146, Acc: 0.91816157, F1: 0.95411426 Bal: 0.8955 - Val Loss: 0.26939243, Accuracy: 0.9160, F1: 0.9529 Bal: 0.8833\n","Epoch 277:      TX: Train Loss: 0.0258, Acc: 0.9925, F1: 0.9958 Bal: 0.9957 - Val Loss: 0.2398, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9280\n","           WALLETS: Train Loss: 0.25089225, Acc: 0.88706985, F1: 0.93528157 Bal: 0.9008 - Val Loss: 0.26658183, Accuracy: 0.8842, F1: 0.9335 Bal: 0.8907\n","Epoch 278:      TX: Train Loss: 0.0258, Acc: 0.9934, F1: 0.9963 Bal: 0.9962 - Val Loss: 0.2491, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9255\n","           WALLETS: Train Loss: 0.25142309, Acc: 0.92316149, F1: 0.95708075 Bal: 0.8930 - Val Loss: 0.27285355, Accuracy: 0.9210, F1: 0.9559 Bal: 0.8805\n","Epoch 279:      TX: Train Loss: 0.0257, Acc: 0.9923, F1: 0.9957 Bal: 0.9956 - Val Loss: 0.2379, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9276\n","           WALLETS: Train Loss: 0.24983925, Acc: 0.88906547, F1: 0.93650576 Bal: 0.9013 - Val Loss: 0.26590627, Accuracy: 0.8857, F1: 0.9345 Bal: 0.8903\n","Epoch 280:      TX: Train Loss: 0.0256, Acc: 0.9936, F1: 0.9964 Bal: 0.9963 - Val Loss: 0.2508, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9256\n","           WALLETS: Train Loss: 0.24636967, Acc: 0.91245773, F1: 0.95071385 Bal: 0.8972 - Val Loss: 0.26603240, Accuracy: 0.9101, F1: 0.9493 Bal: 0.8859\n","Epoch 281:      TX: Train Loss: 0.0255, Acc: 0.9923, F1: 0.9957 Bal: 0.9956 - Val Loss: 0.2375, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9286\n","           WALLETS: Train Loss: 0.24604297, Acc: 0.91215294, F1: 0.95052507 Bal: 0.8980 - Val Loss: 0.26567718, Accuracy: 0.9097, F1: 0.9491 Bal: 0.8868\n","Epoch 282:      TX: Train Loss: 0.0254, Acc: 0.9937, F1: 0.9965 Bal: 0.9964 - Val Loss: 0.2509, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9255\n","           WALLETS: Train Loss: 0.24818538, Acc: 0.89131145, F1: 0.93788169 Bal: 0.9016 - Val Loss: 0.26477078, Accuracy: 0.8883, F1: 0.9361 Bal: 0.8912\n","Epoch 283:      TX: Train Loss: 0.0253, Acc: 0.9925, F1: 0.9958 Bal: 0.9957 - Val Loss: 0.2393, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9265\n","           WALLETS: Train Loss: 0.24807760, Acc: 0.91955850, F1: 0.95493866 Bal: 0.8956 - Val Loss: 0.26917806, Accuracy: 0.9174, F1: 0.9537 Bal: 0.8829\n","Epoch 284:      TX: Train Loss: 0.0252, Acc: 0.9935, F1: 0.9964 Bal: 0.9963 - Val Loss: 0.2488, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.24580206, Acc: 0.89879320, F1: 0.94243941 Bal: 0.9025 - Val Loss: 0.26354936, Accuracy: 0.8951, F1: 0.9403 Bal: 0.8901\n","Epoch 285:      TX: Train Loss: 0.0250, Acc: 0.9928, F1: 0.9960 Bal: 0.9959 - Val Loss: 0.2428, Accuracy: 0.9699, F1: 0.9833 Bal: 0.9273\n","           WALLETS: Train Loss: 0.24485205, Acc: 0.90394914, F1: 0.94557320 Bal: 0.9013 - Val Loss: 0.26346451, Accuracy: 0.9012, F1: 0.9439 Bal: 0.8892\n","Epoch 286:      TX: Train Loss: 0.0249, Acc: 0.9931, F1: 0.9961 Bal: 0.9960 - Val Loss: 0.2455, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.24617893, Acc: 0.91706216, F1: 0.95345134 Bal: 0.8970 - Val Loss: 0.26705387, Accuracy: 0.9145, F1: 0.9520 Bal: 0.8852\n","Epoch 287:      TX: Train Loss: 0.0248, Acc: 0.9932, F1: 0.9962 Bal: 0.9961 - Val Loss: 0.2462, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.24642067, Acc: 0.89463868, F1: 0.93990480 Bal: 0.9028 - Val Loss: 0.26377836, Accuracy: 0.8912, F1: 0.9378 Bal: 0.8906\n","Epoch 288:      TX: Train Loss: 0.0248, Acc: 0.9929, F1: 0.9960 Bal: 0.9959 - Val Loss: 0.2433, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.24456865, Acc: 0.91260286, F1: 0.95076821 Bal: 0.9007 - Val Loss: 0.26484108, Accuracy: 0.9098, F1: 0.9491 Bal: 0.8889\n","Epoch 289:      TX: Train Loss: 0.0247, Acc: 0.9936, F1: 0.9964 Bal: 0.9963 - Val Loss: 0.2489, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.24408993, Acc: 0.91059636, F1: 0.94956442 Bal: 0.9013 - Val Loss: 0.26406243, Accuracy: 0.9076, F1: 0.9478 Bal: 0.8894\n","Epoch 290:      TX: Train Loss: 0.0246, Acc: 0.9928, F1: 0.9960 Bal: 0.9959 - Val Loss: 0.2417, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9269\n","           WALLETS: Train Loss: 0.24510331, Acc: 0.89680846, F1: 0.94122728 Bal: 0.9029 - Val Loss: 0.26299012, Accuracy: 0.8933, F1: 0.9391 Bal: 0.8914\n","Epoch 291:      TX: Train Loss: 0.0245, Acc: 0.9939, F1: 0.9966 Bal: 0.9965 - Val Loss: 0.2507, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9265\n","           WALLETS: Train Loss: 0.24475791, Acc: 0.91620586, F1: 0.95293259 Bal: 0.8982 - Val Loss: 0.26589650, Accuracy: 0.9133, F1: 0.9512 Bal: 0.8864\n","Epoch 292:      TX: Train Loss: 0.0245, Acc: 0.9926, F1: 0.9959 Bal: 0.9958 - Val Loss: 0.2402, Accuracy: 0.9684, F1: 0.9824 Bal: 0.9265\n","           WALLETS: Train Loss: 0.24351241, Acc: 0.90358993, F1: 0.94533919 Bal: 0.9029 - Val Loss: 0.26268059, Accuracy: 0.9006, F1: 0.9436 Bal: 0.8907\n","Epoch 293:      TX: Train Loss: 0.0244, Acc: 0.9941, F1: 0.9967 Bal: 0.9966 - Val Loss: 0.2524, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9265\n","           WALLETS: Train Loss: 0.24331142, Acc: 0.90395640, F1: 0.94555828 Bal: 0.9031 - Val Loss: 0.26251939, Accuracy: 0.9009, F1: 0.9438 Bal: 0.8909\n","Epoch 294:      TX: Train Loss: 0.0243, Acc: 0.9926, F1: 0.9959 Bal: 0.9958 - Val Loss: 0.2398, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9264\n","           WALLETS: Train Loss: 0.24387740, Acc: 0.91599179, F1: 0.95277914 Bal: 0.9012 - Val Loss: 0.26504689, Accuracy: 0.9128, F1: 0.9509 Bal: 0.8880\n","Epoch 295:      TX: Train Loss: 0.0242, Acc: 0.9941, F1: 0.9967 Bal: 0.9966 - Val Loss: 0.2532, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9265\n","           WALLETS: Train Loss: 0.24357231, Acc: 0.89979463, F1: 0.94303835 Bal: 0.9033 - Val Loss: 0.26226324, Accuracy: 0.8962, F1: 0.9409 Bal: 0.8910\n","Epoch 296:      TX: Train Loss: 0.0241, Acc: 0.9928, F1: 0.9960 Bal: 0.9959 - Val Loss: 0.2404, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9266\n","           WALLETS: Train Loss: 0.24262552, Acc: 0.91042220, F1: 0.94944941 Bal: 0.9024 - Val Loss: 0.26315564, Accuracy: 0.9073, F1: 0.9477 Bal: 0.8895\n","Epoch 297:      TX: Train Loss: 0.0240, Acc: 0.9941, F1: 0.9967 Bal: 0.9966 - Val Loss: 0.2520, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.24251191, Acc: 0.91139461, F1: 0.95002926 Bal: 0.9026 - Val Loss: 0.26326528, Accuracy: 0.9078, F1: 0.9479 Bal: 0.8892\n","Epoch 298:      TX: Train Loss: 0.0239, Acc: 0.9930, F1: 0.9961 Bal: 0.9960 - Val Loss: 0.2420, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9275\n","           WALLETS: Train Loss: 0.24287722, Acc: 0.90058562, F1: 0.94351269 Bal: 0.9038 - Val Loss: 0.26190081, Accuracy: 0.8973, F1: 0.9416 Bal: 0.8911\n","Epoch 299:      TX: Train Loss: 0.0238, Acc: 0.9940, F1: 0.9966 Bal: 0.9965 - Val Loss: 0.2503, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.24253762, Acc: 0.91452954, F1: 0.95190395 Bal: 0.9019 - Val Loss: 0.26385951, Accuracy: 0.9112, F1: 0.9500 Bal: 0.8886\n","Epoch 300:      TX: Train Loss: 0.0237, Acc: 0.9932, F1: 0.9962 Bal: 0.9961 - Val Loss: 0.2442, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9268\n","           WALLETS: Train Loss: 0.24185550, Acc: 0.90590122, F1: 0.94672446 Bal: 0.9037 - Val Loss: 0.26184642, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8919\n","Epoch 301:      TX: Train Loss: 0.0236, Acc: 0.9939, F1: 0.9966 Bal: 0.9965 - Val Loss: 0.2486, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.24166976, Acc: 0.90585405, F1: 0.94669699 Bal: 0.9036 - Val Loss: 0.26174504, Accuracy: 0.9032, F1: 0.9452 Bal: 0.8919\n","Epoch 302:      TX: Train Loss: 0.0235, Acc: 0.9935, F1: 0.9964 Bal: 0.9963 - Val Loss: 0.2459, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9270\n","           WALLETS: Train Loss: 0.24183144, Acc: 0.91406874, F1: 0.95162282 Bal: 0.9027 - Val Loss: 0.26328677, Accuracy: 0.9106, F1: 0.9496 Bal: 0.8887\n","Epoch 303:      TX: Train Loss: 0.0234, Acc: 0.9937, F1: 0.9965 Bal: 0.9964 - Val Loss: 0.2471, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9260\n","           WALLETS: Train Loss: 0.24167860, Acc: 0.90240345, F1: 0.94461124 Bal: 0.9040 - Val Loss: 0.26129085, Accuracy: 0.8993, F1: 0.9428 Bal: 0.8919\n","Epoch 304:      TX: Train Loss: 0.0234, Acc: 0.9939, F1: 0.9966 Bal: 0.9965 - Val Loss: 0.2475, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9260\n","           WALLETS: Train Loss: 0.24113786, Acc: 0.91147443, F1: 0.95006795 Bal: 0.9035 - Val Loss: 0.26230296, Accuracy: 0.9082, F1: 0.9481 Bal: 0.8907\n","Epoch 305:      TX: Train Loss: 0.0233, Acc: 0.9936, F1: 0.9964 Bal: 0.9963 - Val Loss: 0.2459, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9257\n","           WALLETS: Train Loss: 0.24083735, Acc: 0.90934094, F1: 0.94878974 Bal: 0.9037 - Val Loss: 0.26175222, Accuracy: 0.9061, F1: 0.9469 Bal: 0.8905\n","Epoch 306:      TX: Train Loss: 0.0232, Acc: 0.9939, F1: 0.9966 Bal: 0.9965 - Val Loss: 0.2490, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.24086843, Acc: 0.90444986, F1: 0.94584446 Bal: 0.9042 - Val Loss: 0.26105344, Accuracy: 0.9017, F1: 0.9442 Bal: 0.8925\n","Epoch 307:      TX: Train Loss: 0.0232, Acc: 0.9935, F1: 0.9964 Bal: 0.9964 - Val Loss: 0.2444, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9256\n","           WALLETS: Train Loss: 0.24080639, Acc: 0.91397803, F1: 0.95156275 Bal: 0.9033 - Val Loss: 0.26259455, Accuracy: 0.9104, F1: 0.9495 Bal: 0.8891\n","Epoch 308:      TX: Train Loss: 0.0231, Acc: 0.9941, F1: 0.9967 Bal: 0.9966 - Val Loss: 0.2508, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.24048120, Acc: 0.90484536, F1: 0.94608092 Bal: 0.9044 - Val Loss: 0.26088518, Accuracy: 0.9021, F1: 0.9445 Bal: 0.8927\n","Epoch 309:      TX: Train Loss: 0.0231, Acc: 0.9933, F1: 0.9963 Bal: 0.9963 - Val Loss: 0.2422, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9261\n","           WALLETS: Train Loss: 0.24010237, Acc: 0.91001582, F1: 0.94919074 Bal: 0.9040 - Val Loss: 0.26143554, Accuracy: 0.9069, F1: 0.9474 Bal: 0.8911\n","Epoch 310:      TX: Train Loss: 0.0230, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2540, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9241\n","           WALLETS: Train Loss: 0.23994417, Acc: 0.91081044, F1: 0.94966510 Bal: 0.9041 - Val Loss: 0.26146215, Accuracy: 0.9076, F1: 0.9478 Bal: 0.8911\n","Epoch 311:      TX: Train Loss: 0.0230, Acc: 0.9929, F1: 0.9960 Bal: 0.9961 - Val Loss: 0.2389, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9280\n","           WALLETS: Train Loss: 0.23992458, Acc: 0.90509935, F1: 0.94623170 Bal: 0.9046 - Val Loss: 0.26056778, Accuracy: 0.9020, F1: 0.9444 Bal: 0.8927\n","Epoch 312:      TX: Train Loss: 0.0231, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2591, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9237\n","           WALLETS: Train Loss: 0.23977837, Acc: 0.91348456, F1: 0.95126199 Bal: 0.9041 - Val Loss: 0.26188469, Accuracy: 0.9102, F1: 0.9493 Bal: 0.8907\n","Epoch 313:      TX: Train Loss: 0.0232, Acc: 0.9922, F1: 0.9957 Bal: 0.9957 - Val Loss: 0.2345, Accuracy: 0.9671, F1: 0.9816 Bal: 0.9287\n","           WALLETS: Train Loss: 0.23949620, Acc: 0.90597016, F1: 0.94675222 Bal: 0.9050 - Val Loss: 0.26044682, Accuracy: 0.9027, F1: 0.9448 Bal: 0.8928\n","Epoch 314:      TX: Train Loss: 0.0231, Acc: 0.9952, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2628, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9240\n","           WALLETS: Train Loss: 0.23918337, Acc: 0.91041857, F1: 0.94942675 Bal: 0.9045 - Val Loss: 0.26097557, Accuracy: 0.9072, F1: 0.9476 Bal: 0.8911\n","Epoch 315:      TX: Train Loss: 0.0231, Acc: 0.9922, F1: 0.9957 Bal: 0.9957 - Val Loss: 0.2345, Accuracy: 0.9673, F1: 0.9818 Bal: 0.9288\n","           WALLETS: Train Loss: 0.23899469, Acc: 0.91038592, F1: 0.94940531 Bal: 0.9047 - Val Loss: 0.26084328, Accuracy: 0.9071, F1: 0.9475 Bal: 0.8913\n","Epoch 316:      TX: Train Loss: 0.0227, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2577, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9248\n","           WALLETS: Train Loss: 0.23889808, Acc: 0.90690629, F1: 0.94731373 Bal: 0.9052 - Val Loss: 0.26022905, Accuracy: 0.9038, F1: 0.9455 Bal: 0.8934\n","Epoch 317:      TX: Train Loss: 0.0224, Acc: 0.9937, F1: 0.9965 Bal: 0.9965 - Val Loss: 0.2453, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9265\n","           WALLETS: Train Loss: 0.23877555, Acc: 0.91294031, F1: 0.95093211 Bal: 0.9046 - Val Loss: 0.26122969, Accuracy: 0.9091, F1: 0.9487 Bal: 0.8904\n","Epoch 318:      TX: Train Loss: 0.0223, Acc: 0.9936, F1: 0.9964 Bal: 0.9964 - Val Loss: 0.2447, Accuracy: 0.9699, F1: 0.9833 Bal: 0.9264\n","           WALLETS: Train Loss: 0.23858738, Acc: 0.90639105, F1: 0.94700190 Bal: 0.9054 - Val Loss: 0.25996977, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8932\n","Epoch 319:      TX: Train Loss: 0.0224, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2571, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9244\n","           WALLETS: Train Loss: 0.23833260, Acc: 0.91210577, F1: 0.95043196 Bal: 0.9049 - Val Loss: 0.26075643, Accuracy: 0.9084, F1: 0.9483 Bal: 0.8913\n","Epoch 320:      TX: Train Loss: 0.0225, Acc: 0.9930, F1: 0.9961 Bal: 0.9961 - Val Loss: 0.2372, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9286\n","           WALLETS: Train Loss: 0.23809592, Acc: 0.90868783, F1: 0.94838273 Bal: 0.9053 - Val Loss: 0.26004031, Accuracy: 0.9057, F1: 0.9466 Bal: 0.8928\n","Epoch 321:      TX: Train Loss: 0.0224, Acc: 0.9949, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2591, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9249\n","           WALLETS: Train Loss: 0.23790339, Acc: 0.90948607, F1: 0.94886061 Bal: 0.9053 - Val Loss: 0.26006618, Accuracy: 0.9064, F1: 0.9470 Bal: 0.8927\n","Epoch 322:      TX: Train Loss: 0.0221, Acc: 0.9934, F1: 0.9963 Bal: 0.9963 - Val Loss: 0.2420, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9260\n","           WALLETS: Train Loss: 0.23775180, Acc: 0.91135470, F1: 0.94997942 Bal: 0.9053 - Val Loss: 0.26028588, Accuracy: 0.9078, F1: 0.9479 Bal: 0.8920\n","Epoch 323:      TX: Train Loss: 0.0220, Acc: 0.9941, F1: 0.9967 Bal: 0.9968 - Val Loss: 0.2497, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.23762135, Acc: 0.90772630, F1: 0.94780055 Bal: 0.9058 - Val Loss: 0.25956628, Accuracy: 0.9043, F1: 0.9458 Bal: 0.8925\n","Epoch 324:      TX: Train Loss: 0.0219, Acc: 0.9945, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2531, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9252\n","           WALLETS: Train Loss: 0.23747218, Acc: 0.91286048, F1: 0.95087929 Bal: 0.9052 - Val Loss: 0.26038504, Accuracy: 0.9092, F1: 0.9488 Bal: 0.8917\n","Epoch 325:      TX: Train Loss: 0.0220, Acc: 0.9934, F1: 0.9963 Bal: 0.9963 - Val Loss: 0.2408, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9269\n","           WALLETS: Train Loss: 0.23731159, Acc: 0.90726913, F1: 0.94752512 Bal: 0.9059 - Val Loss: 0.25934368, Accuracy: 0.9037, F1: 0.9455 Bal: 0.8925\n","Epoch 326:      TX: Train Loss: 0.0220, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2579, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9260\n","           WALLETS: Train Loss: 0.23711911, Acc: 0.91298022, F1: 0.95094929 Bal: 0.9054 - Val Loss: 0.26019666, Accuracy: 0.9091, F1: 0.9487 Bal: 0.8918\n","Epoch 327:      TX: Train Loss: 0.0218, Acc: 0.9934, F1: 0.9963 Bal: 0.9964 - Val Loss: 0.2420, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9270\n","           WALLETS: Train Loss: 0.23692694, Acc: 0.90798755, F1: 0.94795560 Bal: 0.9060 - Val Loss: 0.25920239, Accuracy: 0.9046, F1: 0.9459 Bal: 0.8928\n","Epoch 328:      TX: Train Loss: 0.0217, Acc: 0.9945, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2521, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.23672345, Acc: 0.91234525, F1: 0.95056802 Bal: 0.9056 - Val Loss: 0.25982842, Accuracy: 0.9087, F1: 0.9484 Bal: 0.8921\n","Epoch 329:      TX: Train Loss: 0.0216, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2506, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.23653136, Acc: 0.90903978, F1: 0.94858622 Bal: 0.9060 - Val Loss: 0.25914750, Accuracy: 0.9056, F1: 0.9466 Bal: 0.8928\n","Epoch 330:      TX: Train Loss: 0.0216, Acc: 0.9937, F1: 0.9965 Bal: 0.9965 - Val Loss: 0.2441, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9261\n","           WALLETS: Train Loss: 0.23634163, Acc: 0.91161231, F1: 0.95012551 Bal: 0.9061 - Val Loss: 0.25943112, Accuracy: 0.9079, F1: 0.9480 Bal: 0.8924\n","Epoch 331:      TX: Train Loss: 0.0216, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2561, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9256\n","           WALLETS: Train Loss: 0.23616326, Acc: 0.91006299, F1: 0.94919791 Bal: 0.9062 - Val Loss: 0.25907505, Accuracy: 0.9065, F1: 0.9471 Bal: 0.8925\n","Epoch 332:      TX: Train Loss: 0.0215, Acc: 0.9935, F1: 0.9964 Bal: 0.9964 - Val Loss: 0.2427, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.23598769, Acc: 0.91086849, F1: 0.94967972 Bal: 0.9062 - Val Loss: 0.25908729, Accuracy: 0.9072, F1: 0.9475 Bal: 0.8924\n","Epoch 333:      TX: Train Loss: 0.0214, Acc: 0.9947, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2540, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23581691, Acc: 0.91104628, F1: 0.94978576 Bal: 0.9063 - Val Loss: 0.25901958, Accuracy: 0.9074, F1: 0.9477 Bal: 0.8925\n","Epoch 334:      TX: Train Loss: 0.0213, Acc: 0.9943, F1: 0.9968 Bal: 0.9968 - Val Loss: 0.2482, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9259\n","           WALLETS: Train Loss: 0.23564972, Acc: 0.91026618, F1: 0.94931663 Bal: 0.9065 - Val Loss: 0.25878710, Accuracy: 0.9066, F1: 0.9472 Bal: 0.8925\n","Epoch 335:      TX: Train Loss: 0.0212, Acc: 0.9943, F1: 0.9968 Bal: 0.9968 - Val Loss: 0.2477, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9259\n","           WALLETS: Train Loss: 0.23548564, Acc: 0.91204046, F1: 0.95037705 Bal: 0.9066 - Val Loss: 0.25898188, Accuracy: 0.9082, F1: 0.9481 Bal: 0.8923\n","Epoch 336:      TX: Train Loss: 0.0212, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2537, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23533246, Acc: 0.90963121, F1: 0.94893486 Bal: 0.9066 - Val Loss: 0.25850242, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8927\n","Epoch 337:      TX: Train Loss: 0.0211, Acc: 0.9938, F1: 0.9966 Bal: 0.9966 - Val Loss: 0.2442, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.23518677, Acc: 0.91308181, F1: 0.95099894 Bal: 0.9065 - Val Loss: 0.25904244, Accuracy: 0.9089, F1: 0.9486 Bal: 0.8919\n","Epoch 338:      TX: Train Loss: 0.0211, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2549, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23507461, Acc: 0.90830685, F1: 0.94813748 Bal: 0.9070 - Val Loss: 0.25815651, Accuracy: 0.9046, F1: 0.9459 Bal: 0.8936\n","Epoch 339:      TX: Train Loss: 0.0210, Acc: 0.9941, F1: 0.9967 Bal: 0.9968 - Val Loss: 0.2459, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.23501232, Acc: 0.91513548, F1: 0.95222240 Bal: 0.9065 - Val Loss: 0.25939775, Accuracy: 0.9113, F1: 0.9500 Bal: 0.8924\n","Epoch 340:      TX: Train Loss: 0.0209, Acc: 0.9945, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2513, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9265\n","           WALLETS: Train Loss: 0.23509914, Acc: 0.90527351, F1: 0.94631448 Bal: 0.9068 - Val Loss: 0.25778008, Accuracy: 0.9012, F1: 0.9439 Bal: 0.8927\n","Epoch 341:      TX: Train Loss: 0.0208, Acc: 0.9945, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2503, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.23542917, Acc: 0.91917026, F1: 0.95462406 Bal: 0.9056 - Val Loss: 0.26077059, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8902\n","Epoch 342:      TX: Train Loss: 0.0208, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2471, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9257\n","           WALLETS: Train Loss: 0.23640031, Acc: 0.89853921, F1: 0.94224299 Bal: 0.9063 - Val Loss: 0.25801265, Accuracy: 0.8941, F1: 0.9396 Bal: 0.8917\n","Epoch 343:      TX: Train Loss: 0.0208, Acc: 0.9949, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2541, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23802313, Acc: 0.92573040, F1: 0.95852103 Bal: 0.9013 - Val Loss: 0.26508293, Accuracy: 0.9219, F1: 0.9563 Bal: 0.8855\n","Epoch 344:      TX: Train Loss: 0.0207, Acc: 0.9941, F1: 0.9967 Bal: 0.9967 - Val Loss: 0.2449, Accuracy: 0.9699, F1: 0.9833 Bal: 0.9273\n","           WALLETS: Train Loss: 0.24076135, Acc: 0.88725490, F1: 0.93535011 Bal: 0.9045 - Val Loss: 0.26071823, Accuracy: 0.8839, F1: 0.9333 Bal: 0.8928\n","Epoch 345:      TX: Train Loss: 0.0207, Acc: 0.9949, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2548, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.24077344, Acc: 0.92968535, F1: 0.96085406 Bal: 0.8983 - Val Loss: 0.26906157, Accuracy: 0.9256, F1: 0.9586 Bal: 0.8818\n","Epoch 346:      TX: Train Loss: 0.0206, Acc: 0.9943, F1: 0.9968 Bal: 0.9968 - Val Loss: 0.2455, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.23802064, Acc: 0.89299502, F1: 0.93886723 Bal: 0.9055 - Val Loss: 0.25896469, Accuracy: 0.8892, F1: 0.9366 Bal: 0.8922\n","Epoch 347:      TX: Train Loss: 0.0205, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2525, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23395768, Acc: 0.91688437, F1: 0.95325989 Bal: 0.9067 - Val Loss: 0.25913253, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8922\n","Epoch 348:      TX: Train Loss: 0.0204, Acc: 0.9945, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2488, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.23449594, Acc: 0.91990682, F1: 0.95505796 Bal: 0.9057 - Val Loss: 0.26036558, Accuracy: 0.9159, F1: 0.9528 Bal: 0.8895\n","Epoch 349:      TX: Train Loss: 0.0204, Acc: 0.9946, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2493, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.23756710, Acc: 0.89244713, F1: 0.93852886 Bal: 0.9057 - Val Loss: 0.25853601, Accuracy: 0.8885, F1: 0.9362 Bal: 0.8924\n","Epoch 350:      TX: Train Loss: 0.0203, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2519, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9265\n","           WALLETS: Train Loss: 0.23695670, Acc: 0.92584288, F1: 0.95857050 Bal: 0.9034 - Val Loss: 0.26440328, Accuracy: 0.9222, F1: 0.9565 Bal: 0.8870\n","Epoch 351:      TX: Train Loss: 0.0203, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2469, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9256\n","           WALLETS: Train Loss: 0.23396447, Acc: 0.90337586, F1: 0.94516808 Bal: 0.9069 - Val Loss: 0.25689715, Accuracy: 0.8988, F1: 0.9425 Bal: 0.8924\n","Epoch 352:      TX: Train Loss: 0.0203, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2537, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.23316346, Acc: 0.90835039, F1: 0.94815849 Bal: 0.9075 - Val Loss: 0.25694627, Accuracy: 0.9040, F1: 0.9456 Bal: 0.8930\n","Epoch 353:      TX: Train Loss: 0.0202, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2463, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9265\n","           WALLETS: Train Loss: 0.23507547, Acc: 0.92378920, F1: 0.95735488 Bal: 0.9047 - Val Loss: 0.26221758, Accuracy: 0.9197, F1: 0.9550 Bal: 0.8889\n","Epoch 354:      TX: Train Loss: 0.0202, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2540, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.23540927, Acc: 0.89726564, F1: 0.94146275 Bal: 0.9067 - Val Loss: 0.25745451, Accuracy: 0.8928, F1: 0.9388 Bal: 0.8918\n","Epoch 355:      TX: Train Loss: 0.0201, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2475, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9256\n","           WALLETS: Train Loss: 0.23305444, Acc: 0.91788218, F1: 0.95384917 Bal: 0.9070 - Val Loss: 0.25901979, Accuracy: 0.9140, F1: 0.9516 Bal: 0.8923\n","Epoch 356:      TX: Train Loss: 0.0200, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2525, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.23262477, Acc: 0.91618046, F1: 0.95283498 Bal: 0.9075 - Val Loss: 0.25818262, Accuracy: 0.9124, F1: 0.9507 Bal: 0.8925\n","Epoch 357:      TX: Train Loss: 0.0200, Acc: 0.9946, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2491, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9259\n","           WALLETS: Train Loss: 0.23409709, Acc: 0.89981640, F1: 0.94301241 Bal: 0.9069 - Val Loss: 0.25668612, Accuracy: 0.8950, F1: 0.9401 Bal: 0.8916\n","Epoch 358:      TX: Train Loss: 0.0199, Acc: 0.9949, F1: 0.9971 Bal: 0.9972 - Val Loss: 0.2509, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.23375541, Acc: 0.92186253, F1: 0.95621285 Bal: 0.9057 - Val Loss: 0.26084262, Accuracy: 0.9177, F1: 0.9538 Bal: 0.8889\n","Epoch 359:      TX: Train Loss: 0.0199, Acc: 0.9949, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2505, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.23223220, Acc: 0.90790409, F1: 0.94788540 Bal: 0.9080 - Val Loss: 0.25643745, Accuracy: 0.9033, F1: 0.9452 Bal: 0.8928\n","Epoch 360:      TX: Train Loss: 0.0198, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2499, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.23208265, Acc: 0.90804560, F1: 0.94797113 Bal: 0.9079 - Val Loss: 0.25626886, Accuracy: 0.9031, F1: 0.9451 Bal: 0.8928\n","Epoch 361:      TX: Train Loss: 0.0198, Acc: 0.9949, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2516, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.23295073, Acc: 0.92126384, F1: 0.95585375 Bal: 0.9064 - Val Loss: 0.25984636, Accuracy: 0.9169, F1: 0.9534 Bal: 0.8895\n","Epoch 362:      TX: Train Loss: 0.0197, Acc: 0.9946, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2493, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9260\n","           WALLETS: Train Loss: 0.23269770, Acc: 0.90292957, F1: 0.94489224 Bal: 0.9075 - Val Loss: 0.25616580, Accuracy: 0.8984, F1: 0.9422 Bal: 0.8923\n","Epoch 363:      TX: Train Loss: 0.0197, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2529, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9265\n","           WALLETS: Train Loss: 0.23156710, Acc: 0.91552009, F1: 0.95243912 Bal: 0.9078 - Val Loss: 0.25749218, Accuracy: 0.9113, F1: 0.9500 Bal: 0.8921\n","Epoch 364:      TX: Train Loss: 0.0196, Acc: 0.9946, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2483, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9255\n","           WALLETS: Train Loss: 0.23151110, Acc: 0.91667755, F1: 0.95312589 Bal: 0.9079 - Val Loss: 0.25760728, Accuracy: 0.9127, F1: 0.9508 Bal: 0.8925\n","Epoch 365:      TX: Train Loss: 0.0196, Acc: 0.9951, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2544, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23214018, Acc: 0.90392375, F1: 0.94549100 Bal: 0.9077 - Val Loss: 0.25584465, Accuracy: 0.8994, F1: 0.9428 Bal: 0.8925\n","Epoch 366:      TX: Train Loss: 0.0195, Acc: 0.9946, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2470, Accuracy: 0.9699, F1: 0.9833 Bal: 0.9254\n","           WALLETS: Train Loss: 0.23175584, Acc: 0.91948593, F1: 0.95479584 Bal: 0.9073 - Val Loss: 0.25867960, Accuracy: 0.9154, F1: 0.9525 Bal: 0.8913\n","Epoch 367:      TX: Train Loss: 0.0195, Acc: 0.9954, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2563, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.23099200, Acc: 0.91029158, F1: 0.94931509 Bal: 0.9082 - Val Loss: 0.25613734, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8936\n","Epoch 368:      TX: Train Loss: 0.0195, Acc: 0.9945, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2453, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9262\n","           WALLETS: Train Loss: 0.23089962, Acc: 0.90967112, F1: 0.94894119 Bal: 0.9084 - Val Loss: 0.25589913, Accuracy: 0.9050, F1: 0.9462 Bal: 0.8934\n","Epoch 369:      TX: Train Loss: 0.0195, Acc: 0.9956, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2589, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9257\n","           WALLETS: Train Loss: 0.23125140, Acc: 0.91914123, F1: 0.95459204 Bal: 0.9073 - Val Loss: 0.25817949, Accuracy: 0.9150, F1: 0.9522 Bal: 0.8911\n","Epoch 370:      TX: Train Loss: 0.0195, Acc: 0.9943, F1: 0.9968 Bal: 0.9968 - Val Loss: 0.2429, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9271\n","           WALLETS: Train Loss: 0.23108940, Acc: 0.90577060, F1: 0.94660092 Bal: 0.9081 - Val Loss: 0.25550279, Accuracy: 0.9012, F1: 0.9439 Bal: 0.8926\n","Epoch 371:      TX: Train Loss: 0.0195, Acc: 0.9958, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2620, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9260\n","           WALLETS: Train Loss: 0.23048575, Acc: 0.91570151, F1: 0.95254223 Bal: 0.9083 - Val Loss: 0.25690633, Accuracy: 0.9114, F1: 0.9500 Bal: 0.8923\n","Epoch 372:      TX: Train Loss: 0.0195, Acc: 0.9941, F1: 0.9967 Bal: 0.9967 - Val Loss: 0.2410, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9267\n","           WALLETS: Train Loss: 0.23026469, Acc: 0.91479804, F1: 0.95200271 Bal: 0.9086 - Val Loss: 0.25652632, Accuracy: 0.9105, F1: 0.9495 Bal: 0.8929\n","Epoch 373:      TX: Train Loss: 0.0194, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2633, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9261\n","           WALLETS: Train Loss: 0.23047715, Acc: 0.90784241, F1: 0.94784332 Bal: 0.9085 - Val Loss: 0.25541770, Accuracy: 0.9029, F1: 0.9449 Bal: 0.8929\n","Epoch 374:      TX: Train Loss: 0.0194, Acc: 0.9942, F1: 0.9968 Bal: 0.9968 - Val Loss: 0.2423, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9259\n","           WALLETS: Train Loss: 0.23040372, Acc: 0.91835024, F1: 0.95411999 Bal: 0.9077 - Val Loss: 0.25761965, Accuracy: 0.9144, F1: 0.9518 Bal: 0.8923\n","Epoch 375:      TX: Train Loss: 0.0192, Acc: 0.9957, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2601, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9259\n","           WALLETS: Train Loss: 0.23001964, Acc: 0.90939174, F1: 0.94877097 Bal: 0.9087 - Val Loss: 0.25549167, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8937\n","Epoch 376:      TX: Train Loss: 0.0191, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2479, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9253\n","           WALLETS: Train Loss: 0.22969705, Acc: 0.91333580, F1: 0.95112933 Bal: 0.9088 - Val Loss: 0.25591889, Accuracy: 0.9089, F1: 0.9485 Bal: 0.8934\n","Epoch 377:      TX: Train Loss: 0.0190, Acc: 0.9951, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2533, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.22972295, Acc: 0.91647799, F1: 0.95300202 Bal: 0.9085 - Val Loss: 0.25662741, Accuracy: 0.9122, F1: 0.9505 Bal: 0.8930\n","Epoch 378:      TX: Train Loss: 0.0189, Acc: 0.9954, F1: 0.9975 Bal: 0.9975 - Val Loss: 0.2548, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22977659, Acc: 0.90825968, F1: 0.94809002 Bal: 0.9089 - Val Loss: 0.25512102, Accuracy: 0.9034, F1: 0.9453 Bal: 0.8930\n","Epoch 379:      TX: Train Loss: 0.0189, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2474, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9253\n","           WALLETS: Train Loss: 0.22956981, Acc: 0.91739597, F1: 0.95354503 Bal: 0.9088 - Val Loss: 0.25685239, Accuracy: 0.9131, F1: 0.9510 Bal: 0.8924\n","Epoch 380:      TX: Train Loss: 0.0189, Acc: 0.9958, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9256\n","           WALLETS: Train Loss: 0.22924179, Acc: 0.91145629, F1: 0.95000502 Bal: 0.9090 - Val Loss: 0.25528145, Accuracy: 0.9068, F1: 0.9473 Bal: 0.8934\n","Epoch 381:      TX: Train Loss: 0.0189, Acc: 0.9944, F1: 0.9969 Bal: 0.9969 - Val Loss: 0.2445, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22906514, Acc: 0.91272623, F1: 0.95076363 Bal: 0.9090 - Val Loss: 0.25539950, Accuracy: 0.9085, F1: 0.9483 Bal: 0.8938\n","Epoch 382:      TX: Train Loss: 0.0189, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2615, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22905260, Acc: 0.91663401, F1: 0.95309240 Bal: 0.9088 - Val Loss: 0.25627041, Accuracy: 0.9122, F1: 0.9505 Bal: 0.8933\n","Epoch 383:      TX: Train Loss: 0.0188, Acc: 0.9945, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2453, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9261\n","           WALLETS: Train Loss: 0.22903843, Acc: 0.90936634, F1: 0.94875104 Bal: 0.9092 - Val Loss: 0.25486726, Accuracy: 0.9045, F1: 0.9459 Bal: 0.8934\n","Epoch 384:      TX: Train Loss: 0.0187, Acc: 0.9958, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9255\n","           WALLETS: Train Loss: 0.22884311, Acc: 0.91708756, F1: 0.95335988 Bal: 0.9090 - Val Loss: 0.25629222, Accuracy: 0.9128, F1: 0.9509 Bal: 0.8933\n","Epoch 385:      TX: Train Loss: 0.0186, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2493, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9253\n","           WALLETS: Train Loss: 0.22859441, Acc: 0.91178285, F1: 0.95019859 Bal: 0.9091 - Val Loss: 0.25494874, Accuracy: 0.9072, F1: 0.9475 Bal: 0.8933\n","Epoch 386:      TX: Train Loss: 0.0186, Acc: 0.9954, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2545, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.22840430, Acc: 0.91378572, F1: 0.95139319 Bal: 0.9093 - Val Loss: 0.25525299, Accuracy: 0.9090, F1: 0.9486 Bal: 0.8935\n","Epoch 387:      TX: Train Loss: 0.0185, Acc: 0.9954, F1: 0.9975 Bal: 0.9975 - Val Loss: 0.2545, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.22832803, Acc: 0.91572328, F1: 0.95254712 Bal: 0.9092 - Val Loss: 0.25567958, Accuracy: 0.9112, F1: 0.9499 Bal: 0.8933\n","Epoch 388:      TX: Train Loss: 0.0185, Acc: 0.9951, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2502, Accuracy: 0.9697, F1: 0.9832 Bal: 0.9253\n","           WALLETS: Train Loss: 0.22828346, Acc: 0.91087575, F1: 0.94965144 Bal: 0.9096 - Val Loss: 0.25464559, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8928\n","Epoch 389:      TX: Train Loss: 0.0185, Acc: 0.9958, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2585, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9266\n","           WALLETS: Train Loss: 0.22817184, Acc: 0.91708030, F1: 0.95335523 Bal: 0.9090 - Val Loss: 0.25590488, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8930\n","Epoch 390:      TX: Train Loss: 0.0185, Acc: 0.9949, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2474, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9250\n","           WALLETS: Train Loss: 0.22799805, Acc: 0.91131478, F1: 0.94991414 Bal: 0.9096 - Val Loss: 0.25458646, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8927\n","Epoch 391:      TX: Train Loss: 0.0184, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2607, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9256\n","           WALLETS: Train Loss: 0.22779559, Acc: 0.91555638, F1: 0.95244789 Bal: 0.9092 - Val Loss: 0.25537184, Accuracy: 0.9109, F1: 0.9497 Bal: 0.8933\n","Epoch 392:      TX: Train Loss: 0.0184, Acc: 0.9948, F1: 0.9971 Bal: 0.9971 - Val Loss: 0.2467, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22763161, Acc: 0.91384740, F1: 0.95142847 Bal: 0.9094 - Val Loss: 0.25489217, Accuracy: 0.9092, F1: 0.9487 Bal: 0.8934\n","Epoch 393:      TX: Train Loss: 0.0183, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2604, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9255\n","           WALLETS: Train Loss: 0.22752178, Acc: 0.91315438, F1: 0.95101300 Bal: 0.9096 - Val Loss: 0.25465950, Accuracy: 0.9085, F1: 0.9483 Bal: 0.8935\n","Epoch 394:      TX: Train Loss: 0.0183, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2485, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9250\n","           WALLETS: Train Loss: 0.22743063, Acc: 0.91619135, F1: 0.95282291 Bal: 0.9095 - Val Loss: 0.25531179, Accuracy: 0.9117, F1: 0.9502 Bal: 0.8934\n","Epoch 395:      TX: Train Loss: 0.0182, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2578, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22734287, Acc: 0.91170302, F1: 0.95014454 Bal: 0.9098 - Val Loss: 0.25432390, Accuracy: 0.9069, F1: 0.9474 Bal: 0.8931\n","Epoch 396:      TX: Train Loss: 0.0181, Acc: 0.9953, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2518, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9257\n","           WALLETS: Train Loss: 0.22721757, Acc: 0.91691703, F1: 0.95325374 Bal: 0.9095 - Val Loss: 0.25536603, Accuracy: 0.9120, F1: 0.9504 Bal: 0.8926\n","Epoch 397:      TX: Train Loss: 0.0181, Acc: 0.9958, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2548, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22707734, Acc: 0.91201144, F1: 0.95032855 Bal: 0.9098 - Val Loss: 0.25421101, Accuracy: 0.9070, F1: 0.9474 Bal: 0.8934\n","Epoch 398:      TX: Train Loss: 0.0181, Acc: 0.9958, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2551, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22691292, Acc: 0.91641994, F1: 0.95295687 Bal: 0.9097 - Val Loss: 0.25508273, Accuracy: 0.9117, F1: 0.9502 Bal: 0.8931\n","Epoch 399:      TX: Train Loss: 0.0180, Acc: 0.9954, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2520, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9256\n","           WALLETS: Train Loss: 0.22675711, Acc: 0.91316164, F1: 0.95101569 Bal: 0.9098 - Val Loss: 0.25427270, Accuracy: 0.9082, F1: 0.9481 Bal: 0.8930\n","Epoch 400:      TX: Train Loss: 0.0180, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2578, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22660543, Acc: 0.91531328, F1: 0.95229706 Bal: 0.9099 - Val Loss: 0.25462943, Accuracy: 0.9104, F1: 0.9494 Bal: 0.8935\n","Epoch 401:      TX: Train Loss: 0.0180, Acc: 0.9952, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2496, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9251\n","           WALLETS: Train Loss: 0.22647047, Acc: 0.91455494, F1: 0.95184559 Bal: 0.9099 - Val Loss: 0.25440949, Accuracy: 0.9095, F1: 0.9489 Bal: 0.8934\n","Epoch 402:      TX: Train Loss: 0.0180, Acc: 0.9960, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2603, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22634347, Acc: 0.91411228, F1: 0.95158225 Bal: 0.9099 - Val Loss: 0.25427341, Accuracy: 0.9092, F1: 0.9487 Bal: 0.8934\n","Epoch 403:      TX: Train Loss: 0.0180, Acc: 0.9951, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2478, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9259\n","           WALLETS: Train Loss: 0.22622201, Acc: 0.91562895, F1: 0.95248449 Bal: 0.9100 - Val Loss: 0.25453657, Accuracy: 0.9106, F1: 0.9496 Bal: 0.8934\n","Epoch 404:      TX: Train Loss: 0.0179, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2621, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9254\n","           WALLETS: Train Loss: 0.22611076, Acc: 0.91331403, F1: 0.95110465 Bal: 0.9100 - Val Loss: 0.25397605, Accuracy: 0.9087, F1: 0.9484 Bal: 0.8938\n","Epoch 405:      TX: Train Loss: 0.0179, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2468, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9258\n","           WALLETS: Train Loss: 0.22599767, Acc: 0.91659410, F1: 0.95305662 Bal: 0.9101 - Val Loss: 0.25466475, Accuracy: 0.9116, F1: 0.9501 Bal: 0.8932\n","Epoch 406:      TX: Train Loss: 0.0179, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2624, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9255\n","           WALLETS: Train Loss: 0.22589861, Acc: 0.91250127, F1: 0.95061832 Bal: 0.9102 - Val Loss: 0.25373715, Accuracy: 0.9076, F1: 0.9477 Bal: 0.8938\n","Epoch 407:      TX: Train Loss: 0.0178, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2473, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22579871, Acc: 0.91748668, F1: 0.95358894 Bal: 0.9099 - Val Loss: 0.25481603, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8924\n","Epoch 408:      TX: Train Loss: 0.0178, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2609, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22573364, Acc: 0.91160868, F1: 0.95008125 Bal: 0.9105 - Val Loss: 0.25345147, Accuracy: 0.9067, F1: 0.9472 Bal: 0.8938\n","Epoch 409:      TX: Train Loss: 0.0177, Acc: 0.9953, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2496, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9262\n","           WALLETS: Train Loss: 0.22568418, Acc: 0.91880016, F1: 0.95436945 Bal: 0.9097 - Val Loss: 0.25516161, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8923\n","Epoch 410:      TX: Train Loss: 0.0176, Acc: 0.9960, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2582, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9262\n","           WALLETS: Train Loss: 0.22571133, Acc: 0.90968564, F1: 0.94892928 Bal: 0.9106 - Val Loss: 0.25317371, Accuracy: 0.9051, F1: 0.9462 Bal: 0.8937\n","Epoch 411:      TX: Train Loss: 0.0176, Acc: 0.9957, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2527, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9266\n","           WALLETS: Train Loss: 0.22580375, Acc: 0.92093729, F1: 0.95563347 Bal: 0.9097 - Val Loss: 0.25595555, Accuracy: 0.9160, F1: 0.9528 Bal: 0.8915\n","Epoch 412:      TX: Train Loss: 0.0175, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2551, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9257\n","           WALLETS: Train Loss: 0.22609378, Acc: 0.90652168, F1: 0.94703058 Bal: 0.9103 - Val Loss: 0.25301421, Accuracy: 0.9012, F1: 0.9439 Bal: 0.8929\n","Epoch 413:      TX: Train Loss: 0.0175, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2557, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22651039, Acc: 0.92447860, F1: 0.95772623 Bal: 0.9089 - Val Loss: 0.25771964, Accuracy: 0.9198, F1: 0.9551 Bal: 0.8906\n","Epoch 414:      TX: Train Loss: 0.0175, Acc: 0.9956, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2521, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9266\n","           WALLETS: Train Loss: 0.22731930, Acc: 0.90121334, F1: 0.94382894 Bal: 0.9097 - Val Loss: 0.25334969, Accuracy: 0.8962, F1: 0.9409 Bal: 0.8922\n","Epoch 415:      TX: Train Loss: 0.0175, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2591, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9261\n","           WALLETS: Train Loss: 0.22790335, Acc: 0.92823399, F1: 0.95993567 Bal: 0.9079 - Val Loss: 0.26025197, Accuracy: 0.9232, F1: 0.9571 Bal: 0.8885\n","Epoch 416:      TX: Train Loss: 0.0175, Acc: 0.9953, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2490, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9261\n","           WALLETS: Train Loss: 0.22856054, Acc: 0.89766839, F1: 0.94167644 Bal: 0.9095 - Val Loss: 0.25397977, Accuracy: 0.8926, F1: 0.9387 Bal: 0.8926\n","Epoch 417:      TX: Train Loss: 0.0175, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2628, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9254\n","           WALLETS: Train Loss: 0.22774757, Acc: 0.92840452, F1: 0.96003727 Bal: 0.9076 - Val Loss: 0.26032701, Accuracy: 0.9235, F1: 0.9573 Bal: 0.8885\n","Epoch 418:      TX: Train Loss: 0.0175, Acc: 0.9949, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2458, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9267\n","           WALLETS: Train Loss: 0.22641070, Acc: 0.90293682, F1: 0.94486865 Bal: 0.9101 - Val Loss: 0.25295416, Accuracy: 0.8981, F1: 0.9420 Bal: 0.8926\n","Epoch 419:      TX: Train Loss: 0.0175, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2659, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9257\n","           WALLETS: Train Loss: 0.22473212, Acc: 0.92090826, F1: 0.95561339 Bal: 0.9100 - Val Loss: 0.25537694, Accuracy: 0.9156, F1: 0.9526 Bal: 0.8916\n","Epoch 420:      TX: Train Loss: 0.0176, Acc: 0.9949, F1: 0.9971 Bal: 0.9972 - Val Loss: 0.2439, Accuracy: 0.9686, F1: 0.9825 Bal: 0.9266\n","           WALLETS: Train Loss: 0.22407544, Acc: 0.91577045, F1: 0.95256020 Bal: 0.9109 - Val Loss: 0.25350773, Accuracy: 0.9104, F1: 0.9495 Bal: 0.8933\n","Epoch 421:      TX: Train Loss: 0.0175, Acc: 0.9966, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2664, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9257\n","           WALLETS: Train Loss: 0.22450511, Acc: 0.90933005, F1: 0.94871200 Bal: 0.9110 - Val Loss: 0.25253436, Accuracy: 0.9041, F1: 0.9457 Bal: 0.8937\n","Epoch 422:      TX: Train Loss: 0.0174, Acc: 0.9950, F1: 0.9972 Bal: 0.9972 - Val Loss: 0.2459, Accuracy: 0.9688, F1: 0.9826 Bal: 0.9267\n","           WALLETS: Train Loss: 0.22533600, Acc: 0.92452940, F1: 0.95775123 Bal: 0.9095 - Val Loss: 0.25715178, Accuracy: 0.9198, F1: 0.9550 Bal: 0.8909\n","Epoch 423:      TX: Train Loss: 0.0173, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2621, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22598675, Acc: 0.90261752, F1: 0.94467178 Bal: 0.9105 - Val Loss: 0.25278154, Accuracy: 0.8975, F1: 0.9417 Bal: 0.8925\n","Epoch 424:      TX: Train Loss: 0.0171, Acc: 0.9957, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2523, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9265\n","           WALLETS: Train Loss: 0.22549319, Acc: 0.92584288, F1: 0.95852493 Bal: 0.9092 - Val Loss: 0.25783682, Accuracy: 0.9208, F1: 0.9557 Bal: 0.8902\n","Epoch 425:      TX: Train Loss: 0.0171, Acc: 0.9960, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2546, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9268\n","           WALLETS: Train Loss: 0.22450109, Acc: 0.90752674, F1: 0.94762928 Bal: 0.9109 - Val Loss: 0.25242445, Accuracy: 0.9026, F1: 0.9447 Bal: 0.8935\n","Epoch 426:      TX: Train Loss: 0.0171, Acc: 0.9963, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2595, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22351858, Acc: 0.91869857, F1: 0.95430137 Bal: 0.9106 - Val Loss: 0.25413769, Accuracy: 0.9132, F1: 0.9512 Bal: 0.8919\n","Epoch 427:      TX: Train Loss: 0.0171, Acc: 0.9953, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2484, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22329743, Acc: 0.91741774, F1: 0.95353983 Bal: 0.9108 - Val Loss: 0.25361100, Accuracy: 0.9117, F1: 0.9503 Bal: 0.8922\n","Epoch 428:      TX: Train Loss: 0.0172, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2643, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9256\n","           WALLETS: Train Loss: 0.22370952, Acc: 0.90943891, F1: 0.94877378 Bal: 0.9113 - Val Loss: 0.25221312, Accuracy: 0.9041, F1: 0.9456 Bal: 0.8938\n","Epoch 429:      TX: Train Loss: 0.0172, Acc: 0.9951, F1: 0.9973 Bal: 0.9973 - Val Loss: 0.2460, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9269\n","           WALLETS: Train Loss: 0.22415857, Acc: 0.92367310, F1: 0.95724408 Bal: 0.9099 - Val Loss: 0.25622082, Accuracy: 0.9184, F1: 0.9543 Bal: 0.8908\n","Epoch 430:      TX: Train Loss: 0.0171, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2643, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9256\n","           WALLETS: Train Loss: 0.22431675, Acc: 0.90616246, F1: 0.94680396 Bal: 0.9113 - Val Loss: 0.25220892, Accuracy: 0.9009, F1: 0.9437 Bal: 0.8932\n","Epoch 431:      TX: Train Loss: 0.0170, Acc: 0.9955, F1: 0.9975 Bal: 0.9975 - Val Loss: 0.2487, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22377872, Acc: 0.92341911, F1: 0.95709343 Bal: 0.9101 - Val Loss: 0.25593233, Accuracy: 0.9182, F1: 0.9541 Bal: 0.8911\n","Epoch 432:      TX: Train Loss: 0.0169, Acc: 0.9963, F1: 0.9979 Bal: 0.9980 - Val Loss: 0.2593, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22308280, Acc: 0.91114062, F1: 0.94979253 Bal: 0.9114 - Val Loss: 0.25221789, Accuracy: 0.9060, F1: 0.9468 Bal: 0.8936\n","Epoch 433:      TX: Train Loss: 0.0168, Acc: 0.9961, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2549, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9270\n","           WALLETS: Train Loss: 0.22259276, Acc: 0.91726898, F1: 0.95344825 Bal: 0.9112 - Val Loss: 0.25324759, Accuracy: 0.9116, F1: 0.9502 Bal: 0.8926\n","Epoch 434:      TX: Train Loss: 0.0168, Acc: 0.9960, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2530, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9266\n","           WALLETS: Train Loss: 0.22256026, Acc: 0.91839015, F1: 0.95411425 Bal: 0.9111 - Val Loss: 0.25358072, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8918\n","Epoch 435:      TX: Train Loss: 0.0168, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2605, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.22282124, Acc: 0.91054919, F1: 0.94943690 Bal: 0.9116 - Val Loss: 0.25196517, Accuracy: 0.9050, F1: 0.9462 Bal: 0.8937\n","Epoch 436:      TX: Train Loss: 0.0168, Acc: 0.9956, F1: 0.9975 Bal: 0.9975 - Val Loss: 0.2489, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22302943, Acc: 0.92281680, F1: 0.95673538 Bal: 0.9105 - Val Loss: 0.25529826, Accuracy: 0.9173, F1: 0.9536 Bal: 0.8911\n","Epoch 437:      TX: Train Loss: 0.0168, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2633, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9264\n","           WALLETS: Train Loss: 0.22306474, Acc: 0.90840481, F1: 0.94814873 Bal: 0.9118 - Val Loss: 0.25182325, Accuracy: 0.9032, F1: 0.9451 Bal: 0.8938\n","Epoch 438:      TX: Train Loss: 0.0168, Acc: 0.9956, F1: 0.9975 Bal: 0.9975 - Val Loss: 0.2484, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9270\n","           WALLETS: Train Loss: 0.22271107, Acc: 0.92264263, F1: 0.95663194 Bal: 0.9106 - Val Loss: 0.25503913, Accuracy: 0.9171, F1: 0.9535 Bal: 0.8912\n","Epoch 439:      TX: Train Loss: 0.0167, Acc: 0.9965, F1: 0.9980 Bal: 0.9981 - Val Loss: 0.2619, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.22226250, Acc: 0.91165585, F1: 0.95009756 Bal: 0.9118 - Val Loss: 0.25185952, Accuracy: 0.9059, F1: 0.9467 Bal: 0.8932\n","Epoch 440:      TX: Train Loss: 0.0167, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2514, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22186248, Acc: 0.91832484, F1: 0.95407322 Bal: 0.9113 - Val Loss: 0.25319406, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8922\n","Epoch 441:      TX: Train Loss: 0.0166, Acc: 0.9963, F1: 0.9979 Bal: 0.9980 - Val Loss: 0.2578, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9271\n","           WALLETS: Train Loss: 0.22168128, Acc: 0.91668844, F1: 0.95310052 Bal: 0.9115 - Val Loss: 0.25261119, Accuracy: 0.9108, F1: 0.9497 Bal: 0.8923\n","Epoch 442:      TX: Train Loss: 0.0166, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2560, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9270\n","           WALLETS: Train Loss: 0.22168724, Acc: 0.91368775, F1: 0.95131097 Bal: 0.9118 - Val Loss: 0.25190753, Accuracy: 0.9082, F1: 0.9481 Bal: 0.8939\n","Epoch 443:      TX: Train Loss: 0.0165, Acc: 0.9961, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2538, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.22177586, Acc: 0.92064339, F1: 0.95544777 Bal: 0.9111 - Val Loss: 0.25388697, Accuracy: 0.9150, F1: 0.9522 Bal: 0.8912\n","Epoch 444:      TX: Train Loss: 0.0165, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2593, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22187850, Acc: 0.91082495, F1: 0.94959753 Bal: 0.9121 - Val Loss: 0.25154030, Accuracy: 0.9054, F1: 0.9464 Bal: 0.8932\n","Epoch 445:      TX: Train Loss: 0.0165, Acc: 0.9959, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2515, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9271\n","           WALLETS: Train Loss: 0.22183613, Acc: 0.92250475, F1: 0.95654651 Bal: 0.9111 - Val Loss: 0.25452167, Accuracy: 0.9169, F1: 0.9533 Bal: 0.8913\n","Epoch 446:      TX: Train Loss: 0.0165, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2612, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.22172256, Acc: 0.91045848, F1: 0.94937722 Bal: 0.9121 - Val Loss: 0.25141832, Accuracy: 0.9048, F1: 0.9461 Bal: 0.8929\n","Epoch 447:      TX: Train Loss: 0.0165, Acc: 0.9958, F1: 0.9977 Bal: 0.9977 - Val Loss: 0.2510, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9271\n","           WALLETS: Train Loss: 0.22147174, Acc: 0.92179359, F1: 0.95612453 Bal: 0.9114 - Val Loss: 0.25408417, Accuracy: 0.9159, F1: 0.9527 Bal: 0.8911\n","Epoch 448:      TX: Train Loss: 0.0164, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2612, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.22121857, Acc: 0.91226905, F1: 0.95046150 Bal: 0.9121 - Val Loss: 0.25143507, Accuracy: 0.9068, F1: 0.9473 Bal: 0.8935\n","Epoch 449:      TX: Train Loss: 0.0164, Acc: 0.9960, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2520, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22094969, Acc: 0.91968549, F1: 0.95487690 Bal: 0.9116 - Val Loss: 0.25313246, Accuracy: 0.9141, F1: 0.9517 Bal: 0.8920\n","Epoch 450:      TX: Train Loss: 0.0164, Acc: 0.9965, F1: 0.9980 Bal: 0.9981 - Val Loss: 0.2599, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.22074094, Acc: 0.91484158, F1: 0.95199643 Bal: 0.9121 - Val Loss: 0.25174424, Accuracy: 0.9096, F1: 0.9489 Bal: 0.8937\n","Epoch 451:      TX: Train Loss: 0.0163, Acc: 0.9961, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2539, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9275\n","           WALLETS: Train Loss: 0.22057854, Acc: 0.91743589, F1: 0.95354084 Bal: 0.9119 - Val Loss: 0.25228676, Accuracy: 0.9118, F1: 0.9503 Bal: 0.8923\n","Epoch 452:      TX: Train Loss: 0.0163, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2581, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.22046526, Acc: 0.91733066, F1: 0.95347736 Bal: 0.9120 - Val Loss: 0.25220570, Accuracy: 0.9116, F1: 0.9501 Bal: 0.8922\n","Epoch 453:      TX: Train Loss: 0.0163, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2555, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.22039159, Acc: 0.91536044, F1: 0.95230403 Bal: 0.9122 - Val Loss: 0.25167292, Accuracy: 0.9100, F1: 0.9492 Bal: 0.8934\n","Epoch 454:      TX: Train Loss: 0.0162, Acc: 0.9963, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2568, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.22034074, Acc: 0.91922831, F1: 0.95460413 Bal: 0.9118 - Val Loss: 0.25272286, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8923\n","Epoch 455:      TX: Train Loss: 0.0162, Acc: 0.9963, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2565, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.22032858, Acc: 0.91352448, F1: 0.95120878 Bal: 0.9123 - Val Loss: 0.25125754, Accuracy: 0.9080, F1: 0.9480 Bal: 0.8934\n","Epoch 456:      TX: Train Loss: 0.0162, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2562, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.22033776, Acc: 0.92118039, F1: 0.95575953 Bal: 0.9117 - Val Loss: 0.25334987, Accuracy: 0.9156, F1: 0.9525 Bal: 0.8920\n","Epoch 457:      TX: Train Loss: 0.0161, Acc: 0.9963, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2569, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.22042309, Acc: 0.91150709, F1: 0.95000051 Bal: 0.9126 - Val Loss: 0.25094005, Accuracy: 0.9057, F1: 0.9466 Bal: 0.8931\n","Epoch 458:      TX: Train Loss: 0.0161, Acc: 0.9963, F1: 0.9979 Bal: 0.9980 - Val Loss: 0.2562, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.22054368, Acc: 0.92343362, F1: 0.95709005 Bal: 0.9116 - Val Loss: 0.25428820, Accuracy: 0.9177, F1: 0.9538 Bal: 0.8908\n","Epoch 459:      TX: Train Loss: 0.0161, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2567, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.22083339, Acc: 0.90870960, F1: 0.94831956 Bal: 0.9130 - Val Loss: 0.25075150, Accuracy: 0.9030, F1: 0.9450 Bal: 0.8935\n","Epoch 460:      TX: Train Loss: 0.0161, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2567, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.22115822, Acc: 0.92625651, F1: 0.95875259 Bal: 0.9111 - Val Loss: 0.25583211, Accuracy: 0.9209, F1: 0.9557 Bal: 0.8910\n","Epoch 461:      TX: Train Loss: 0.0160, Acc: 0.9963, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2559, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.22177720, Acc: 0.90457686, F1: 0.94583590 Bal: 0.9124 - Val Loss: 0.25091597, Accuracy: 0.8987, F1: 0.9424 Bal: 0.8931\n","Epoch 462:      TX: Train Loss: 0.0160, Acc: 0.9965, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.22214809, Acc: 0.92924268, F1: 0.96050582 Bal: 0.9105 - Val Loss: 0.25779670, Accuracy: 0.9234, F1: 0.9572 Bal: 0.8900\n","Epoch 463:      TX: Train Loss: 0.0160, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2539, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9275\n","           WALLETS: Train Loss: 0.22262742, Acc: 0.90202610, F1: 0.94429292 Bal: 0.9124 - Val Loss: 0.25123823, Accuracy: 0.8966, F1: 0.9411 Bal: 0.8937\n","Epoch 464:      TX: Train Loss: 0.0160, Acc: 0.9967, F1: 0.9982 Bal: 0.9982 - Val Loss: 0.2614, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.22208591, Acc: 0.92956924, F1: 0.96069701 Bal: 0.9104 - Val Loss: 0.25796595, Accuracy: 0.9238, F1: 0.9574 Bal: 0.8901\n","Epoch 465:      TX: Train Loss: 0.0160, Acc: 0.9960, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2498, Accuracy: 0.9691, F1: 0.9828 Bal: 0.9278\n","           WALLETS: Train Loss: 0.22125858, Acc: 0.90513200, F1: 0.94616864 Bal: 0.9127 - Val Loss: 0.25068459, Accuracy: 0.8991, F1: 0.9426 Bal: 0.8932\n","Epoch 466:      TX: Train Loss: 0.0161, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2667, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9259\n","           WALLETS: Train Loss: 0.21989989, Acc: 0.92452214, F1: 0.95772965 Bal: 0.9117 - Val Loss: 0.25436351, Accuracy: 0.9189, F1: 0.9545 Bal: 0.8910\n","Epoch 467:      TX: Train Loss: 0.0163, Acc: 0.9955, F1: 0.9975 Bal: 0.9975 - Val Loss: 0.2442, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21901096, Acc: 0.91429370, F1: 0.95166535 Bal: 0.9126 - Val Loss: 0.25072846, Accuracy: 0.9085, F1: 0.9483 Bal: 0.8934\n","Epoch 468:      TX: Train Loss: 0.0164, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2739, Accuracy: 0.9732, F1: 0.9851 Bal: 0.9262\n","           WALLETS: Train Loss: 0.21879174, Acc: 0.91583939, F1: 0.95258421 Bal: 0.9128 - Val Loss: 0.25097448, Accuracy: 0.9099, F1: 0.9492 Bal: 0.8926\n","Epoch 469:      TX: Train Loss: 0.0166, Acc: 0.9947, F1: 0.9970 Bal: 0.9970 - Val Loss: 0.2389, Accuracy: 0.9677, F1: 0.9820 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21912198, Acc: 0.92260272, F1: 0.95659570 Bal: 0.9121 - Val Loss: 0.25320092, Accuracy: 0.9166, F1: 0.9532 Bal: 0.8917\n","Epoch 470:      TX: Train Loss: 0.0165, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2772, Accuracy: 0.9741, F1: 0.9856 Bal: 0.9267\n","           WALLETS: Train Loss: 0.21969819, Acc: 0.90915952, F1: 0.94858736 Bal: 0.9132 - Val Loss: 0.25024083, Accuracy: 0.9035, F1: 0.9453 Bal: 0.8941\n","Epoch 471:      TX: Train Loss: 0.0164, Acc: 0.9951, F1: 0.9972 Bal: 0.9973 - Val Loss: 0.2414, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21999452, Acc: 0.92653953, F1: 0.95891506 Bal: 0.9116 - Val Loss: 0.25542954, Accuracy: 0.9212, F1: 0.9559 Bal: 0.8912\n","Epoch 472:      TX: Train Loss: 0.0159, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2677, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9260\n","           WALLETS: Train Loss: 0.22001433, Acc: 0.90743966, F1: 0.94755324 Bal: 0.9133 - Val Loss: 0.25029403, Accuracy: 0.9017, F1: 0.9442 Bal: 0.8943\n","Epoch 473:      TX: Train Loss: 0.0157, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2571, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21941428, Acc: 0.92542198, F1: 0.95825734 Bal: 0.9118 - Val Loss: 0.25466806, Accuracy: 0.9197, F1: 0.9550 Bal: 0.8912\n","Epoch 474:      TX: Train Loss: 0.0158, Acc: 0.9961, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2495, Accuracy: 0.9695, F1: 0.9830 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21874784, Acc: 0.91155789, F1: 0.95002368 Bal: 0.9134 - Val Loss: 0.25015652, Accuracy: 0.9057, F1: 0.9466 Bal: 0.8936\n","Epoch 475:      TX: Train Loss: 0.0160, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2714, Accuracy: 0.9732, F1: 0.9851 Bal: 0.9262\n","           WALLETS: Train Loss: 0.21817806, Acc: 0.92034586, F1: 0.95525831 Bal: 0.9127 - Val Loss: 0.25200674, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8928\n","Epoch 476:      TX: Train Loss: 0.0162, Acc: 0.9953, F1: 0.9974 Bal: 0.9974 - Val Loss: 0.2419, Accuracy: 0.9680, F1: 0.9821 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21794324, Acc: 0.91771890, F1: 0.95369934 Bal: 0.9130 - Val Loss: 0.25110376, Accuracy: 0.9121, F1: 0.9505 Bal: 0.8927\n","Epoch 477:      TX: Train Loss: 0.0159, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2713, Accuracy: 0.9732, F1: 0.9851 Bal: 0.9262\n","           WALLETS: Train Loss: 0.21798861, Acc: 0.91477990, F1: 0.95194682 Bal: 0.9135 - Val Loss: 0.25035405, Accuracy: 0.9088, F1: 0.9485 Bal: 0.8935\n","Epoch 478:      TX: Train Loss: 0.0156, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2514, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21816050, Acc: 0.92266077, F1: 0.95662667 Bal: 0.9125 - Val Loss: 0.25278434, Accuracy: 0.9167, F1: 0.9532 Bal: 0.8917\n","Epoch 479:      TX: Train Loss: 0.0155, Acc: 0.9964, F1: 0.9980 Bal: 0.9980 - Val Loss: 0.2565, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9275\n","           WALLETS: Train Loss: 0.21836045, Acc: 0.91128213, F1: 0.94985758 Bal: 0.9135 - Val Loss: 0.24994871, Accuracy: 0.9054, F1: 0.9464 Bal: 0.8938\n","Epoch 480:      TX: Train Loss: 0.0156, Acc: 0.9972, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2668, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.21838768, Acc: 0.92457657, F1: 0.95775575 Bal: 0.9124 - Val Loss: 0.25376576, Accuracy: 0.9184, F1: 0.9543 Bal: 0.8906\n","Epoch 481:      TX: Train Loss: 0.0158, Acc: 0.9956, F1: 0.9976 Bal: 0.9976 - Val Loss: 0.2455, Accuracy: 0.9682, F1: 0.9823 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21833453, Acc: 0.91053831, F1: 0.94941093 Bal: 0.9136 - Val Loss: 0.24983007, Accuracy: 0.9046, F1: 0.9460 Bal: 0.8938\n","Epoch 482:      TX: Train Loss: 0.0157, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2703, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9260\n","           WALLETS: Train Loss: 0.21806936, Acc: 0.92418107, F1: 0.95752086 Bal: 0.9127 - Val Loss: 0.25341007, Accuracy: 0.9179, F1: 0.9539 Bal: 0.8910\n","Epoch 483:      TX: Train Loss: 0.0155, Acc: 0.9961, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2507, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21778852, Acc: 0.91218197, F1: 0.95039566 Bal: 0.9135 - Val Loss: 0.24981913, Accuracy: 0.9063, F1: 0.9470 Bal: 0.8939\n","Epoch 484:      TX: Train Loss: 0.0154, Acc: 0.9967, F1: 0.9982 Bal: 0.9982 - Val Loss: 0.2590, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21744882, Acc: 0.92212377, F1: 0.95630595 Bal: 0.9130 - Val Loss: 0.25223950, Accuracy: 0.9158, F1: 0.9527 Bal: 0.8912\n","Epoch 485:      TX: Train Loss: 0.0154, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2635, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.21718201, Acc: 0.91524796, F1: 0.95222414 Bal: 0.9137 - Val Loss: 0.25009501, Accuracy: 0.9093, F1: 0.9488 Bal: 0.8932\n","Epoch 486:      TX: Train Loss: 0.0155, Acc: 0.9961, F1: 0.9978 Bal: 0.9978 - Val Loss: 0.2491, Accuracy: 0.9693, F1: 0.9829 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21697675, Acc: 0.91923920, F1: 0.95459590 Bal: 0.9135 - Val Loss: 0.25106093, Accuracy: 0.9133, F1: 0.9512 Bal: 0.8927\n","Epoch 487:      TX: Train Loss: 0.0155, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2676, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.21685515, Acc: 0.91825590, F1: 0.95401353 Bal: 0.9135 - Val Loss: 0.25072733, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8929\n","Epoch 488:      TX: Train Loss: 0.0154, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2519, Accuracy: 0.9699, F1: 0.9833 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21680014, Acc: 0.91653242, F1: 0.95298820 Bal: 0.9137 - Val Loss: 0.25021595, Accuracy: 0.9108, F1: 0.9497 Bal: 0.8932\n","Epoch 489:      TX: Train Loss: 0.0153, Acc: 0.9968, F1: 0.9982 Bal: 0.9982 - Val Loss: 0.2597, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9267\n","           WALLETS: Train Loss: 0.21679100, Acc: 0.92095180, F1: 0.95561016 Bal: 0.9134 - Val Loss: 0.25148830, Accuracy: 0.9148, F1: 0.9521 Bal: 0.8918\n","Epoch 490:      TX: Train Loss: 0.0153, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2614, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9268\n","           WALLETS: Train Loss: 0.21683241, Acc: 0.91431184, F1: 0.95166361 Bal: 0.9139 - Val Loss: 0.24972109, Accuracy: 0.9082, F1: 0.9481 Bal: 0.8930\n","Epoch 491:      TX: Train Loss: 0.0153, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2518, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21688716, Acc: 0.92305264, F1: 0.95685012 Bal: 0.9134 - Val Loss: 0.25233173, Accuracy: 0.9167, F1: 0.9532 Bal: 0.8912\n","Epoch 492:      TX: Train Loss: 0.0153, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2652, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21701695, Acc: 0.91206586, F1: 0.95032213 Bal: 0.9139 - Val Loss: 0.24941912, Accuracy: 0.9062, F1: 0.9469 Bal: 0.8942\n","Epoch 493:      TX: Train Loss: 0.0153, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2529, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21714005, Acc: 0.92509543, F1: 0.95805702 Bal: 0.9129 - Val Loss: 0.25333318, Accuracy: 0.9188, F1: 0.9544 Bal: 0.8916\n","Epoch 494:      TX: Train Loss: 0.0152, Acc: 0.9969, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2598, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21739563, Acc: 0.90975458, F1: 0.94893358 Bal: 0.9143 - Val Loss: 0.24928728, Accuracy: 0.9037, F1: 0.9454 Bal: 0.8944\n","Epoch 495:      TX: Train Loss: 0.0152, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2602, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.21758316, Acc: 0.92727972, F1: 0.95934042 Bal: 0.9127 - Val Loss: 0.25453618, Accuracy: 0.9213, F1: 0.9559 Bal: 0.8914\n","Epoch 496:      TX: Train Loss: 0.0152, Acc: 0.9963, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2526, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21794277, Acc: 0.90722921, F1: 0.94741497 Bal: 0.9144 - Val Loss: 0.24930134, Accuracy: 0.9011, F1: 0.9438 Bal: 0.8939\n","Epoch 497:      TX: Train Loss: 0.0152, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2649, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21802537, Acc: 0.92875285, F1: 0.96020768 Bal: 0.9121 - Val Loss: 0.25561288, Accuracy: 0.9229, F1: 0.9569 Bal: 0.8907\n","Epoch 498:      TX: Train Loss: 0.0152, Acc: 0.9962, F1: 0.9979 Bal: 0.9979 - Val Loss: 0.2512, Accuracy: 0.9697, F1: 0.9831 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21818630, Acc: 0.90592299, F1: 0.94663000 Bal: 0.9142 - Val Loss: 0.24933848, Accuracy: 0.9001, F1: 0.9433 Bal: 0.8940\n","Epoch 499:      TX: Train Loss: 0.0151, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2627, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9286\n","           WALLETS: Train Loss: 0.21777712, Acc: 0.92862948, F1: 0.96013522 Bal: 0.9121 - Val Loss: 0.25543910, Accuracy: 0.9229, F1: 0.9569 Bal: 0.8907\n","Epoch 500:      TX: Train Loss: 0.0151, Acc: 0.9966, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2563, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21731734, Acc: 0.90832862, F1: 0.94807242 Bal: 0.9148 - Val Loss: 0.24909875, Accuracy: 0.9015, F1: 0.9441 Bal: 0.8938\n","Epoch 501:      TX: Train Loss: 0.0151, Acc: 0.9967, F1: 0.9981 Bal: 0.9981 - Val Loss: 0.2568, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21651062, Acc: 0.92566871, F1: 0.95839426 Bal: 0.9128 - Val Loss: 0.25331986, Accuracy: 0.9199, F1: 0.9551 Bal: 0.8919\n","Epoch 502:      TX: Train Loss: 0.0150, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2590, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21552554, Acc: 0.91986691, F1: 0.95496396 Bal: 0.9140 - Val Loss: 0.25058475, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8922\n","Epoch 503:      TX: Train Loss: 0.0150, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2591, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21622185, Acc: 0.91175019, F1: 0.95012877 Bal: 0.9144 - Val Loss: 0.24901192, Accuracy: 0.9059, F1: 0.9467 Bal: 0.8945\n","Epoch 504:      TX: Train Loss: 0.0150, Acc: 0.9969, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2571, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21544792, Acc: 0.91694605, F1: 0.95322806 Bal: 0.9144 - Val Loss: 0.24972180, Accuracy: 0.9108, F1: 0.9497 Bal: 0.8926\n","Epoch 505:      TX: Train Loss: 0.0150, Acc: 0.9969, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2567, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21597257, Acc: 0.92433709, F1: 0.95760491 Bal: 0.9137 - Val Loss: 0.25245732, Accuracy: 0.9181, F1: 0.9540 Bal: 0.8918\n","Epoch 506:      TX: Train Loss: 0.0150, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2582, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21534988, Acc: 0.92006284, F1: 0.95508012 Bal: 0.9140 - Val Loss: 0.25058758, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8920\n","Epoch 507:      TX: Train Loss: 0.0150, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2588, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21576147, Acc: 0.91320155, F1: 0.95099578 Bal: 0.9145 - Val Loss: 0.24905394, Accuracy: 0.9074, F1: 0.9477 Bal: 0.8942\n","Epoch 508:      TX: Train Loss: 0.0150, Acc: 0.9969, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2575, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9275\n","           WALLETS: Train Loss: 0.21526524, Acc: 0.91703676, F1: 0.95328153 Bal: 0.9144 - Val Loss: 0.24967019, Accuracy: 0.9107, F1: 0.9496 Bal: 0.8921\n","Epoch 509:      TX: Train Loss: 0.0150, Acc: 0.9969, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2570, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21556865, Acc: 0.92326309, F1: 0.95697199 Bal: 0.9137 - Val Loss: 0.25184685, Accuracy: 0.9168, F1: 0.9533 Bal: 0.8914\n","Epoch 510:      TX: Train Loss: 0.0150, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2580, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21516445, Acc: 0.92018621, F1: 0.95515146 Bal: 0.9141 - Val Loss: 0.25051233, Accuracy: 0.9139, F1: 0.9515 Bal: 0.8919\n","Epoch 511:      TX: Train Loss: 0.0150, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2586, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21540610, Acc: 0.91442069, F1: 0.95172323 Bal: 0.9145 - Val Loss: 0.24911977, Accuracy: 0.9083, F1: 0.9482 Bal: 0.8933\n","Epoch 512:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2577, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21507333, Acc: 0.91733792, F1: 0.95345901 Bal: 0.9146 - Val Loss: 0.24965350, Accuracy: 0.9111, F1: 0.9499 Bal: 0.8923\n","Epoch 513:      TX: Train Loss: 0.0149, Acc: 0.9969, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2573, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21525033, Acc: 0.92251201, F1: 0.95652652 Bal: 0.9140 - Val Loss: 0.25138655, Accuracy: 0.9160, F1: 0.9528 Bal: 0.8918\n","Epoch 514:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2581, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21497115, Acc: 0.91996125, F1: 0.95501698 Bal: 0.9143 - Val Loss: 0.25036713, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8918\n","Epoch 515:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2586, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21511604, Acc: 0.91524071, F1: 0.95220969 Bal: 0.9148 - Val Loss: 0.24917334, Accuracy: 0.9093, F1: 0.9488 Bal: 0.8934\n","Epoch 516:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2579, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21487691, Acc: 0.91770439, F1: 0.95367623 Bal: 0.9146 - Val Loss: 0.24966267, Accuracy: 0.9114, F1: 0.9500 Bal: 0.8921\n","Epoch 517:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2574, Accuracy: 0.9702, F1: 0.9834 Bal: 0.9275\n","           WALLETS: Train Loss: 0.21498199, Acc: 0.92190244, F1: 0.95616633 Bal: 0.9141 - Val Loss: 0.25103030, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8918\n","Epoch 518:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2578, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21477747, Acc: 0.91971089, F1: 0.95486863 Bal: 0.9143 - Val Loss: 0.25019777, Accuracy: 0.9134, F1: 0.9513 Bal: 0.8921\n","Epoch 519:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21486510, Acc: 0.91598090, F1: 0.95265183 Bal: 0.9146 - Val Loss: 0.24922729, Accuracy: 0.9100, F1: 0.9492 Bal: 0.8931\n","Epoch 520:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2580, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21468437, Acc: 0.91820511, F1: 0.95397274 Bal: 0.9147 - Val Loss: 0.24970557, Accuracy: 0.9116, F1: 0.9502 Bal: 0.8918\n","Epoch 521:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2576, Accuracy: 0.9704, F1: 0.9835 Bal: 0.9276\n","           WALLETS: Train Loss: 0.21474683, Acc: 0.92150694, F1: 0.95593133 Bal: 0.9143 - Val Loss: 0.25077090, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8917\n","Epoch 522:      TX: Train Loss: 0.0149, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2578, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21458790, Acc: 0.91938796, F1: 0.95467630 Bal: 0.9144 - Val Loss: 0.25003418, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8922\n","Epoch 523:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21463913, Acc: 0.91649613, F1: 0.95295777 Bal: 0.9147 - Val Loss: 0.24926804, Accuracy: 0.9102, F1: 0.9493 Bal: 0.8919\n","Epoch 524:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21449511, Acc: 0.91863688, F1: 0.95422945 Bal: 0.9146 - Val Loss: 0.24974509, Accuracy: 0.9121, F1: 0.9505 Bal: 0.8919\n","Epoch 525:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2578, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21452869, Acc: 0.92117313, F1: 0.95573166 Bal: 0.9146 - Val Loss: 0.25054491, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8918\n","Epoch 526:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2580, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21440281, Acc: 0.91912309, F1: 0.95451800 Bal: 0.9146 - Val Loss: 0.24987051, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8920\n","Epoch 527:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2582, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21442614, Acc: 0.91700411, F1: 0.95325903 Bal: 0.9148 - Val Loss: 0.24931246, Accuracy: 0.9105, F1: 0.9495 Bal: 0.8920\n","Epoch 528:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2581, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21431184, Acc: 0.91898521, F1: 0.95443637 Bal: 0.9146 - Val Loss: 0.24980603, Accuracy: 0.9125, F1: 0.9507 Bal: 0.8920\n","Epoch 529:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9983 Bal: 0.9983 - Val Loss: 0.2579, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21432005, Acc: 0.92080666, F1: 0.95551434 Bal: 0.9146 - Val Loss: 0.25035477, Accuracy: 0.9143, F1: 0.9518 Bal: 0.8918\n","Epoch 530:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2580, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21422154, Acc: 0.91884370, F1: 0.95435148 Bal: 0.9147 - Val Loss: 0.24971488, Accuracy: 0.9124, F1: 0.9506 Bal: 0.8919\n","Epoch 531:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21422005, Acc: 0.91744677, F1: 0.95352087 Bal: 0.9149 - Val Loss: 0.24933468, Accuracy: 0.9108, F1: 0.9497 Bal: 0.8915\n","Epoch 532:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21413152, Acc: 0.91938433, F1: 0.95467231 Bal: 0.9147 - Val Loss: 0.24983795, Accuracy: 0.9128, F1: 0.9509 Bal: 0.8919\n","Epoch 533:      TX: Train Loss: 0.0148, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2579, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21411601, Acc: 0.92045108, F1: 0.95530421 Bal: 0.9146 - Val Loss: 0.25016573, Accuracy: 0.9140, F1: 0.9516 Bal: 0.8918\n","Epoch 534:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2580, Accuracy: 0.9706, F1: 0.9836 Bal: 0.9277\n","           WALLETS: Train Loss: 0.21404205, Acc: 0.91868043, F1: 0.95425301 Bal: 0.9149 - Val Loss: 0.24959159, Accuracy: 0.9120, F1: 0.9504 Bal: 0.8917\n","Epoch 535:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21401761, Acc: 0.91792209, F1: 0.95380349 Bal: 0.9149 - Val Loss: 0.24939162, Accuracy: 0.9114, F1: 0.9501 Bal: 0.8918\n","Epoch 536:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.21395150, Acc: 0.91970000, F1: 0.95485984 Bal: 0.9146 - Val Loss: 0.24987495, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8920\n","Epoch 537:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2579, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.21391676, Acc: 0.92019347, F1: 0.95515041 Bal: 0.9148 - Val Loss: 0.25000310, Accuracy: 0.9136, F1: 0.9514 Bal: 0.8918\n","Epoch 538:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2580, Accuracy: 0.9708, F1: 0.9838 Bal: 0.9278\n","           WALLETS: Train Loss: 0.21386279, Acc: 0.91850989, F1: 0.95415211 Bal: 0.9149 - Val Loss: 0.24950051, Accuracy: 0.9119, F1: 0.9503 Bal: 0.8914\n","Epoch 539:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21382041, Acc: 0.91840830, F1: 0.95409064 Bal: 0.9150 - Val Loss: 0.24944167, Accuracy: 0.9118, F1: 0.9503 Bal: 0.8917\n","Epoch 540:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21377097, Acc: 0.91988868, F1: 0.95497123 Bal: 0.9146 - Val Loss: 0.24985699, Accuracy: 0.9134, F1: 0.9512 Bal: 0.8921\n","Epoch 541:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2580, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21372268, Acc: 0.91979434, F1: 0.95491527 Bal: 0.9146 - Val Loss: 0.24981056, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8920\n","Epoch 542:      TX: Train Loss: 0.0147, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21368057, Acc: 0.91852803, F1: 0.95416185 Bal: 0.9150 - Val Loss: 0.24941470, Accuracy: 0.9118, F1: 0.9503 Bal: 0.8914\n","Epoch 543:      TX: Train Loss: 0.0147, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21362774, Acc: 0.91885822, F1: 0.95435796 Bal: 0.9150 - Val Loss: 0.24949411, Accuracy: 0.9121, F1: 0.9505 Bal: 0.8916\n","Epoch 544:      TX: Train Loss: 0.0146, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21358740, Acc: 0.92000479, F1: 0.95503961 Bal: 0.9147 - Val Loss: 0.24982072, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8920\n","Epoch 545:      TX: Train Loss: 0.0146, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21353272, Acc: 0.91953310, F1: 0.95475882 Bal: 0.9148 - Val Loss: 0.24964663, Accuracy: 0.9129, F1: 0.9509 Bal: 0.8918\n","Epoch 546:      TX: Train Loss: 0.0146, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21349533, Acc: 0.91860060, F1: 0.95420455 Bal: 0.9150 - Val Loss: 0.24937338, Accuracy: 0.9119, F1: 0.9503 Bal: 0.8916\n","Epoch 547:      TX: Train Loss: 0.0146, Acc: 0.9970, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21343912, Acc: 0.91927911, F1: 0.95460676 Bal: 0.9150 - Val Loss: 0.24955282, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8917\n","Epoch 548:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21339951, Acc: 0.91994311, F1: 0.95500265 Bal: 0.9147 - Val Loss: 0.24976072, Accuracy: 0.9134, F1: 0.9513 Bal: 0.8918\n","Epoch 549:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21334608, Acc: 0.91922831, F1: 0.95457653 Bal: 0.9150 - Val Loss: 0.24952865, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8917\n","Epoch 550:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21330509, Acc: 0.91877476, F1: 0.95430794 Bal: 0.9150 - Val Loss: 0.24938852, Accuracy: 0.9120, F1: 0.9504 Bal: 0.8914\n","Epoch 551:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21325356, Acc: 0.91962018, F1: 0.95480907 Bal: 0.9150 - Val Loss: 0.24959452, Accuracy: 0.9129, F1: 0.9510 Bal: 0.8919\n","Epoch 552:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21320941, Acc: 0.91986691, F1: 0.95495587 Bal: 0.9149 - Val Loss: 0.24965112, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8916\n","Epoch 553:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21316099, Acc: 0.91910495, F1: 0.95450344 Bal: 0.9150 - Val Loss: 0.24942121, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8915\n","Epoch 554:      TX: Train Loss: 0.0146, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21311437, Acc: 0.91909043, F1: 0.95449472 Bal: 0.9151 - Val Loss: 0.24940330, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8915\n","Epoch 555:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21306784, Acc: 0.91988868, F1: 0.95496683 Bal: 0.9151 - Val Loss: 0.24959330, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8918\n","Epoch 556:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21301925, Acc: 0.91967098, F1: 0.95483781 Bal: 0.9152 - Val Loss: 0.24952815, Accuracy: 0.9129, F1: 0.9509 Bal: 0.8917\n","Epoch 557:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21297444, Acc: 0.91910858, F1: 0.95450464 Bal: 0.9152 - Val Loss: 0.24935915, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8914\n","Epoch 558:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2584, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21292555, Acc: 0.91944239, F1: 0.95470274 Bal: 0.9151 - Val Loss: 0.24943194, Accuracy: 0.9127, F1: 0.9509 Bal: 0.8916\n","Epoch 559:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21288055, Acc: 0.91988142, F1: 0.95496238 Bal: 0.9152 - Val Loss: 0.24952993, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8918\n","Epoch 560:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21283250, Acc: 0.91946416, F1: 0.95471553 Bal: 0.9151 - Val Loss: 0.24939822, Accuracy: 0.9127, F1: 0.9508 Bal: 0.8916\n","Epoch 561:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9710, F1: 0.9839 Bal: 0.9280\n","           WALLETS: Train Loss: 0.21278703, Acc: 0.91926097, F1: 0.95459369 Bal: 0.9153 - Val Loss: 0.24931234, Accuracy: 0.9125, F1: 0.9507 Bal: 0.8914\n","Epoch 562:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21273910, Acc: 0.91967823, F1: 0.95484171 Bal: 0.9152 - Val Loss: 0.24940576, Accuracy: 0.9129, F1: 0.9509 Bal: 0.8917\n","Epoch 563:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21269244, Acc: 0.91975080, F1: 0.95488527 Bal: 0.9151 - Val Loss: 0.24941368, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8918\n","Epoch 564:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21264571, Acc: 0.91940248, F1: 0.95467724 Bal: 0.9153 - Val Loss: 0.24929112, Accuracy: 0.9126, F1: 0.9508 Bal: 0.8915\n","Epoch 565:      TX: Train Loss: 0.0145, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21259823, Acc: 0.91947504, F1: 0.95472027 Bal: 0.9153 - Val Loss: 0.24928495, Accuracy: 0.9127, F1: 0.9508 Bal: 0.8916\n","Epoch 566:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21255167, Acc: 0.91979434, F1: 0.95491067 Bal: 0.9152 - Val Loss: 0.24934672, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8918\n","Epoch 567:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21250431, Acc: 0.91964195, F1: 0.95481984 Bal: 0.9152 - Val Loss: 0.24928586, Accuracy: 0.9128, F1: 0.9509 Bal: 0.8917\n","Epoch 568:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21245751, Acc: 0.91945327, F1: 0.95470673 Bal: 0.9154 - Val Loss: 0.24921741, Accuracy: 0.9127, F1: 0.9508 Bal: 0.8916\n","Epoch 569:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21240994, Acc: 0.91968912, F1: 0.95484719 Bal: 0.9153 - Val Loss: 0.24925762, Accuracy: 0.9129, F1: 0.9509 Bal: 0.8917\n","Epoch 570:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21236262, Acc: 0.91981248, F1: 0.95492004 Bal: 0.9153 - Val Loss: 0.24926381, Accuracy: 0.9131, F1: 0.9510 Bal: 0.8918\n","Epoch 571:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21231537, Acc: 0.91955124, F1: 0.95476413 Bal: 0.9155 - Val Loss: 0.24917690, Accuracy: 0.9127, F1: 0.9508 Bal: 0.8916\n","Epoch 572:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21226746, Acc: 0.91959841, F1: 0.95479148 Bal: 0.9155 - Val Loss: 0.24915721, Accuracy: 0.9128, F1: 0.9509 Bal: 0.8918\n","Epoch 573:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21221885, Acc: 0.91988505, F1: 0.95496084 Bal: 0.9156 - Val Loss: 0.24919206, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8920\n","Epoch 574:      TX: Train Loss: 0.0144, Acc: 0.9971, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21217041, Acc: 0.91978346, F1: 0.95490078 Bal: 0.9156 - Val Loss: 0.24914902, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8919\n","Epoch 575:      TX: Train Loss: 0.0144, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2581, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21212275, Acc: 0.91964921, F1: 0.95482097 Bal: 0.9156 - Val Loss: 0.24909152, Accuracy: 0.9129, F1: 0.9509 Bal: 0.8920\n","Epoch 576:      TX: Train Loss: 0.0144, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21207502, Acc: 0.91980886, F1: 0.95491533 Bal: 0.9156 - Val Loss: 0.24910842, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8921\n","Epoch 577:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9713, F1: 0.9840 Bal: 0.9281\n","           WALLETS: Train Loss: 0.21202740, Acc: 0.91989231, F1: 0.95496473 Bal: 0.9156 - Val Loss: 0.24910924, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8921\n","Epoch 578:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21197994, Acc: 0.91973266, F1: 0.95487056 Bal: 0.9156 - Val Loss: 0.24905835, Accuracy: 0.9129, F1: 0.9510 Bal: 0.8922\n","Epoch 579:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21193260, Acc: 0.91976169, F1: 0.95488780 Bal: 0.9156 - Val Loss: 0.24905227, Accuracy: 0.9129, F1: 0.9509 Bal: 0.8922\n","Epoch 580:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21188575, Acc: 0.91989957, F1: 0.95496881 Bal: 0.9157 - Val Loss: 0.24906538, Accuracy: 0.9131, F1: 0.9510 Bal: 0.8922\n","Epoch 581:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9282\n","           WALLETS: Train Loss: 0.21183886, Acc: 0.91984151, F1: 0.95493452 Bal: 0.9157 - Val Loss: 0.24902990, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8922\n","Epoch 582:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21179235, Acc: 0.91981974, F1: 0.95492154 Bal: 0.9157 - Val Loss: 0.24899592, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8922\n","Epoch 583:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21174665, Acc: 0.91991045, F1: 0.95497502 Bal: 0.9157 - Val Loss: 0.24899790, Accuracy: 0.9131, F1: 0.9510 Bal: 0.8922\n","Epoch 584:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21170062, Acc: 0.91993222, F1: 0.95498781 Bal: 0.9157 - Val Loss: 0.24898876, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8923\n","Epoch 585:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2582, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21165544, Acc: 0.91987054, F1: 0.95495139 Bal: 0.9157 - Val Loss: 0.24895921, Accuracy: 0.9129, F1: 0.9510 Bal: 0.8922\n","Epoch 586:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9984 Bal: 0.9984 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21160980, Acc: 0.91992496, F1: 0.95498337 Bal: 0.9157 - Val Loss: 0.24895793, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8923\n","Epoch 587:      TX: Train Loss: 0.0143, Acc: 0.9972, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21156450, Acc: 0.92004107, F1: 0.95505176 Bal: 0.9158 - Val Loss: 0.24895933, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8923\n","Epoch 588:      TX: Train Loss: 0.0142, Acc: 0.9972, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2581, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21151955, Acc: 0.91997576, F1: 0.95501339 Bal: 0.9157 - Val Loss: 0.24892738, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8923\n","Epoch 589:      TX: Train Loss: 0.0142, Acc: 0.9972, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2581, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21147494, Acc: 0.91997939, F1: 0.95501479 Bal: 0.9158 - Val Loss: 0.24891642, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8923\n","Epoch 590:      TX: Train Loss: 0.0142, Acc: 0.9972, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2581, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21143030, Acc: 0.92005922, F1: 0.95506186 Bal: 0.9158 - Val Loss: 0.24892987, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8923\n","Epoch 591:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2582, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21138549, Acc: 0.92006647, F1: 0.95506594 Bal: 0.9159 - Val Loss: 0.24891822, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8923\n","Epoch 592:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21134101, Acc: 0.92006647, F1: 0.95506539 Bal: 0.9159 - Val Loss: 0.24889964, Accuracy: 0.9131, F1: 0.9511 Bal: 0.8921\n","Epoch 593:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21129617, Acc: 0.92009913, F1: 0.95508476 Bal: 0.9159 - Val Loss: 0.24889846, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8923\n","Epoch 594:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21125153, Acc: 0.92016807, F1: 0.95512525 Bal: 0.9160 - Val Loss: 0.24889423, Accuracy: 0.9132, F1: 0.9511 Bal: 0.8923\n","Epoch 595:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21120669, Acc: 0.92008461, F1: 0.95507568 Bal: 0.9160 - Val Loss: 0.24887334, Accuracy: 0.9133, F1: 0.9512 Bal: 0.8924\n","Epoch 596:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21116191, Acc: 0.92013904, F1: 0.95510784 Bal: 0.9160 - Val Loss: 0.24887063, Accuracy: 0.9133, F1: 0.9512 Bal: 0.8924\n","Epoch 597:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21111709, Acc: 0.92022249, F1: 0.95515667 Bal: 0.9161 - Val Loss: 0.24886867, Accuracy: 0.9133, F1: 0.9512 Bal: 0.8924\n","Epoch 598:      TX: Train Loss: 0.0142, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21107176, Acc: 0.92017895, F1: 0.95513128 Bal: 0.9160 - Val Loss: 0.24885461, Accuracy: 0.9134, F1: 0.9512 Bal: 0.8924\n","Epoch 599:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21102707, Acc: 0.92019709, F1: 0.95514138 Bal: 0.9161 - Val Loss: 0.24884439, Accuracy: 0.9134, F1: 0.9512 Bal: 0.8924\n","Epoch 600:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9284\n","           WALLETS: Train Loss: 0.21098189, Acc: 0.92025878, F1: 0.95517798 Bal: 0.9161 - Val Loss: 0.24884616, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8926\n","Epoch 601:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21093711, Acc: 0.92029869, F1: 0.95520105 Bal: 0.9161 - Val Loss: 0.24883486, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8926\n","Epoch 602:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21089192, Acc: 0.92028780, F1: 0.95519411 Bal: 0.9162 - Val Loss: 0.24882343, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8926\n","Epoch 603:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9283\n","           WALLETS: Train Loss: 0.21084686, Acc: 0.92031320, F1: 0.95520957 Bal: 0.9161 - Val Loss: 0.24882624, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8925\n","Epoch 604:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.21080202, Acc: 0.92032046, F1: 0.95521402 Bal: 0.9161 - Val Loss: 0.24882424, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8926\n","Epoch 605:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.21075679, Acc: 0.92032772, F1: 0.95521773 Bal: 0.9162 - Val Loss: 0.24881110, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8926\n","Epoch 606:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.21071196, Acc: 0.92034586, F1: 0.95522802 Bal: 0.9162 - Val Loss: 0.24880706, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8927\n","Epoch 607:      TX: Train Loss: 0.0141, Acc: 0.9973, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21066724, Acc: 0.92033860, F1: 0.95522412 Bal: 0.9162 - Val Loss: 0.24880585, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8927\n","Epoch 608:      TX: Train Loss: 0.0141, Acc: 0.9974, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21062246, Acc: 0.92037489, F1: 0.95524488 Bal: 0.9163 - Val Loss: 0.24880204, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8927\n","Epoch 609:      TX: Train Loss: 0.0141, Acc: 0.9974, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21057776, Acc: 0.92038214, F1: 0.95524914 Bal: 0.9163 - Val Loss: 0.24879387, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8927\n","Epoch 610:      TX: Train Loss: 0.0141, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21053322, Acc: 0.92038940, F1: 0.95525286 Bal: 0.9164 - Val Loss: 0.24878679, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8926\n","Epoch 611:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21048838, Acc: 0.92039666, F1: 0.95525712 Bal: 0.9164 - Val Loss: 0.24878232, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8928\n","Epoch 612:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21044406, Acc: 0.92041117, F1: 0.95526583 Bal: 0.9163 - Val Loss: 0.24877900, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8928\n","Epoch 613:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9985 Bal: 0.9985 - Val Loss: 0.2583, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21039911, Acc: 0.92045834, F1: 0.95529298 Bal: 0.9164 - Val Loss: 0.24877755, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8928\n","Epoch 614:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21035449, Acc: 0.92044745, F1: 0.95528622 Bal: 0.9165 - Val Loss: 0.24876323, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8928\n","Epoch 615:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21030971, Acc: 0.92043657, F1: 0.95528019 Bal: 0.9164 - Val Loss: 0.24875368, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8928\n","Epoch 616:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21026514, Acc: 0.92048737, F1: 0.95531020 Bal: 0.9164 - Val Loss: 0.24875325, Accuracy: 0.9136, F1: 0.9514 Bal: 0.8929\n","Epoch 617:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21022011, Acc: 0.92050551, F1: 0.95532049 Bal: 0.9165 - Val Loss: 0.24874224, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8928\n","Epoch 618:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21017513, Acc: 0.92050188, F1: 0.95531818 Bal: 0.9165 - Val Loss: 0.24872759, Accuracy: 0.9136, F1: 0.9513 Bal: 0.8928\n","Epoch 619:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21012996, Acc: 0.92052365, F1: 0.95533078 Bal: 0.9165 - Val Loss: 0.24871981, Accuracy: 0.9136, F1: 0.9514 Bal: 0.8929\n","Epoch 620:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21008469, Acc: 0.92052365, F1: 0.95533096 Bal: 0.9165 - Val Loss: 0.24870926, Accuracy: 0.9136, F1: 0.9514 Bal: 0.8929\n","Epoch 621:      TX: Train Loss: 0.0140, Acc: 0.9974, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.21003929, Acc: 0.92052365, F1: 0.95533078 Bal: 0.9165 - Val Loss: 0.24869703, Accuracy: 0.9136, F1: 0.9514 Bal: 0.8927\n","Epoch 622:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20999381, Acc: 0.92052002, F1: 0.95532865 Bal: 0.9165 - Val Loss: 0.24868821, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8927\n","Epoch 623:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20994832, Acc: 0.92053816, F1: 0.95533930 Bal: 0.9165 - Val Loss: 0.24867952, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8927\n","Epoch 624:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20990272, Acc: 0.92053454, F1: 0.95533735 Bal: 0.9165 - Val Loss: 0.24866958, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8927\n","Epoch 625:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20985721, Acc: 0.92054542, F1: 0.95534374 Bal: 0.9165 - Val Loss: 0.24866222, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8927\n","Epoch 626:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20981257, Acc: 0.92052728, F1: 0.95533273 Bal: 0.9166 - Val Loss: 0.24865165, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8927\n","Epoch 627:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2584, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20976675, Acc: 0.92053816, F1: 0.95533875 Bal: 0.9166 - Val Loss: 0.24863648, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8927\n","Epoch 628:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20972149, Acc: 0.92057808, F1: 0.95536219 Bal: 0.9166 - Val Loss: 0.24862833, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8928\n","Epoch 629:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20967558, Acc: 0.92056356, F1: 0.95535367 Bal: 0.9166 - Val Loss: 0.24861507, Accuracy: 0.9136, F1: 0.9514 Bal: 0.8926\n","Epoch 630:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2585, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20962974, Acc: 0.92058170, F1: 0.95536413 Bal: 0.9167 - Val Loss: 0.24860977, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 631:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2586, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20958403, Acc: 0.92061799, F1: 0.95538507 Bal: 0.9167 - Val Loss: 0.24860370, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 632:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2586, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20953777, Acc: 0.92066879, F1: 0.95541471 Bal: 0.9168 - Val Loss: 0.24858911, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8928\n","Epoch 633:      TX: Train Loss: 0.0139, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2586, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20949228, Acc: 0.92071233, F1: 0.95543991 Bal: 0.9168 - Val Loss: 0.24858221, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 634:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2587, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20944628, Acc: 0.92068330, F1: 0.95542287 Bal: 0.9168 - Val Loss: 0.24856888, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 635:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2587, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20940039, Acc: 0.92070870, F1: 0.95543778 Bal: 0.9168 - Val Loss: 0.24856406, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 636:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2586, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20935445, Acc: 0.92074861, F1: 0.95546121 Bal: 0.9169 - Val Loss: 0.24856099, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 637:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2586, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20930772, Acc: 0.92075950, F1: 0.95546742 Bal: 0.9169 - Val Loss: 0.24853913, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 638:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2587, Accuracy: 0.9715, F1: 0.9841 Bal: 0.9272\n","           WALLETS: Train Loss: 0.20926212, Acc: 0.92076675, F1: 0.95547113 Bal: 0.9169 - Val Loss: 0.24853134, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 639:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20921592, Acc: 0.92079941, F1: 0.95549049 Bal: 0.9169 - Val Loss: 0.24853370, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8926\n","Epoch 640:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20916997, Acc: 0.92078127, F1: 0.95548002 Bal: 0.9169 - Val Loss: 0.24851650, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8924\n","Epoch 641:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20912378, Acc: 0.92079941, F1: 0.95549049 Bal: 0.9169 - Val Loss: 0.24850203, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8924\n","Epoch 642:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20907760, Acc: 0.92086472, F1: 0.95552937 Bal: 0.9169 - Val Loss: 0.24850078, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8924\n","Epoch 643:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20903134, Acc: 0.92086109, F1: 0.95552705 Bal: 0.9169 - Val Loss: 0.24848798, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 644:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2587, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20898519, Acc: 0.92085383, F1: 0.95552243 Bal: 0.9170 - Val Loss: 0.24847107, Accuracy: 0.9137, F1: 0.9514 Bal: 0.8925\n","Epoch 645:      TX: Train Loss: 0.0138, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20893937, Acc: 0.92090100, F1: 0.95555012 Bal: 0.9170 - Val Loss: 0.24846338, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 646:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20889330, Acc: 0.92087560, F1: 0.95553485 Bal: 0.9170 - Val Loss: 0.24845195, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 647:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20884719, Acc: 0.92090826, F1: 0.95555401 Bal: 0.9170 - Val Loss: 0.24844514, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 648:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20880136, Acc: 0.92094454, F1: 0.95557495 Bal: 0.9171 - Val Loss: 0.24843293, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 649:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20875551, Acc: 0.92096994, F1: 0.95558949 Bal: 0.9172 - Val Loss: 0.24841911, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 650:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20870982, Acc: 0.92096994, F1: 0.95558949 Bal: 0.9172 - Val Loss: 0.24841090, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 651:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20866376, Acc: 0.92102074, F1: 0.95561912 Bal: 0.9172 - Val Loss: 0.24840042, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 652:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2588, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20861824, Acc: 0.92099171, F1: 0.95560173 Bal: 0.9172 - Val Loss: 0.24838062, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8923\n","Epoch 653:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20857221, Acc: 0.92100985, F1: 0.95561274 Bal: 0.9172 - Val Loss: 0.24838457, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8923\n","Epoch 654:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20852636, Acc: 0.92107154, F1: 0.95564875 Bal: 0.9173 - Val Loss: 0.24838154, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8923\n","Epoch 655:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20848030, Acc: 0.92106065, F1: 0.95564128 Bal: 0.9174 - Val Loss: 0.24836066, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8923\n","Epoch 656:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20843415, Acc: 0.92110056, F1: 0.95566470 Bal: 0.9174 - Val Loss: 0.24835661, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8923\n","Epoch 657:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20838824, Acc: 0.92113322, F1: 0.95568441 Bal: 0.9174 - Val Loss: 0.24834779, Accuracy: 0.9139, F1: 0.9515 Bal: 0.8924\n","Epoch 658:      TX: Train Loss: 0.0137, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20834257, Acc: 0.92111871, F1: 0.95567499 Bal: 0.9175 - Val Loss: 0.24831523, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8925\n","Epoch 659:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2589, Accuracy: 0.9717, F1: 0.9843 Bal: 0.9273\n","           WALLETS: Train Loss: 0.20829666, Acc: 0.92117313, F1: 0.95570729 Bal: 0.9174 - Val Loss: 0.24830841, Accuracy: 0.9139, F1: 0.9515 Bal: 0.8925\n","Epoch 660:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2590, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20825092, Acc: 0.92119853, F1: 0.95572201 Bal: 0.9175 - Val Loss: 0.24830467, Accuracy: 0.9140, F1: 0.9516 Bal: 0.8926\n","Epoch 661:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2590, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20820519, Acc: 0.92118402, F1: 0.95571313 Bal: 0.9175 - Val Loss: 0.24828304, Accuracy: 0.9141, F1: 0.9517 Bal: 0.8926\n","Epoch 662:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2590, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20815937, Acc: 0.92121667, F1: 0.95573211 Bal: 0.9176 - Val Loss: 0.24827600, Accuracy: 0.9141, F1: 0.9517 Bal: 0.8927\n","Epoch 663:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2591, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20811364, Acc: 0.92119853, F1: 0.95572201 Bal: 0.9175 - Val Loss: 0.24827014, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8926\n","Epoch 664:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2592, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20806786, Acc: 0.92122393, F1: 0.95573583 Bal: 0.9176 - Val Loss: 0.24824709, Accuracy: 0.9141, F1: 0.9517 Bal: 0.8925\n","Epoch 665:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2592, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20802242, Acc: 0.92122393, F1: 0.95573619 Bal: 0.9176 - Val Loss: 0.24822795, Accuracy: 0.9141, F1: 0.9517 Bal: 0.8925\n","Epoch 666:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2592, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20797716, Acc: 0.92126384, F1: 0.95575961 Bal: 0.9176 - Val Loss: 0.24822298, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8925\n","Epoch 667:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20793168, Acc: 0.92127110, F1: 0.95576351 Bal: 0.9177 - Val Loss: 0.24820530, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8925\n","Epoch 668:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2592, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20788623, Acc: 0.92122756, F1: 0.95573814 Bal: 0.9176 - Val Loss: 0.24817689, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8925\n","Epoch 669:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2592, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20784046, Acc: 0.92125296, F1: 0.95575340 Bal: 0.9176 - Val Loss: 0.24816984, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8925\n","Epoch 670:      TX: Train Loss: 0.0136, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20779495, Acc: 0.92127836, F1: 0.95576794 Bal: 0.9176 - Val Loss: 0.24816164, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8924\n","Epoch 671:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20774914, Acc: 0.92128924, F1: 0.95577415 Bal: 0.9177 - Val Loss: 0.24815096, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8924\n","Epoch 672:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20770347, Acc: 0.92128198, F1: 0.95576989 Bal: 0.9177 - Val Loss: 0.24813353, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8924\n","Epoch 673:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20765769, Acc: 0.92132553, F1: 0.95579616 Bal: 0.9176 - Val Loss: 0.24813101, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8924\n","Epoch 674:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20761190, Acc: 0.92132553, F1: 0.95579544 Bal: 0.9177 - Val Loss: 0.24811900, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8924\n","Epoch 675:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20756628, Acc: 0.92132190, F1: 0.95579259 Bal: 0.9178 - Val Loss: 0.24810660, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8924\n","Epoch 676:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20752010, Acc: 0.92134730, F1: 0.95580749 Bal: 0.9178 - Val Loss: 0.24810627, Accuracy: 0.9143, F1: 0.9517 Bal: 0.8926\n","Epoch 677:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20747474, Acc: 0.92136907, F1: 0.95582026 Bal: 0.9178 - Val Loss: 0.24809390, Accuracy: 0.9143, F1: 0.9518 Bal: 0.8926\n","Epoch 678:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20742929, Acc: 0.92136544, F1: 0.95581705 Bal: 0.9179 - Val Loss: 0.24807204, Accuracy: 0.9143, F1: 0.9518 Bal: 0.8929\n","Epoch 679:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20738336, Acc: 0.92139446, F1: 0.95583408 Bal: 0.9179 - Val Loss: 0.24806955, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8930\n","Epoch 680:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20733701, Acc: 0.92139809, F1: 0.95583621 Bal: 0.9179 - Val Loss: 0.24805123, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8930\n","Epoch 681:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20729093, Acc: 0.92140535, F1: 0.95584029 Bal: 0.9180 - Val Loss: 0.24804239, Accuracy: 0.9144, F1: 0.9518 Bal: 0.8930\n","Epoch 682:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20724462, Acc: 0.92146340, F1: 0.95587471 Bal: 0.9179 - Val Loss: 0.24805406, Accuracy: 0.9144, F1: 0.9519 Bal: 0.8930\n","Epoch 683:      TX: Train Loss: 0.0135, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20719822, Acc: 0.92145978, F1: 0.95587222 Bal: 0.9180 - Val Loss: 0.24804150, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8930\n","Epoch 684:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2593, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20715173, Acc: 0.92146703, F1: 0.95587576 Bal: 0.9181 - Val Loss: 0.24803376, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8932\n","Epoch 685:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20710529, Acc: 0.92148155, F1: 0.95588427 Bal: 0.9181 - Val Loss: 0.24802253, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8932\n","Epoch 686:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20705840, Acc: 0.92153960, F1: 0.95591833 Bal: 0.9181 - Val Loss: 0.24801706, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8932\n","Epoch 687:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20701155, Acc: 0.92154323, F1: 0.95592010 Bal: 0.9182 - Val Loss: 0.24799994, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8932\n","Epoch 688:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20696458, Acc: 0.92156863, F1: 0.95593428 Bal: 0.9183 - Val Loss: 0.24798219, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8932\n","Epoch 689:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20691738, Acc: 0.92159040, F1: 0.95594705 Bal: 0.9183 - Val Loss: 0.24798132, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8932\n","Epoch 690:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2594, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20686993, Acc: 0.92159765, F1: 0.95595112 Bal: 0.9183 - Val Loss: 0.24796444, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8932\n","Epoch 691:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20682232, Acc: 0.92164482, F1: 0.95597915 Bal: 0.9183 - Val Loss: 0.24796860, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8932\n","Epoch 692:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20677480, Acc: 0.92166659, F1: 0.95599210 Bal: 0.9183 - Val Loss: 0.24795538, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8932\n","Epoch 693:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20672701, Acc: 0.92160854, F1: 0.95595751 Bal: 0.9183 - Val Loss: 0.24792092, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8932\n","Epoch 694:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20667933, Acc: 0.92168111, F1: 0.95599989 Bal: 0.9184 - Val Loss: 0.24791688, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8932\n","Epoch 695:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20663226, Acc: 0.92168836, F1: 0.95600415 Bal: 0.9184 - Val Loss: 0.24789532, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8932\n","Epoch 696:      TX: Train Loss: 0.0134, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20658614, Acc: 0.92161217, F1: 0.95595946 Bal: 0.9183 - Val Loss: 0.24786450, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8932\n","Epoch 697:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2596, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20654015, Acc: 0.92173553, F1: 0.95603199 Bal: 0.9184 - Val Loss: 0.24788439, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8931\n","Epoch 698:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20649391, Acc: 0.92178633, F1: 0.95606179 Bal: 0.9184 - Val Loss: 0.24787867, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8931\n","Epoch 699:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9719, F1: 0.9844 Bal: 0.9275\n","           WALLETS: Train Loss: 0.20644763, Acc: 0.92177545, F1: 0.95605522 Bal: 0.9184 - Val Loss: 0.24785538, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8930\n","Epoch 700:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2596, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20640099, Acc: 0.92184801, F1: 0.95609796 Bal: 0.9184 - Val Loss: 0.24785294, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8931\n","Epoch 701:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2596, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20635480, Acc: 0.92182262, F1: 0.95608306 Bal: 0.9184 - Val Loss: 0.24783354, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8931\n","Epoch 702:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20630883, Acc: 0.92185164, F1: 0.95609991 Bal: 0.9185 - Val Loss: 0.24781667, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8929\n","Epoch 703:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20626231, Acc: 0.92186616, F1: 0.95610842 Bal: 0.9185 - Val Loss: 0.24781248, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8929\n","Epoch 704:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2596, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20621565, Acc: 0.92189518, F1: 0.95612508 Bal: 0.9185 - Val Loss: 0.24779524, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8929\n","Epoch 705:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2596, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20616904, Acc: 0.92190970, F1: 0.95613377 Bal: 0.9185 - Val Loss: 0.24778706, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8930\n","Epoch 706:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20612253, Acc: 0.92195324, F1: 0.95615912 Bal: 0.9186 - Val Loss: 0.24778782, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8930\n","Epoch 707:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20607615, Acc: 0.92194961, F1: 0.95615682 Bal: 0.9186 - Val Loss: 0.24776763, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8929\n","Epoch 708:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2595, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20602964, Acc: 0.92196775, F1: 0.95616763 Bal: 0.9186 - Val Loss: 0.24775851, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8929\n","Epoch 709:      TX: Train Loss: 0.0133, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20598312, Acc: 0.92200403, F1: 0.95618909 Bal: 0.9186 - Val Loss: 0.24776323, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8930\n","Epoch 710:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20593627, Acc: 0.92203306, F1: 0.95620539 Bal: 0.9187 - Val Loss: 0.24774587, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8928\n","Epoch 711:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20588934, Acc: 0.92204395, F1: 0.95621177 Bal: 0.9187 - Val Loss: 0.24773319, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8928\n","Epoch 712:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2598, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20584264, Acc: 0.92207297, F1: 0.95622897 Bal: 0.9187 - Val Loss: 0.24772324, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8926\n","Epoch 713:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2598, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20579584, Acc: 0.92202581, F1: 0.95620078 Bal: 0.9187 - Val Loss: 0.24768957, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8926\n","Epoch 714:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2597, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20574886, Acc: 0.92207660, F1: 0.95623038 Bal: 0.9188 - Val Loss: 0.24769868, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8926\n","Epoch 715:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2598, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20570141, Acc: 0.92211289, F1: 0.95625166 Bal: 0.9188 - Val Loss: 0.24769147, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8926\n","Epoch 716:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2599, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20565361, Acc: 0.92208023, F1: 0.95623251 Bal: 0.9188 - Val Loss: 0.24767904, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8926\n","Epoch 717:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2598, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20560579, Acc: 0.92204032, F1: 0.95620929 Bal: 0.9187 - Val Loss: 0.24767438, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8926\n","Epoch 718:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2599, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20555805, Acc: 0.92213466, F1: 0.95626478 Bal: 0.9187 - Val Loss: 0.24768215, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8926\n","Epoch 719:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2598, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20551014, Acc: 0.92208023, F1: 0.95623269 Bal: 0.9187 - Val Loss: 0.24765685, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8926\n","Epoch 720:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2599, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20546247, Acc: 0.92213103, F1: 0.95626247 Bal: 0.9188 - Val Loss: 0.24767090, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8926\n","Epoch 721:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20541465, Acc: 0.92211651, F1: 0.95625343 Bal: 0.9188 - Val Loss: 0.24765520, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8926\n","Epoch 722:      TX: Train Loss: 0.0132, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20536675, Acc: 0.92206209, F1: 0.95622152 Bal: 0.9188 - Val Loss: 0.24762860, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8927\n","Epoch 723:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9721, F1: 0.9845 Bal: 0.9276\n","           WALLETS: Train Loss: 0.20531908, Acc: 0.92218908, F1: 0.95629632 Bal: 0.9188 - Val Loss: 0.24765369, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8925\n","Epoch 724:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9277\n","           WALLETS: Train Loss: 0.20527227, Acc: 0.92209837, F1: 0.95624243 Bal: 0.9189 - Val Loss: 0.24761614, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8925\n","Epoch 725:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9277\n","           WALLETS: Train Loss: 0.20522478, Acc: 0.92214917, F1: 0.95627257 Bal: 0.9188 - Val Loss: 0.24762197, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8926\n","Epoch 726:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9277\n","           WALLETS: Train Loss: 0.20517778, Acc: 0.92224351, F1: 0.95632770 Bal: 0.9189 - Val Loss: 0.24763125, Accuracy: 0.9146, F1: 0.9520 Bal: 0.8926\n","Epoch 727:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2601, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9277\n","           WALLETS: Train Loss: 0.20513092, Acc: 0.92213829, F1: 0.95626565 Bal: 0.9189 - Val Loss: 0.24759144, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8927\n","Epoch 728:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2601, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20508429, Acc: 0.92225439, F1: 0.95633408 Bal: 0.9189 - Val Loss: 0.24759974, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8927\n","Epoch 729:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9287\n","           WALLETS: Train Loss: 0.20503852, Acc: 0.92229068, F1: 0.95635534 Bal: 0.9189 - Val Loss: 0.24759476, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8927\n","Epoch 730:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9287\n","           WALLETS: Train Loss: 0.20499176, Acc: 0.92225077, F1: 0.95633141 Bal: 0.9190 - Val Loss: 0.24757373, Accuracy: 0.9146, F1: 0.9519 Bal: 0.8927\n","Epoch 731:      TX: Train Loss: 0.0131, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9287\n","           WALLETS: Train Loss: 0.20494549, Acc: 0.92235599, F1: 0.95639327 Bal: 0.9190 - Val Loss: 0.24759321, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8926\n","Epoch 732:      TX: Train Loss: 0.0131, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2600, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9287\n","           WALLETS: Train Loss: 0.20489939, Acc: 0.92234148, F1: 0.95638441 Bal: 0.9190 - Val Loss: 0.24757142, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8928\n","Epoch 733:      TX: Train Loss: 0.0131, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2601, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9287\n","           WALLETS: Train Loss: 0.20485395, Acc: 0.92226891, F1: 0.95634169 Bal: 0.9190 - Val Loss: 0.24755336, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8928\n","Epoch 734:      TX: Train Loss: 0.0131, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2601, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9287\n","           WALLETS: Train Loss: 0.20480829, Acc: 0.92235236, F1: 0.95639079 Bal: 0.9191 - Val Loss: 0.24757518, Accuracy: 0.9148, F1: 0.9521 Bal: 0.8929\n","Epoch 735:      TX: Train Loss: 0.0131, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2600, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20476292, Acc: 0.92232333, F1: 0.95637360 Bal: 0.9191 - Val Loss: 0.24755488, Accuracy: 0.9148, F1: 0.9521 Bal: 0.8929\n","Epoch 736:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2602, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20471723, Acc: 0.92237413, F1: 0.95640337 Bal: 0.9191 - Val Loss: 0.24755396, Accuracy: 0.9148, F1: 0.9521 Bal: 0.8929\n","Epoch 737:      TX: Train Loss: 0.0130, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2602, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20467161, Acc: 0.92241041, F1: 0.95642410 Bal: 0.9192 - Val Loss: 0.24755275, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8929\n","Epoch 738:      TX: Train Loss: 0.0130, Acc: 0.9975, F1: 0.9986 Bal: 0.9986 - Val Loss: 0.2601, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20462653, Acc: 0.92242493, F1: 0.95643243 Bal: 0.9192 - Val Loss: 0.24753588, Accuracy: 0.9149, F1: 0.9522 Bal: 0.8929\n","Epoch 739:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2602, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20458142, Acc: 0.92242856, F1: 0.95643474 Bal: 0.9192 - Val Loss: 0.24753003, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8929\n","Epoch 740:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9986 Bal: 0.9987 - Val Loss: 0.2602, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9288\n","           WALLETS: Train Loss: 0.20453642, Acc: 0.92244670, F1: 0.95644537 Bal: 0.9192 - Val Loss: 0.24752048, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8929\n","Epoch 741:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2602, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20449181, Acc: 0.92247210, F1: 0.95646008 Bal: 0.9192 - Val Loss: 0.24750462, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8929\n","Epoch 742:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2602, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20444690, Acc: 0.92247935, F1: 0.95646433 Bal: 0.9192 - Val Loss: 0.24750185, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8929\n","Epoch 743:      TX: Train Loss: 0.0130, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2602, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20440240, Acc: 0.92249024, F1: 0.95647053 Bal: 0.9193 - Val Loss: 0.24749385, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8931\n","Epoch 744:      TX: Train Loss: 0.0130, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2603, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20435736, Acc: 0.92251201, F1: 0.95648329 Bal: 0.9193 - Val Loss: 0.24748729, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8931\n","Epoch 745:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2603, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20431228, Acc: 0.92248661, F1: 0.95646769 Bal: 0.9193 - Val Loss: 0.24746116, Accuracy: 0.9149, F1: 0.9521 Bal: 0.8931\n","Epoch 746:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2603, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20426738, Acc: 0.92254467, F1: 0.95650225 Bal: 0.9193 - Val Loss: 0.24747279, Accuracy: 0.9151, F1: 0.9522 Bal: 0.8933\n","Epoch 747:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2603, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20422263, Acc: 0.92258821, F1: 0.95652776 Bal: 0.9193 - Val Loss: 0.24746041, Accuracy: 0.9150, F1: 0.9522 Bal: 0.8933\n","Epoch 748:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2604, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20417774, Acc: 0.92254829, F1: 0.95650526 Bal: 0.9192 - Val Loss: 0.24744502, Accuracy: 0.9150, F1: 0.9522 Bal: 0.8933\n","Epoch 749:      TX: Train Loss: 0.0130, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2603, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20413299, Acc: 0.92263900, F1: 0.95655824 Bal: 0.9193 - Val Loss: 0.24746354, Accuracy: 0.9151, F1: 0.9523 Bal: 0.8934\n","Epoch 750:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2604, Accuracy: 0.9730, F1: 0.9850 Bal: 0.9290\n","           WALLETS: Train Loss: 0.20408826, Acc: 0.92257732, F1: 0.95652156 Bal: 0.9193 - Val Loss: 0.24743603, Accuracy: 0.9151, F1: 0.9522 Bal: 0.8933\n","Epoch 751:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20404363, Acc: 0.92263900, F1: 0.95655788 Bal: 0.9193 - Val Loss: 0.24744026, Accuracy: 0.9151, F1: 0.9523 Bal: 0.8934\n","Epoch 752:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20399876, Acc: 0.92263538, F1: 0.95655540 Bal: 0.9194 - Val Loss: 0.24741758, Accuracy: 0.9151, F1: 0.9523 Bal: 0.8934\n","Epoch 753:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20395426, Acc: 0.92264626, F1: 0.95656160 Bal: 0.9194 - Val Loss: 0.24741735, Accuracy: 0.9151, F1: 0.9523 Bal: 0.8934\n","Epoch 754:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20390975, Acc: 0.92270794, F1: 0.95659792 Bal: 0.9194 - Val Loss: 0.24742725, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8934\n","Epoch 755:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20386516, Acc: 0.92265715, F1: 0.95656798 Bal: 0.9194 - Val Loss: 0.24740268, Accuracy: 0.9151, F1: 0.9523 Bal: 0.8934\n","Epoch 756:      TX: Train Loss: 0.0129, Acc: 0.9976, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20382096, Acc: 0.92270794, F1: 0.95659739 Bal: 0.9195 - Val Loss: 0.24740623, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8934\n","Epoch 757:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9728, F1: 0.9849 Bal: 0.9279\n","           WALLETS: Train Loss: 0.20377661, Acc: 0.92270431, F1: 0.95659527 Bal: 0.9195 - Val Loss: 0.24738948, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8934\n","Epoch 758:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20373206, Acc: 0.92271157, F1: 0.95659934 Bal: 0.9195 - Val Loss: 0.24737617, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8934\n","Epoch 759:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20368814, Acc: 0.92274423, F1: 0.95661847 Bal: 0.9195 - Val Loss: 0.24737723, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8934\n","Epoch 760:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20364331, Acc: 0.92273697, F1: 0.95661352 Bal: 0.9196 - Val Loss: 0.24735546, Accuracy: 0.9151, F1: 0.9522 Bal: 0.8933\n","Epoch 761:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20359911, Acc: 0.92274060, F1: 0.95661599 Bal: 0.9195 - Val Loss: 0.24734436, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8934\n","Epoch 762:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2605, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20355427, Acc: 0.92276237, F1: 0.95662875 Bal: 0.9196 - Val Loss: 0.24733683, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8932\n","Epoch 763:      TX: Train Loss: 0.0129, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20350978, Acc: 0.92276963, F1: 0.95663300 Bal: 0.9196 - Val Loss: 0.24731360, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8932\n","Epoch 764:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20346588, Acc: 0.92280228, F1: 0.95665178 Bal: 0.9196 - Val Loss: 0.24729846, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8931\n","Epoch 765:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20342159, Acc: 0.92278414, F1: 0.95664080 Bal: 0.9197 - Val Loss: 0.24728456, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8931\n","Epoch 766:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20337720, Acc: 0.92284219, F1: 0.95667446 Bal: 0.9197 - Val Loss: 0.24728926, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8930\n","Epoch 767:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20333281, Acc: 0.92280228, F1: 0.95665072 Bal: 0.9197 - Val Loss: 0.24726140, Accuracy: 0.9153, F1: 0.9523 Bal: 0.8930\n","Epoch 768:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20328850, Acc: 0.92283131, F1: 0.95666826 Bal: 0.9197 - Val Loss: 0.24727586, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8929\n","Epoch 769:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20324448, Acc: 0.92276963, F1: 0.95663212 Bal: 0.9197 - Val Loss: 0.24723968, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8928\n","Epoch 770:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20320028, Acc: 0.92286759, F1: 0.95668951 Bal: 0.9197 - Val Loss: 0.24725345, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8929\n","Epoch 771:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20315638, Acc: 0.92281680, F1: 0.95665940 Bal: 0.9197 - Val Loss: 0.24722289, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8928\n","Epoch 772:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20311275, Acc: 0.92290388, F1: 0.95671094 Bal: 0.9197 - Val Loss: 0.24723496, Accuracy: 0.9154, F1: 0.9525 Bal: 0.8929\n","Epoch 773:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2606, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20306896, Acc: 0.92287485, F1: 0.95669341 Bal: 0.9198 - Val Loss: 0.24719661, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8929\n","Epoch 774:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20302501, Acc: 0.92287848, F1: 0.95669554 Bal: 0.9198 - Val Loss: 0.24719633, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8927\n","Epoch 775:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20298152, Acc: 0.92287848, F1: 0.95669554 Bal: 0.9198 - Val Loss: 0.24719252, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8929\n","Epoch 776:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20293792, Acc: 0.92288573, F1: 0.95669961 Bal: 0.9198 - Val Loss: 0.24717732, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8931\n","Epoch 777:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2608, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20289364, Acc: 0.92294742, F1: 0.95673592 Bal: 0.9198 - Val Loss: 0.24719176, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8927\n","Epoch 778:      TX: Train Loss: 0.0128, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2608, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20285010, Acc: 0.92289299, F1: 0.95670404 Bal: 0.9198 - Val Loss: 0.24715400, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8928\n","Epoch 779:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2609, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20280594, Acc: 0.92301273, F1: 0.95677418 Bal: 0.9198 - Val Loss: 0.24718170, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8927\n","Epoch 780:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2607, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20276222, Acc: 0.92290750, F1: 0.95671184 Bal: 0.9199 - Val Loss: 0.24712007, Accuracy: 0.9153, F1: 0.9523 Bal: 0.8927\n","Epoch 781:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2609, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20271836, Acc: 0.92308167, F1: 0.95681385 Bal: 0.9200 - Val Loss: 0.24714704, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8927\n","Epoch 782:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2608, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20267434, Acc: 0.92292565, F1: 0.95672193 Bal: 0.9199 - Val Loss: 0.24706891, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8928\n","Epoch 783:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2608, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20263053, Acc: 0.92311795, F1: 0.95683581 Bal: 0.9199 - Val Loss: 0.24712610, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8927\n","Epoch 784:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20258678, Acc: 0.92294742, F1: 0.95673433 Bal: 0.9200 - Val Loss: 0.24705070, Accuracy: 0.9153, F1: 0.9523 Bal: 0.8927\n","Epoch 785:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20254245, Acc: 0.92312158, F1: 0.95683793 Bal: 0.9199 - Val Loss: 0.24710271, Accuracy: 0.9155, F1: 0.9525 Bal: 0.8926\n","Epoch 786:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2609, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20249854, Acc: 0.92298007, F1: 0.95675399 Bal: 0.9200 - Val Loss: 0.24703750, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8929\n","Epoch 787:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20245430, Acc: 0.92312158, F1: 0.95683758 Bal: 0.9199 - Val Loss: 0.24707603, Accuracy: 0.9154, F1: 0.9525 Bal: 0.8926\n","Epoch 788:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20240998, Acc: 0.92303450, F1: 0.95678605 Bal: 0.9200 - Val Loss: 0.24701956, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8925\n","Epoch 789:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20236519, Acc: 0.92312521, F1: 0.95683953 Bal: 0.9200 - Val Loss: 0.24703763, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8926\n","Epoch 790:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20232075, Acc: 0.92309981, F1: 0.95682430 Bal: 0.9200 - Val Loss: 0.24702051, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8926\n","Epoch 791:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20227599, Acc: 0.92312521, F1: 0.95683918 Bal: 0.9200 - Val Loss: 0.24702059, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8926\n","Epoch 792:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20223135, Acc: 0.92317238, F1: 0.95686628 Bal: 0.9201 - Val Loss: 0.24702714, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8924\n","Epoch 793:      TX: Train Loss: 0.0127, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20218645, Acc: 0.92310344, F1: 0.95682555 Bal: 0.9201 - Val Loss: 0.24699762, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8923\n","Epoch 794:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20214181, Acc: 0.92324857, F1: 0.95691213 Bal: 0.9200 - Val Loss: 0.24704513, Accuracy: 0.9153, F1: 0.9524 Bal: 0.8924\n","Epoch 795:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2609, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20209712, Acc: 0.92310707, F1: 0.95682697 Bal: 0.9202 - Val Loss: 0.24696529, Accuracy: 0.9153, F1: 0.9523 Bal: 0.8925\n","Epoch 796:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20205230, Acc: 0.92341548, F1: 0.95700951 Bal: 0.9201 - Val Loss: 0.24706879, Accuracy: 0.9154, F1: 0.9524 Bal: 0.8924\n","Epoch 797:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20200808, Acc: 0.92307804, F1: 0.95680856 Bal: 0.9203 - Val Loss: 0.24692145, Accuracy: 0.9152, F1: 0.9523 Bal: 0.8929\n","Epoch 798:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20196347, Acc: 0.92356424, F1: 0.95709782 Bal: 0.9201 - Val Loss: 0.24714363, Accuracy: 0.9156, F1: 0.9525 Bal: 0.8923\n","Epoch 799:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20192078, Acc: 0.92278777, F1: 0.95663798 Bal: 0.9203 - Val Loss: 0.24684681, Accuracy: 0.9151, F1: 0.9522 Bal: 0.8932\n","Epoch 800:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20187937, Acc: 0.92395248, F1: 0.95732677 Bal: 0.9200 - Val Loss: 0.24727276, Accuracy: 0.9159, F1: 0.9527 Bal: 0.8920\n","Epoch 801:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.20184289, Acc: 0.92229431, F1: 0.95634662 Bal: 0.9202 - Val Loss: 0.24669316, Accuracy: 0.9147, F1: 0.9520 Bal: 0.8930\n","Epoch 802:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.20180812, Acc: 0.92452214, F1: 0.95766306 Bal: 0.9200 - Val Loss: 0.24748956, Accuracy: 0.9165, F1: 0.9531 Bal: 0.8922\n","Epoch 803:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.20178370, Acc: 0.92173553, F1: 0.95601622 Bal: 0.9203 - Val Loss: 0.24646880, Accuracy: 0.9142, F1: 0.9517 Bal: 0.8933\n","Epoch 804:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.20176168, Acc: 0.92523331, F1: 0.95808244 Bal: 0.9199 - Val Loss: 0.24779923, Accuracy: 0.9172, F1: 0.9535 Bal: 0.8925\n","Epoch 805:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.20175265, Acc: 0.92090463, F1: 0.95552377 Bal: 0.9204 - Val Loss: 0.24621868, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8937\n","Epoch 806:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20174091, Acc: 0.92618032, F1: 0.95863988 Bal: 0.9198 - Val Loss: 0.24813667, Accuracy: 0.9180, F1: 0.9540 Bal: 0.8926\n","Epoch 807:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9724, F1: 0.9846 Bal: 0.9267\n","           WALLETS: Train Loss: 0.20174032, Acc: 0.92020435, F1: 0.95510866 Bal: 0.9204 - Val Loss: 0.24600577, Accuracy: 0.9126, F1: 0.9507 Bal: 0.8937\n","Epoch 808:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20172226, Acc: 0.92672820, F1: 0.95896229 Bal: 0.9198 - Val Loss: 0.24844275, Accuracy: 0.9186, F1: 0.9543 Bal: 0.8921\n","Epoch 809:      TX: Train Loss: 0.0126, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2610, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20170753, Acc: 0.91976894, F1: 0.95485136 Bal: 0.9203 - Val Loss: 0.24588375, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8939\n","Epoch 810:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20165886, Acc: 0.92700033, F1: 0.95912110 Bal: 0.9199 - Val Loss: 0.24853221, Accuracy: 0.9188, F1: 0.9545 Bal: 0.8921\n","Epoch 811:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20160937, Acc: 0.91986328, F1: 0.95490684 Bal: 0.9204 - Val Loss: 0.24588959, Accuracy: 0.9123, F1: 0.9506 Bal: 0.8939\n","Epoch 812:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2613, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20152391, Acc: 0.92664475, F1: 0.95891213 Bal: 0.9199 - Val Loss: 0.24834366, Accuracy: 0.9185, F1: 0.9543 Bal: 0.8922\n","Epoch 813:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20144381, Acc: 0.92053454, F1: 0.95530436 Bal: 0.9204 - Val Loss: 0.24604940, Accuracy: 0.9130, F1: 0.9510 Bal: 0.8939\n","Epoch 814:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20134905, Acc: 0.92588642, F1: 0.95846517 Bal: 0.9201 - Val Loss: 0.24791864, Accuracy: 0.9177, F1: 0.9538 Bal: 0.8925\n","Epoch 815:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20126778, Acc: 0.92160491, F1: 0.95593778 Bal: 0.9204 - Val Loss: 0.24633197, Accuracy: 0.9138, F1: 0.9515 Bal: 0.8931\n","Epoch 816:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20119062, Acc: 0.92474710, F1: 0.95779337 Bal: 0.9202 - Val Loss: 0.24742296, Accuracy: 0.9166, F1: 0.9531 Bal: 0.8923\n","Epoch 817:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20112880, Acc: 0.92276600, F1: 0.95662310 Bal: 0.9205 - Val Loss: 0.24665104, Accuracy: 0.9150, F1: 0.9522 Bal: 0.8928\n","Epoch 818:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20107512, Acc: 0.92381460, F1: 0.95724296 Bal: 0.9204 - Val Loss: 0.24701716, Accuracy: 0.9157, F1: 0.9526 Bal: 0.8920\n","Epoch 819:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20102909, Acc: 0.92368761, F1: 0.95716794 Bal: 0.9204 - Val Loss: 0.24695009, Accuracy: 0.9157, F1: 0.9526 Bal: 0.8919\n","Epoch 820:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2613, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20098920, Acc: 0.92309255, F1: 0.95681548 Bal: 0.9205 - Val Loss: 0.24673504, Accuracy: 0.9155, F1: 0.9525 Bal: 0.8929\n","Epoch 821:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20095173, Acc: 0.92437338, F1: 0.95757176 Bal: 0.9204 - Val Loss: 0.24721155, Accuracy: 0.9162, F1: 0.9529 Bal: 0.8920\n","Epoch 822:      TX: Train Loss: 0.0125, Acc: 0.9978, F1: 0.9988 Bal: 0.9988 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20092198, Acc: 0.92236687, F1: 0.95638650 Bal: 0.9206 - Val Loss: 0.24647756, Accuracy: 0.9145, F1: 0.9519 Bal: 0.8929\n","Epoch 823:      TX: Train Loss: 0.0125, Acc: 0.9978, F1: 0.9988 Bal: 0.9988 - Val Loss: 0.2613, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20089763, Acc: 0.92520065, F1: 0.95806081 Bal: 0.9202 - Val Loss: 0.24753013, Accuracy: 0.9171, F1: 0.9534 Bal: 0.8924\n","Epoch 824:      TX: Train Loss: 0.0125, Acc: 0.9978, F1: 0.9988 Bal: 0.9988 - Val Loss: 0.2612, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20088980, Acc: 0.92145978, F1: 0.95585062 Bal: 0.9206 - Val Loss: 0.24616949, Accuracy: 0.9135, F1: 0.9513 Bal: 0.8936\n","Epoch 825:      TX: Train Loss: 0.0125, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2613, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20089261, Acc: 0.92640528, F1: 0.95876878 Bal: 0.9202 - Val Loss: 0.24800253, Accuracy: 0.9179, F1: 0.9539 Bal: 0.8919\n","Epoch 826:      TX: Train Loss: 0.0124, Acc: 0.9977, F1: 0.9987 Bal: 0.9987 - Val Loss: 0.2613, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20092972, Acc: 0.92016081, F1: 0.95508141 Bal: 0.9206 - Val Loss: 0.24580793, Accuracy: 0.9125, F1: 0.9507 Bal: 0.8940\n","Epoch 827:      TX: Train Loss: 0.0124, Acc: 0.9978, F1: 0.9988 Bal: 0.9988 - Val Loss: 0.2615, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20098129, Acc: 0.92784212, F1: 0.95961251 Bal: 0.9202 - Val Loss: 0.24870600, Accuracy: 0.9193, F1: 0.9547 Bal: 0.8914\n","Epoch 828:      TX: Train Loss: 0.0124, Acc: 0.9978, F1: 0.9988 Bal: 0.9988 - Val Loss: 0.2611, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20109355, Acc: 0.91858609, F1: 0.95414640 Bal: 0.9207 - Val Loss: 0.24543011, Accuracy: 0.9114, F1: 0.9500 Bal: 0.8946\n","Epoch 829:      TX: Train Loss: 0.0124, Acc: 0.9978, F1: 0.9988 Bal: 0.9988 - Val Loss: 0.2614, Accuracy: 0.9726, F1: 0.9848 Bal: 0.9268\n","           WALLETS: Train Loss: 0.20119654, Acc: 0.92934790, F1: 0.96049824 Bal: 0.9197 - Val Loss: 0.24965012, Accuracy: 0.9208, F1: 0.9557 Bal: 0.8906\n","Final_result for w\n","{'hidden_channels': 64, 'num_head': 2, 'num_layers': 2, 'num_epoch': 829, 'patience': 50, 'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0, 'conv_type': 'Transformer', 'p': 10, 'factor': 0.5, 'eta_min': None, 'T_max': None, 'aggr': 'sum', 'lr_scheduler': 'ReduceLROnPlateau', 'optimizer': 'Adam', 'type_model': 'HeteroGNN', 'scaler': 'standard_l2', 'dim_reduction': 'pca', 'pca_threshold': 0.99, 'epoch': 829}\n","Epoch 828:\n","  TX:\n","   Train: Loss=0.0124, Acc=0.9978, F1=0.9988, Bal. Acc=0.9988\n","   Val:   Loss=0.2611, Acc=0.9726, F1=0.9848, Bal. Acc=0.9268\n","   Test:  Loss=0.2976, Acc=0.9690, F1=0.9828, Bal. Acc=0.9184\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.87      0.86       453\n","           1       0.99      0.98      0.98      4105\n","\n","    accuracy                           0.97      4558\n","   macro avg       0.92      0.93      0.92      4558\n","weighted avg       0.97      0.97      0.97      4558\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.86      0.84       665\n","           1       0.98      0.98      0.98      6172\n","\n","    accuracy                           0.97      6837\n","   macro avg       0.91      0.92      0.91      6837\n","weighted avg       0.97      0.97      0.97      6837\n","\n","  WALLETS:\n","   Train: Loss=0.20109355, Acc=0.91858609, F1=0.95414640, Bal. Acc=0.9207\n","   Val:   Loss=0.24543011, Acc=0.9114, F1=0.9500, Bal. Acc=0.8946\n","   Test:  Loss=0.24349943, Acc=0.9107, F1=0.9496, Bal. Acc=0.8968\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.87      0.61      2906\n","           1       0.99      0.91      0.95     33841\n","\n","    accuracy                           0.91     36747\n","   macro avg       0.73      0.89      0.78     36747\n","weighted avg       0.95      0.91      0.92     36747\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.88      0.61      4340\n","           1       0.99      0.91      0.95     50781\n","\n","    accuracy                           0.91     55121\n","   macro avg       0.73      0.90      0.78     55121\n","weighted avg       0.95      0.91      0.92     55121\n","\n","\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1wIoomnaeh74t1AKH1zYUzUr42JRiCeq-","timestamp":1739893838211}],"collapsed_sections":["GR94DzLt62zk"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}